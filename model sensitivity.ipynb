{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "910d412a",
   "metadata": {},
   "source": [
    "## 前期准备preparation in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6bd1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "import time\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fd0176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds to ensure reproducibility\n",
    "# 设置随机种子以保证可复现\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200ca661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据\n",
    "def load_data(folder_path):\n",
    "    # Retrieve all CSV files from the folder\n",
    "    # 获取文件夹中的所有 CSV 文件\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]  \n",
    "    # List used to store data\n",
    "    # 用来存放数据的列表\n",
    "    data_list = []  \n",
    "    \n",
    "    for file_name in csv_files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        # Read CSV file\n",
    "        # 读取 CSV 文件\n",
    "        df = pd.read_csv(file_path,encoding='gbk') \n",
    "        #Only the first and tenth columns of data (including label data) have been selected here and can be freely adjusted\n",
    "        #这里只选中了第1列与第10列数据（包括标签数据），可自由调整\n",
    "        select_data=df.iloc[:,1:10]\n",
    "        #Assuming that the number of rows in each file is seq_1en and the number of columns is feature_stize\n",
    "        # 假设每个文件的行数是 seq_len，列数是 feature_size\n",
    "        seq_len = select_data.shape[0]  \n",
    "        feature_size = select_data.shape[1]  \n",
    "        #Convert DataFrame to NumPy array\n",
    "        # 将 DataFrame 转换为 NumPy 数组\n",
    "        data = select_data.to_numpy()\n",
    "        #Add data to data_ist\n",
    "        # 将数据添加到 data_list 中\n",
    "        data_list.append(data)\n",
    "    #Concatenate the data of all files into a large NumPy array\n",
    "    # 将所有文件的数据拼接成一个大的 NumPy 数组\n",
    "    data_array = np.array(data_list)  # shape: (site_size, seq_len, feature_size)\n",
    "    data_array = data_array.transpose(1,0,2)# shape: (seq_len, site_size, feature_size)\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "311b353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping，patience:allowing the maximum number of training epochs without improvement in validation loss; delta： When the validation loss improves delta at least compared to the optimal loss, it is considered to have improved\n",
    "# 早停机制,patience验证损失未改善情况下允许训练的最大次数；delta：当验证损失比最佳损失至少改善delta则认为有所改善\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ea27d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a sliding window\n",
    "#制作滑动窗口\n",
    "def create_sequences(data, input_seq_len, output_seq_len, datay_site, target_col):\n",
    "    X, y = [], []\n",
    "    #Traverse all possible sequences\n",
    "    # 遍历所有可能的序列\n",
    "    for i in range(len(data) - input_seq_len - output_seq_len + 1):  # len(data) 是 seq_len\n",
    "        #Create input data，shape:(site_size=9, input_seq_len=72, feature_size=9)\n",
    "        # 制作输入序列数据，形状是 (site_size=9, input_seq_len=72, feature_size=9)\n",
    "        X_sample = data[i:i + input_seq_len,:,  :]  # 选择 seq_len 范围的数据\n",
    "        X.append(X_sample)\n",
    "        \n",
    "        #Create output data，shape:(target_site_size=1, output_seq_len, target_feature_size=1)\n",
    "        # 制作输出序列数据，形状是 (target_site_size=1, output_seq_len, target_feature_size=1)\n",
    "        target_data = data[i + input_seq_len:i + input_seq_len + output_seq_len, datay_site,  target_col]\n",
    "        y.append(target_data.reshape(output_seq_len,1,  1))  \n",
    "        \n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25c9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义LSTM模型\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size,dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)  # 批量计算\n",
    "        out = self.dropout(lstm_out[:, -1, :])\n",
    "        out = self.fc(out)  # 仅使用最后时间步的隐藏状态#(batch_size,seq_len,hidden_size)\n",
    "        #out = self.fc(lstm_out[:, :output_seq_len, :])\n",
    "        #print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "294d8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为Tensor\n",
    "def to_tensor(arr):\n",
    "    return torch.tensor(arr, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11603194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#评估指标\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 计算 RMSE、R2 和 MAE\n",
    "def calculate_metrics(predictions, actuals):\n",
    "    # 计算 RMSE\n",
    "    rmse = np.sqrt(np.mean((predictions - actuals) ** 2))\n",
    "    \n",
    "    # 计算 R2\n",
    "    r2 = r2_score(actuals, predictions)\n",
    "    \n",
    "    # 计算 MAE\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    \n",
    "    return rmse, r2, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d9dded",
   "metadata": {},
   "source": [
    "## 定义函数（不同循环需修改）Define function (different loops need to be modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ce19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM训练和验证循环\n",
    "def LSTM_train_and_evaluate(data, param_grid, datay_site, target_site_index, target_col, input_feature):              \n",
    "    for params in ParameterGrid(param_grid):\n",
    "        epoch_logs=[]\n",
    "        input_seq_len = params['input_seq_len']  # 输入序列长度,Input sequence length\n",
    "        output_seq_len = params['output_seq_len']\n",
    "        batch_size = params['batch_size']\n",
    "        learning_rate = params['learning_rate']\n",
    "        LSTM_input_size = params['LSTM_input_size']\n",
    "        LSTM_hidden_size = params['hidden_size']\n",
    "        LSTM_num_layers = params['num_layers']\n",
    "        dropout = params['dropout']\n",
    "        \n",
    "        print(f\"Training with parameters: {params}\")\n",
    "        early_stopping = EarlyStopping(patience=10, delta=0.001)#早停\n",
    "        best_model_state = None\n",
    "        lstm_model = LSTMModel(LSTM_input_size, LSTM_hidden_size, LSTM_num_layers, output_seq_len,dropout)\n",
    "        lstm_model.to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(lstm_model.parameters(), lr=learning_rate)       \n",
    "        epochs=200\n",
    "        \n",
    "        #数据划分\n",
    "        X, y = create_sequences(data, input_seq_len, output_seq_len, datay_site, target_col)\n",
    "        y = y.squeeze((-1,-2))\n",
    "        #Divide the training set，validation set and test set 7:1:2\n",
    "        # 划分训练集验证集和测试集7：1：2\n",
    "        train_size, val_size, test_size = 0.7, 0.1, 0.2\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size/(train_size+val_size+test_size), shuffle=False)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size/(train_size+val_size), shuffle=False)\n",
    "        X_train, X_val, X_test = to_tensor(X_train), to_tensor(X_val), to_tensor(X_test)\n",
    "        y_train, y_val, y_test = to_tensor(y_train), to_tensor(y_val), to_tensor(y_test)\n",
    "        # create DataLoader\n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        val_dataset = TensorDataset(X_val, y_val)\n",
    "        test_dataset = TensorDataset(X_test, y_test)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            start_time=time.time()\n",
    "            lstm_model.train()\n",
    "            train_loss = 0\n",
    "            for X_origin, y_batch in train_loader:\n",
    "                len_1 = len(input_feature) if isinstance(input_feature, (list, tuple, set)) else 1\n",
    "                len_2 = len(target_site_index) if isinstance(target_site_index, (list, tuple, set)) else 1\n",
    "                if len_1+len_2==2:\n",
    "                    X_batch = X_origin[:,:,target_site_index,input_feature].unsqueeze(-1)\n",
    "                if len_1+len_2==18:\n",
    "                    X_batch = X_origin.view(X_origin.size(0),X_origin.size(1),-1)    \n",
    "                else:\n",
    "                    X_batch = X_origin[:,:,target_site_index,input_feature].squeeze()#(batch_size,seq_len, site_size, combined_feature_size)\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                #print(y_batch.shape)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = lstm_model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            \n",
    "            # 验证\n",
    "            lstm_model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for X_origin, y_batch in val_loader:\n",
    "                    len_1 = len(input_feature) if isinstance(input_feature, (list, tuple, set)) else 1\n",
    "                    len_2 = len(target_site_index) if isinstance(target_site_index, (list, tuple, set)) else 1\n",
    "                    if len_1+len_2==2:\n",
    "                        X_batch = X_origin[:,:,target_site_index,input_feature].unsqueeze(-1)\n",
    "                    if len_1+len_2==18:\n",
    "                        X_batch = X_origin.view(X_origin.size(0),X_origin.size(1),-1)\n",
    "                    else:\n",
    "                        X_batch = X_origin[:,:,target_site_index,input_feature].squeeze()\n",
    "                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                    outputs = lstm_model(X_batch)\n",
    "                    loss = criterion(outputs, y_batch)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            end_time=time.time()\n",
    "            epoch_duration=end_time-start_time\n",
    "            epoch_logs.append([epoch+1,train_loss,val_loss,epoch_duration])\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "            if val_loss < early_stopping.best_loss - early_stopping.delta:\n",
    "                best_model_state = lstm_model.state_dict()  # 保存模型参数\n",
    "            early_stopping(val_loss)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        # 回退到最佳模型\n",
    "        if best_model_state is not None:\n",
    "            lstm_model.load_state_dict(best_model_state)\n",
    "            print(\"Model restored to the best validation state.\")\n",
    "\n",
    "\n",
    "        # LSTM测试集评估\n",
    "        lstm_model.eval()\n",
    "        predictions, actuals = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_origin, y_batch in test_loader:\n",
    "                len_1 = len(input_feature) if isinstance(input_feature, (list, tuple, set)) else 1\n",
    "                len_2 = len(target_site_index) if isinstance(target_site_index, (list, tuple, set)) else 1\n",
    "                if len_1+len_2==2:\n",
    "                    X_batch = X_origin[:,:,target_site_index,input_feature].unsqueeze(-1)\n",
    "                if len_1+len_2==18:\n",
    "                    X_batch = X_origin.view(X_origin.size(0),X_origin.size(1),-1)\n",
    "                else:\n",
    "                    X_batch = X_origin[:,:,target_site_index,input_feature].squeeze()\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = lstm_model(X_batch)\n",
    "                predictions.append(outputs.cpu().numpy())  # 将数据移回CPU\n",
    "                actuals.append(y_batch.cpu().numpy())      # 将数据移回CPU\n",
    "\n",
    "        predictions = np.concatenate(predictions, axis=0)\n",
    "        actuals = np.concatenate(actuals, axis=0)\n",
    "        mse = mean_squared_error(actuals, predictions)\n",
    "        print(f\"Test MSE: {mse:.4f}\")\n",
    "    return predictions, actuals, lstm_model, test_loader, epoch_logs\n",
    "\n",
    "#lstm model sensitivity\n",
    "#LSTM特征重要性分析\n",
    "def LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='noise'):\n",
    "    \"\"\"\n",
    "    计算特征的重要性：对于每个特征，在其置零或加噪声时，观察对模型输出的影响。\n",
    "    \"\"\"\n",
    "    feature_importances_all = []\n",
    "    for X_origin, y_batch in test_loader:\n",
    "        feature_importances = []\n",
    "        len_1 = len(input_feature) if isinstance(input_feature, (list, tuple, set)) else 1\n",
    "        len_2 = len(target_site_index) if isinstance(target_site_index, (list, tuple, set)) else 1\n",
    "        if len_1+len_2==2:\n",
    "            X_batch = X_origin[:,:,target_site_index,input_feature].unsqueeze(-1)\n",
    "        if len_1+len_2==18:\n",
    "            X_batch = X_origin.view(X_origin.size(0),X_origin.size(1),-1)\n",
    "        else:\n",
    "            X_batch = X_origin[:,:,target_site_index,input_feature].squeeze()\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        lstm_model.eval()\n",
    "        baseline_output = lstm_model(X_batch).detach().cpu().numpy()  # 将数据移回CPU\n",
    "        for j in range(X_batch.shape[2]):  # 遍历特征\n",
    "            perturbed_output = []\n",
    "            X_perturbed = X_batch.clone()\n",
    "            if baseline == 'zero':\n",
    "                X_perturbed[:, :, j] = 0  # 将第 i 个特征置零\n",
    "            elif baseline == 'noise':\n",
    "                noise = torch.randn_like(X_perturbed[:, :, j])\n",
    "                X_perturbed[:, :, j] += noise*X_perturbed[:, :, j]  # 添加噪声\n",
    "            outputs = lstm_model(X_perturbed)\n",
    "            perturbed_output.append(outputs.detach().cpu().numpy())\n",
    "            importance = np.mean(np.abs(perturbed_output - baseline_output))\n",
    "            feature_importances.append(importance)\n",
    "        feature_importances_all.append(feature_importances)\n",
    "    return feature_importances_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47c01b4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 单站点单特征Single site single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9dbf526",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'LSTM_input_size': 1, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 3.3434, Val Loss: 1.0462\n",
      "Epoch 2/200, Train Loss: 1.8739, Val Loss: 1.1699\n",
      "Epoch 3/200, Train Loss: 1.7709, Val Loss: 0.9568\n",
      "Epoch 4/200, Train Loss: 1.7730, Val Loss: 1.0404\n",
      "Epoch 5/200, Train Loss: 1.6822, Val Loss: 1.0330\n",
      "Epoch 6/200, Train Loss: 1.6112, Val Loss: 0.9890\n",
      "Epoch 7/200, Train Loss: 1.5718, Val Loss: 1.2011\n",
      "Epoch 8/200, Train Loss: 1.5409, Val Loss: 0.7910\n",
      "Epoch 9/200, Train Loss: 1.5354, Val Loss: 0.9658\n",
      "Epoch 10/200, Train Loss: 1.5097, Val Loss: 0.9647\n",
      "Epoch 11/200, Train Loss: 1.4921, Val Loss: 0.9482\n",
      "Epoch 12/200, Train Loss: 1.4879, Val Loss: 0.7971\n",
      "Epoch 13/200, Train Loss: 1.4774, Val Loss: 0.9863\n",
      "Epoch 14/200, Train Loss: 1.4396, Val Loss: 0.6695\n",
      "Epoch 15/200, Train Loss: 1.4237, Val Loss: 0.6673\n",
      "Epoch 16/200, Train Loss: 1.4094, Val Loss: 0.7113\n",
      "Epoch 17/200, Train Loss: 1.3931, Val Loss: 0.7612\n",
      "Epoch 18/200, Train Loss: 1.3878, Val Loss: 1.0263\n",
      "Epoch 19/200, Train Loss: 1.3563, Val Loss: 0.9142\n",
      "Epoch 20/200, Train Loss: 1.3226, Val Loss: 0.7913\n",
      "Epoch 21/200, Train Loss: 1.3004, Val Loss: 0.7425\n",
      "Epoch 22/200, Train Loss: 1.2687, Val Loss: 1.0329\n",
      "Epoch 23/200, Train Loss: 1.2232, Val Loss: 0.9926\n",
      "Epoch 24/200, Train Loss: 1.1777, Val Loss: 0.6904\n",
      "Epoch 25/200, Train Loss: 1.1024, Val Loss: 0.6230\n",
      "Epoch 26/200, Train Loss: 1.0790, Val Loss: 0.8067\n",
      "Epoch 27/200, Train Loss: 1.0598, Val Loss: 1.0771\n",
      "Epoch 28/200, Train Loss: 1.0432, Val Loss: 0.7237\n",
      "Epoch 29/200, Train Loss: 1.0317, Val Loss: 0.7768\n",
      "Epoch 30/200, Train Loss: 1.0341, Val Loss: 0.9742\n",
      "Epoch 31/200, Train Loss: 1.0297, Val Loss: 0.8572\n",
      "Epoch 32/200, Train Loss: 0.9831, Val Loss: 0.8070\n",
      "Epoch 33/200, Train Loss: 0.9682, Val Loss: 0.8019\n",
      "Epoch 34/200, Train Loss: 0.9443, Val Loss: 1.0336\n",
      "Epoch 35/200, Train Loss: 0.9360, Val Loss: 0.7711\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 1.8846\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.3728\n",
      "Test R2: 0.2164\n",
      "Test MAE: 1.1092\n",
      "0    1.994074\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "#单站点单特征循环Single site single feature\n",
    "#change the Define function.input: X_origin[:,:,target_site_index,input_feature].unsqueeze(-1),LSTM_input_size = 1\n",
    "#超参数优化\n",
    "param_grid = {\n",
    "    'LSTM_input_size' : [1],\n",
    "    'hidden_size': [64],#32,64,128\n",
    "    'num_layers': [2],#1, 2, 3\n",
    "    'learning_rate': [0.001],#0.001, 0.002, 0.005\n",
    "    'batch_size': [16],#8，16, 32\n",
    "    'dropout': [0.2],#0.1,0.2,0.3\n",
    "    'input_seq_len' : [72],#24,48,72\n",
    "    'output_seq_len' : [1]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "all_output_metrics = []\n",
    "all_output_importance = []\n",
    "folder_path = 'E:\\LYQ\\data'\n",
    "#'E:\\LYQ\\data'\n",
    "#'E:/your/data/folder_path'\n",
    "data = load_data(folder_path)\n",
    "for model_sites in range(9):\n",
    "    output_metrics = []\n",
    "    output_importance = []\n",
    "    for model_input_feature in range(9):\n",
    "        #Model hyperparameters\n",
    "        datay_site = model_sites\n",
    "        target_site_index = model_sites\n",
    "        target_col = 2  # 目标特征（例如 特征0）,Target feature (e.g. feature 0)\n",
    "        input_feature = model_input_feature#0:WT,1:pH,2:DO,3:EC,4:TSS,5:CODMN,6:AN,7:TP,8:TN\n",
    "\n",
    "        target_site_index = model_sites  # 目标站点（例如 站点0）,Target site (e.g. site 0)\n",
    "        predictions, actuals, lstm_model, test_loader, epoch_logs = LSTM_train_and_evaluate(data,param_grid,datay_site, target_site_index, target_col, input_feature)        #Calculate accuracy\n",
    "        # 计算精度\n",
    "        rmse, r2, mae = calculate_metrics(predictions, actuals)\n",
    "        #result\n",
    "        # 输出结果\n",
    "        print(f\"predictions shape: {predictions.shape}\")\n",
    "        print(f\"actuals shape: {actuals.shape}\")\n",
    "        print(f\"Test RMSE: {rmse:.4f}\")\n",
    "        print(f\"Test R2: {r2:.4f}\")\n",
    "        print(f\"Test MAE: {mae:.4f}\")\n",
    "        feature_importances = np.mean(pd.DataFrame(LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='noise')),axis= 0)\n",
    "        print(feature_importances)\n",
    "        \n",
    "        output_metrics.append([rmse, r2, mae])\n",
    "        output_importance.append(feature_importances)\n",
    "        epoch_logs = pd.DataFrame(epoch_logs,columns=['Epoch','Train_Loss','Val_loss','Time'])\n",
    "        epoch_logs.to_csv(f\"LSTM_logs_1site_1feature_batch_site{model_sites}_feature{model_input_feature}.csv\",index=False)\n",
    "        \n",
    "    all_output_metrics.append(pd.DataFrame(output_metrics,columns=['RMSE','R2','MAE']))\n",
    "    all_output_importance.append(pd.DataFrame({f\"N{model_sites}\" : output_importance.values}, index = ['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']))\n",
    "    torch.save(lstm_model,f\"LSTM_N{target_site_index+1}_1Feature1Site_targetDO.pth\")\n",
    "    \n",
    "result_output_metrics = pd.concat(all_output_metrics,axis = 1)\n",
    "result_output_importance = pd.concat(all_output_importance,axis = 1)\n",
    "result_output_metrics.index = result_output_importance.index = ['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']\n",
    "\n",
    "result_output_metrics.to_csv(f\"LSTM_1site_1feature_batch_metrics.csv\",index=False)\n",
    "result_output_importance.to_csv(f\"LSTM_1site_1feature_batch_importance.csv\",index=False)\n",
    "['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127d3a8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 单站点所有特征Single site all feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1820d8a5",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30642, 9, 9)\n",
      "Training with parameters: {'LSTM_input_size': 9, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 2.2908, Val Loss: 0.5853\n",
      "Epoch 2/200, Train Loss: 0.4792, Val Loss: 0.4542\n",
      "Epoch 3/200, Train Loss: 0.4410, Val Loss: 0.5107\n",
      "Epoch 4/200, Train Loss: 0.4208, Val Loss: 0.5473\n",
      "Epoch 5/200, Train Loss: 0.3853, Val Loss: 0.4644\n",
      "Epoch 6/200, Train Loss: 0.3833, Val Loss: 0.4832\n",
      "Epoch 7/200, Train Loss: 0.3748, Val Loss: 0.4648\n",
      "Epoch 8/200, Train Loss: 0.3544, Val Loss: 0.3354\n",
      "Epoch 9/200, Train Loss: 0.3495, Val Loss: 0.5461\n",
      "Epoch 10/200, Train Loss: 0.3327, Val Loss: 0.3919\n",
      "Epoch 11/200, Train Loss: 0.3239, Val Loss: 0.3242\n",
      "Epoch 12/200, Train Loss: 0.3023, Val Loss: 0.3547\n",
      "Epoch 13/200, Train Loss: 0.2974, Val Loss: 0.3857\n",
      "Epoch 14/200, Train Loss: 0.2857, Val Loss: 0.3866\n",
      "Epoch 15/200, Train Loss: 0.2758, Val Loss: 0.3286\n",
      "Epoch 16/200, Train Loss: 0.2764, Val Loss: 0.4432\n",
      "Epoch 17/200, Train Loss: 0.2665, Val Loss: 0.4789\n",
      "Epoch 18/200, Train Loss: 0.2594, Val Loss: 0.3424\n",
      "Epoch 19/200, Train Loss: 0.2546, Val Loss: 0.3128\n",
      "Epoch 20/200, Train Loss: 0.2398, Val Loss: 0.3030\n",
      "Epoch 21/200, Train Loss: 0.2394, Val Loss: 0.4065\n",
      "Epoch 22/200, Train Loss: 0.2241, Val Loss: 0.3268\n",
      "Epoch 23/200, Train Loss: 0.2245, Val Loss: 0.2880\n",
      "Epoch 24/200, Train Loss: 0.2147, Val Loss: 0.2295\n",
      "Epoch 25/200, Train Loss: 0.2069, Val Loss: 0.3978\n",
      "Epoch 26/200, Train Loss: 0.1998, Val Loss: 0.2169\n",
      "Epoch 27/200, Train Loss: 0.1933, Val Loss: 0.1785\n",
      "Epoch 28/200, Train Loss: 0.1960, Val Loss: 0.1169\n",
      "Epoch 29/200, Train Loss: 0.1867, Val Loss: 0.1789\n",
      "Epoch 30/200, Train Loss: 0.1840, Val Loss: 0.2436\n",
      "Epoch 31/200, Train Loss: 0.1802, Val Loss: 0.2708\n",
      "Epoch 32/200, Train Loss: 0.1704, Val Loss: 0.2089\n",
      "Epoch 33/200, Train Loss: 0.1681, Val Loss: 0.1464\n",
      "Epoch 34/200, Train Loss: 0.1671, Val Loss: 0.2381\n",
      "Epoch 35/200, Train Loss: 0.1609, Val Loss: 0.2033\n",
      "Epoch 36/200, Train Loss: 0.1597, Val Loss: 0.3179\n",
      "Epoch 37/200, Train Loss: 0.1568, Val Loss: 0.2660\n",
      "Epoch 38/200, Train Loss: 0.1532, Val Loss: 0.2285\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 0.0960\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.3099\n",
      "Test R2: 0.9601\n",
      "Test MAE: 0.2052\n",
      "0    0.426130\n",
      "1    0.232746\n",
      "2    2.171083\n",
      "3    0.690224\n",
      "4    0.113830\n",
      "5    0.200023\n",
      "6    0.020548\n",
      "7    0.005491\n",
      "8    0.164992\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "#单站点所有特征循环,Single site all feature\n",
    "#change the Define function input:X_origin[:,:,target_site_index,:].squeeze(),LSTM_input_size = 9\n",
    "#超参数优化\n",
    "param_grid = {\n",
    "    'LSTM_input_size' : [9],\n",
    "    'hidden_size': [64],#32,64,128\n",
    "    'num_layers': [2],#1, 2, 3\n",
    "    'learning_rate': [0.001],#0.001, 0.002, 0.005\n",
    "    'batch_size': [16],#8，16, 32\n",
    "    'dropout': [0.2],#0.1,0.2,0.3\n",
    "    'input_seq_len' : [72],#24,48,72\n",
    "    'output_seq_len' : [1]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "all_output_metrics = []\n",
    "all_output_importance = []\n",
    "folder_path = 'E:\\LYQ\\data'\n",
    "#'E:\\LYQ\\data'\n",
    "#'E:/your/data/folder_path'\n",
    "data = load_data(folder_path)\n",
    "print(data.shape)\n",
    "target_col = 2  # 目标特征（例如 特征0）,Target feature (e.g. feature 0)\n",
    "input_feature = [0,1,2,3,4,5,6,7,8]#0:WT,1:pH,2:DO,3:EC,4:TSS,5:CODMN,6:AN,7:TP,8:TN  \n",
    "\n",
    "\n",
    "for model_sites in range(1):\n",
    "    #Model hyperparameters\n",
    "    # 模型超参数\n",
    "    datay_site = model_sites\n",
    "    target_site_index = model_sites\n",
    "    predictions, actuals, lstm_model, test_loader, epoch_logs = LSTM_train_and_evaluate(data,param_grid, datay_site, target_site_index, target_col, input_feature)\n",
    "    #Calculate accuracy\n",
    "    # 计算精度\n",
    "    rmse, r2, mae = calculate_metrics(predictions, actuals)\n",
    "    #result\n",
    "    # 输出结果\n",
    "    print(f\"predictions shape: {predictions.shape}\")\n",
    "    print(f\"actuals shape: {actuals.shape}\")\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test R2: {r2:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    feature_importances = np.mean(pd.DataFrame(LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='noise')),axis= 0)\n",
    "    print(feature_importances)\n",
    "\n",
    "    all_output_metrics.append([rmse, r2, mae])\n",
    "    all_output_importance.append(pd.DataFrame({f\"N{model_sites}\" : feature_importances.values}, index = ['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']))\n",
    "    epoch_logs = pd.DataFrame(epoch_logs,columns=['Epoch','Train_Loss','Val_loss','Time'])\n",
    "    epoch_logs.to_csv(f\"LSTM_logs_1siteallfeature_batch_site{model_sites}.csv\",index=False)\n",
    "\n",
    "    torch.save(lstm_model,f\"LSTM_N{target_site_index+1}_AllFeature1Site_targetDO.pth\")\n",
    "\n",
    "result_output_metrics = pd.DataFrame(all_output_metrics,columns=['RMSE','R2','MAE'])\n",
    "result_output_importance = pd.concat(all_output_importance,axis = 1)\n",
    "\n",
    "result_output_metrics.to_csv(f\"LSTM_1siteallfeature_batch_metrics_.csv\",index=False)\n",
    "result_output_importance.to_csv(f\"LSTM_1siteallfeature_logs_one_batch_importance.csv\",index=False)\n",
    "#['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc94a45",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 所有站点单特征all site single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d737ccb2",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30642, 9, 9)\n",
      "Training with parameters: {'LSTM_input_size': 9, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 3.3912, Val Loss: 0.9712\n",
      "Epoch 2/200, Train Loss: 1.7313, Val Loss: 0.9760\n",
      "Epoch 3/200, Train Loss: 1.6899, Val Loss: 1.0574\n",
      "Epoch 4/200, Train Loss: 1.6682, Val Loss: 0.9305\n",
      "Epoch 5/200, Train Loss: 1.5761, Val Loss: 1.0228\n",
      "Epoch 6/200, Train Loss: 1.4998, Val Loss: 0.9627\n",
      "Epoch 7/200, Train Loss: 1.3818, Val Loss: 0.9327\n",
      "Epoch 8/200, Train Loss: 1.3337, Val Loss: 0.7837\n",
      "Epoch 9/200, Train Loss: 1.2906, Val Loss: 0.9181\n",
      "Epoch 10/200, Train Loss: 1.2782, Val Loss: 0.8577\n",
      "Epoch 11/200, Train Loss: 1.2528, Val Loss: 0.9729\n",
      "Epoch 12/200, Train Loss: 1.2150, Val Loss: 1.4816\n",
      "Epoch 13/200, Train Loss: 1.1874, Val Loss: 0.8125\n",
      "Epoch 14/200, Train Loss: 1.2008, Val Loss: 0.9700\n",
      "Epoch 15/200, Train Loss: 1.1664, Val Loss: 0.8087\n",
      "Epoch 16/200, Train Loss: 1.1652, Val Loss: 0.8450\n",
      "Epoch 17/200, Train Loss: 1.1591, Val Loss: 0.8949\n",
      "Epoch 18/200, Train Loss: 1.1115, Val Loss: 1.1503\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 1.4172\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1905\n",
      "Test R2: 0.4108\n",
      "Test MAE: 0.9438\n",
      "0    1.452677\n",
      "1    2.299560\n",
      "2    0.460307\n",
      "3    3.801808\n",
      "4    1.051374\n",
      "5    2.400837\n",
      "6    1.238603\n",
      "7    1.316780\n",
      "8    3.004918\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "#所有站点单特征循环all site single feature\n",
    "#change the Define function input:X_origin[:,:,:,input_feature].squeeze(),LSTM_input_size = 9\n",
    "#超参数优化\n",
    "param_grid = {\n",
    "    'LSTM_input_size' : [9],\n",
    "    'hidden_size': [64],#32,64,128\n",
    "    'num_layers': [2],#1, 2, 3\n",
    "    'learning_rate': [0.001],#0.001, 0.002, 0.005\n",
    "    'batch_size': [16],#8，16, 32\n",
    "    'dropout': [0.2],#0.1,0.2,0.3\n",
    "    'input_seq_len' : [72],#24,48,72\n",
    "    'output_seq_len' : [1]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "all_output_metrics = []\n",
    "all_output_importance = []\n",
    "folder_path = 'E:\\LYQ\\data'\n",
    "#'E:\\LYQ\\data'\n",
    "#'E:/your/data/folder_path'\n",
    "data = load_data(folder_path)\n",
    "print(data.shape)\n",
    "target_col = 2  # 目标特征（例如 特征0）,Target feature (e.g. feature 0)\n",
    "target_site_index = [0,1,2,3,4,5,6,7,8]#range(9)\n",
    "all_output_metrics = []\n",
    "all_output_importance = []\n",
    "\n",
    "for model_sites in range(9):\n",
    "    output_metrics = []\n",
    "    output_importance = []\n",
    "    for model_input_feature in range(9):\n",
    "        #Model hyperparameters\n",
    "        # 模型超参数\n",
    "        datay_site = model_sites\n",
    "\n",
    "        input_feature = model_input_feature#0:WT,1:pH,2:DO,3:EC,4:TSS,5:CODMN,6:AN,7:TP,8:TN\n",
    "\n",
    "        predictions, actuals, lstm_model, test_loader, epoch_logs = LSTM_train_and_evaluate(data,param_grid, datay_site, target_site_index, target_col, input_feature)\n",
    "        #Calculate accuracy\n",
    "        # 计算精度\n",
    "        rmse, r2, mae = calculate_metrics(predictions, actuals)\n",
    "        #result\n",
    "        # 输出结果\n",
    "        print(f\"predictions shape: {predictions.shape}\")\n",
    "        print(f\"actuals shape: {actuals.shape}\")\n",
    "        print(f\"Test RMSE: {rmse:.4f}\")\n",
    "        print(f\"Test R2: {r2:.4f}\")\n",
    "        print(f\"Test MAE: {mae:.4f}\")\n",
    "        feature_importances = np.mean(pd.DataFrame(LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='zero')),axis= 0)\n",
    "        print(feature_importances)\n",
    "        \n",
    "        feature_importanes= pd.DataFrame({f\"F{model_input_feature}\" : feature_importances.values}, index = [f'N{s}' for s in range(9)])\n",
    "        \n",
    "        output_metrics.append([rmse, r2, mae])\n",
    "        output_importance.append(feature_importances)\n",
    "        epoch_logs = pd.DataFrame(epoch_logs,columns=['Epoch','Train_Loss','Val_loss','Time'])\n",
    "        epoch_logs.to_csv(f\"LSTM_logs_allsite_1feature_batch_site{model_sites}_feature{model_input_feature}.csv\",index=False)  \n",
    "        \n",
    "    all_output_metrics.append(pd.DataFrame(output_metrics,columns=['RMSE','R2','MAE'], index = ['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']))\n",
    "    all_output_importance = pd.concat(output_importance,axis = 1)\n",
    "    all_output_importance.to_csv(f\"LSTM_al1site_1feature_batch_importance_site{model_sites}.csv\",index=False)\n",
    "\n",
    "    torch.save(lstm_model,f\"LSTM_N{target_site_index+1}_1FeatureAllSite_targetDO.pth\")\n",
    "    \n",
    "result_output_metrics = pd.concat(all_output_metrics,axis = 1)\n",
    "\n",
    "result_output_metrics.to_csv(f\"LSTM_al1site_1feature_batch_metrics.csv\",index=False)\n",
    "\n",
    "# all_output_metrics.to_csv(f\"LSTM_allsite_1feature_batch_metrics备用查看数据.csv\",index=False)\n",
    "#['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "701d6a00",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30642, 9, 9)\n",
      "Training with parameters: {'LSTM_input_size': 8, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 3.3546, Val Loss: 0.9230\n",
      "Epoch 2/200, Train Loss: 1.2254, Val Loss: 0.9439\n",
      "Epoch 3/200, Train Loss: 1.1671, Val Loss: 1.1216\n",
      "Epoch 4/200, Train Loss: 1.0972, Val Loss: 1.2287\n",
      "Epoch 5/200, Train Loss: 1.0293, Val Loss: 1.4855\n",
      "Epoch 6/200, Train Loss: 0.9620, Val Loss: 1.6070\n",
      "Epoch 7/200, Train Loss: 0.8755, Val Loss: 1.8171\n",
      "Epoch 8/200, Train Loss: 0.8064, Val Loss: 1.7334\n",
      "Epoch 9/200, Train Loss: 0.7363, Val Loss: 1.2975\n",
      "Epoch 10/200, Train Loss: 0.7073, Val Loss: 1.5761\n",
      "Epoch 11/200, Train Loss: 0.6640, Val Loss: 1.3089\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 1.0147\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.0073\n",
      "Test R2: 0.5781\n",
      "Test MAE: 0.7357\n",
      "0    1.554133\n",
      "1    1.105961\n",
      "2    0.618451\n",
      "3    1.272881\n",
      "4    1.680006\n",
      "5    0.558631\n",
      "6    1.836389\n",
      "7    0.620964\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 8, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 2.3720, Val Loss: 0.9551\n",
      "Epoch 2/200, Train Loss: 0.9350, Val Loss: 0.8508\n",
      "Epoch 3/200, Train Loss: 0.8448, Val Loss: 1.2817\n",
      "Epoch 4/200, Train Loss: 0.7694, Val Loss: 0.8275\n",
      "Epoch 5/200, Train Loss: 0.7273, Val Loss: 1.1033\n",
      "Epoch 6/200, Train Loss: 0.6723, Val Loss: 0.8851\n",
      "Epoch 7/200, Train Loss: 0.6207, Val Loss: 0.8027\n",
      "Epoch 8/200, Train Loss: 0.6048, Val Loss: 1.0511\n",
      "Epoch 9/200, Train Loss: 0.5611, Val Loss: 0.9958\n",
      "Epoch 10/200, Train Loss: 0.5162, Val Loss: 0.9301\n",
      "Epoch 11/200, Train Loss: 0.4859, Val Loss: 1.1794\n",
      "Epoch 12/200, Train Loss: 0.4690, Val Loss: 1.3146\n",
      "Epoch 13/200, Train Loss: 0.4612, Val Loss: 0.8022\n",
      "Epoch 14/200, Train Loss: 0.4203, Val Loss: 1.0758\n",
      "Epoch 15/200, Train Loss: 0.4078, Val Loss: 0.9362\n",
      "Epoch 16/200, Train Loss: 0.3790, Val Loss: 0.9235\n",
      "Epoch 17/200, Train Loss: 0.3650, Val Loss: 1.0874\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 1.1651\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.0794\n",
      "Test R2: 0.3474\n",
      "Test MAE: 0.8324\n",
      "0    2.266707\n",
      "1    1.132631\n",
      "2    1.307736\n",
      "3    0.647027\n",
      "4    1.414199\n",
      "5    0.830898\n",
      "6    0.603408\n",
      "7    0.546085\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 8, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 2.2647, Val Loss: 0.8698\n",
      "Epoch 2/200, Train Loss: 1.1291, Val Loss: 0.7892\n",
      "Epoch 3/200, Train Loss: 1.0481, Val Loss: 0.9079\n",
      "Epoch 4/200, Train Loss: 1.0011, Val Loss: 1.8700\n",
      "Epoch 5/200, Train Loss: 0.9794, Val Loss: 0.9570\n",
      "Epoch 6/200, Train Loss: 0.9425, Val Loss: 1.3304\n",
      "Epoch 7/200, Train Loss: 0.9389, Val Loss: 1.3086\n",
      "Epoch 8/200, Train Loss: 0.8952, Val Loss: 1.5460\n",
      "Epoch 9/200, Train Loss: 0.8848, Val Loss: 0.9664\n",
      "Epoch 10/200, Train Loss: 0.8610, Val Loss: 1.8326\n",
      "Epoch 11/200, Train Loss: 0.8327, Val Loss: 1.2555\n",
      "Epoch 12/200, Train Loss: 0.8300, Val Loss: 1.5779\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 1.9855\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.4091\n",
      "Test R2: 0.6423\n",
      "Test MAE: 1.1497\n",
      "0    0.683990\n",
      "1    1.645456\n",
      "2    2.862142\n",
      "3    1.066944\n",
      "4    0.840301\n",
      "5    0.798985\n",
      "6    0.979392\n",
      "7    1.718578\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 8, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 2.1868, Val Loss: 2.2146\n",
      "Epoch 2/200, Train Loss: 1.0386, Val Loss: 2.0606\n",
      "Epoch 3/200, Train Loss: 0.9392, Val Loss: 1.9580\n",
      "Epoch 4/200, Train Loss: 0.8957, Val Loss: 1.6844\n",
      "Epoch 5/200, Train Loss: 0.8741, Val Loss: 1.7889\n",
      "Epoch 6/200, Train Loss: 0.8186, Val Loss: 2.3924\n",
      "Epoch 7/200, Train Loss: 0.8148, Val Loss: 2.3117\n",
      "Epoch 8/200, Train Loss: 0.7575, Val Loss: 2.6648\n",
      "Epoch 9/200, Train Loss: 0.7282, Val Loss: 2.4206\n",
      "Epoch 10/200, Train Loss: 0.7175, Val Loss: 2.0032\n",
      "Epoch 11/200, Train Loss: 0.6886, Val Loss: 1.8821\n",
      "Epoch 12/200, Train Loss: 0.6691, Val Loss: 1.5811\n",
      "Epoch 13/200, Train Loss: 0.6525, Val Loss: 2.7534\n",
      "Epoch 14/200, Train Loss: 0.6282, Val Loss: 2.5588\n",
      "Epoch 15/200, Train Loss: 0.6107, Val Loss: 2.3252\n",
      "Epoch 16/200, Train Loss: 0.6054, Val Loss: 3.0207\n",
      "Epoch 17/200, Train Loss: 0.5794, Val Loss: 2.1660\n",
      "Epoch 18/200, Train Loss: 0.5614, Val Loss: 1.8924\n",
      "Epoch 19/200, Train Loss: 0.5554, Val Loss: 2.3693\n",
      "Epoch 20/200, Train Loss: 0.5366, Val Loss: 2.0801\n",
      "Epoch 21/200, Train Loss: 0.5174, Val Loss: 1.8816\n",
      "Epoch 22/200, Train Loss: 0.5120, Val Loss: 1.7072\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 0.8163\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.9035\n",
      "Test R2: 0.7825\n",
      "Test MAE: 0.6706\n",
      "0    0.573948\n",
      "1    1.347235\n",
      "2    1.076815\n",
      "3    0.608977\n",
      "4    2.184651\n",
      "5    0.562442\n",
      "6    1.208233\n",
      "7    0.879259\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 8, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 1.5623, Val Loss: 2.1712\n",
      "Epoch 2/200, Train Loss: 0.8586, Val Loss: 2.4690\n",
      "Epoch 3/200, Train Loss: 0.8195, Val Loss: 2.0191\n",
      "Epoch 4/200, Train Loss: 0.7887, Val Loss: 2.0512\n",
      "Epoch 5/200, Train Loss: 0.7504, Val Loss: 2.0458\n",
      "Epoch 6/200, Train Loss: 0.7176, Val Loss: 2.4104\n",
      "Epoch 7/200, Train Loss: 0.7079, Val Loss: 1.9610\n",
      "Epoch 8/200, Train Loss: 0.6722, Val Loss: 2.0420\n",
      "Epoch 9/200, Train Loss: 0.6463, Val Loss: 2.1165\n",
      "Epoch 10/200, Train Loss: 0.6230, Val Loss: 1.8923\n",
      "Epoch 11/200, Train Loss: 0.6100, Val Loss: 2.0978\n",
      "Epoch 12/200, Train Loss: 0.5790, Val Loss: 2.0064\n",
      "Epoch 13/200, Train Loss: 0.5590, Val Loss: 2.2433\n",
      "Epoch 14/200, Train Loss: 0.5394, Val Loss: 2.0832\n",
      "Epoch 15/200, Train Loss: 0.5208, Val Loss: 2.0401\n",
      "Epoch 16/200, Train Loss: 0.5103, Val Loss: 2.4081\n",
      "Epoch 17/200, Train Loss: 0.4844, Val Loss: 2.0384\n",
      "Epoch 18/200, Train Loss: 0.4631, Val Loss: 2.1299\n",
      "Epoch 19/200, Train Loss: 0.4504, Val Loss: 2.0592\n",
      "Epoch 20/200, Train Loss: 0.4363, Val Loss: 2.1002\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 1.0300\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.0149\n",
      "Test R2: 0.7777\n",
      "Test MAE: 0.8129\n",
      "0    1.334272\n",
      "1    0.612946\n",
      "2    1.117240\n",
      "3    0.989566\n",
      "4    0.793331\n",
      "5    1.137534\n",
      "6    0.613219\n",
      "7    2.313126\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 8, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 2.0068, Val Loss: 0.5472\n",
      "Epoch 2/200, Train Loss: 0.9659, Val Loss: 0.5327\n",
      "Epoch 3/200, Train Loss: 0.9080, Val Loss: 0.6022\n",
      "Epoch 4/200, Train Loss: 0.8404, Val Loss: 0.6483\n",
      "Epoch 5/200, Train Loss: 0.8088, Val Loss: 0.5452\n",
      "Epoch 6/200, Train Loss: 0.7650, Val Loss: 0.5241\n",
      "Epoch 7/200, Train Loss: 0.7360, Val Loss: 0.6104\n",
      "Epoch 8/200, Train Loss: 0.6998, Val Loss: 0.6052\n",
      "Epoch 9/200, Train Loss: 0.6937, Val Loss: 0.6141\n",
      "Epoch 10/200, Train Loss: 0.6575, Val Loss: 0.7250\n",
      "Epoch 11/200, Train Loss: 0.6236, Val Loss: 0.5703\n",
      "Epoch 12/200, Train Loss: 0.6014, Val Loss: 0.7113\n",
      "Epoch 13/200, Train Loss: 0.6041, Val Loss: 0.5633\n",
      "Epoch 14/200, Train Loss: 0.5774, Val Loss: 0.6827\n",
      "Epoch 15/200, Train Loss: 0.5676, Val Loss: 0.5991\n",
      "Epoch 16/200, Train Loss: 0.5303, Val Loss: 0.5786\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 0.5996\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.7743\n",
      "Test R2: 0.8141\n",
      "Test MAE: 0.5996\n",
      "0    0.750948\n",
      "1    1.820677\n",
      "2    0.540305\n",
      "3    2.569266\n",
      "4    0.635537\n",
      "5    0.439796\n",
      "6    0.979614\n",
      "7    0.482966\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 8, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 1.5609, Val Loss: 0.9635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 1.1266, Val Loss: 0.8536\n",
      "Epoch 3/200, Train Loss: 1.0810, Val Loss: 1.0222\n",
      "Epoch 4/200, Train Loss: 1.0385, Val Loss: 0.8473\n",
      "Epoch 5/200, Train Loss: 0.9832, Val Loss: 1.1354\n",
      "Epoch 6/200, Train Loss: 0.9364, Val Loss: 1.2395\n",
      "Epoch 7/200, Train Loss: 0.9165, Val Loss: 1.3763\n",
      "Epoch 8/200, Train Loss: 0.8620, Val Loss: 0.8860\n",
      "Epoch 9/200, Train Loss: 0.8338, Val Loss: 1.5593\n",
      "Epoch 10/200, Train Loss: 0.8266, Val Loss: 1.1515\n",
      "Epoch 11/200, Train Loss: 0.7663, Val Loss: 1.5017\n",
      "Epoch 12/200, Train Loss: 0.7373, Val Loss: 1.4058\n",
      "Epoch 13/200, Train Loss: 0.7127, Val Loss: 1.5514\n",
      "Epoch 14/200, Train Loss: 0.7029, Val Loss: 1.4588\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 1.3703\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1706\n",
      "Test R2: 0.4421\n",
      "Test MAE: 1.0155\n",
      "0    0.566114\n",
      "1    0.845455\n",
      "2    1.431105\n",
      "3    0.876834\n",
      "4    1.439783\n",
      "5    0.666207\n",
      "6    2.039798\n",
      "7    1.068767\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 8, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 1.9058, Val Loss: 1.0848\n",
      "Epoch 2/200, Train Loss: 1.2754, Val Loss: 1.0551\n",
      "Epoch 3/200, Train Loss: 1.2023, Val Loss: 1.2595\n",
      "Epoch 4/200, Train Loss: 1.1396, Val Loss: 1.3946\n",
      "Epoch 5/200, Train Loss: 1.0888, Val Loss: 1.2448\n",
      "Epoch 6/200, Train Loss: 1.0524, Val Loss: 1.2569\n",
      "Epoch 7/200, Train Loss: 1.0415, Val Loss: 1.1666\n",
      "Epoch 8/200, Train Loss: 0.9977, Val Loss: 1.2590\n",
      "Epoch 9/200, Train Loss: 0.9959, Val Loss: 1.1392\n",
      "Epoch 10/200, Train Loss: 0.9515, Val Loss: 1.4453\n",
      "Epoch 11/200, Train Loss: 0.9248, Val Loss: 1.2669\n",
      "Epoch 12/200, Train Loss: 0.8768, Val Loss: 1.3665\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 1.2320\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1099\n",
      "Test R2: 0.4647\n",
      "Test MAE: 0.8204\n",
      "0    1.002697\n",
      "1    0.923494\n",
      "2    0.662354\n",
      "3    0.736907\n",
      "4    0.444588\n",
      "5    0.926649\n",
      "6    2.620903\n",
      "7    1.060482\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 8, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 1.3095, Val Loss: 1.0504\n",
      "Epoch 2/200, Train Loss: 0.7397, Val Loss: 1.0961\n",
      "Epoch 3/200, Train Loss: 0.6739, Val Loss: 0.9932\n",
      "Epoch 4/200, Train Loss: 0.6286, Val Loss: 1.3586\n",
      "Epoch 5/200, Train Loss: 0.5732, Val Loss: 1.0167\n",
      "Epoch 6/200, Train Loss: 0.5358, Val Loss: 1.1234\n",
      "Epoch 7/200, Train Loss: 0.5106, Val Loss: 1.0994\n",
      "Epoch 8/200, Train Loss: 0.4786, Val Loss: 1.0928\n",
      "Epoch 9/200, Train Loss: 0.4705, Val Loss: 1.0713\n",
      "Epoch 10/200, Train Loss: 0.4420, Val Loss: 1.1584\n",
      "Epoch 11/200, Train Loss: 0.4287, Val Loss: 1.2455\n",
      "Epoch 12/200, Train Loss: 0.4126, Val Loss: 1.3663\n",
      "Epoch 13/200, Train Loss: 0.4030, Val Loss: 1.2492\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 1.4594\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.2080\n",
      "Test R2: 0.6084\n",
      "Test MAE: 0.9471\n",
      "0    2.276833\n",
      "1    1.062763\n",
      "2    1.192437\n",
      "3    0.974644\n",
      "4    2.113030\n",
      "5    0.668797\n",
      "6    1.410008\n",
      "7    0.866304\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#所有站点单特征循环all site single feature\n",
    "#change the Define function input:X_origin[:,:,:,input_feature].squeeze(),LSTM_input_size = 9\n",
    "#超参数优化\n",
    "param_grid = {\n",
    "    'LSTM_input_size' : [8],\n",
    "    'hidden_size': [64],#32,64,128\n",
    "    'num_layers': [3],#1, 2, 3\n",
    "    'learning_rate': [0.001],#0.001, 0.002, 0.005\n",
    "    'batch_size': [16],#8，16, 32\n",
    "    'dropout': [0.3],#0.1,0.2,0.3\n",
    "    'input_seq_len' : [72],#24,48,72\n",
    "    'output_seq_len' : [1]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "all_output_metrics = []\n",
    "all_output_importance = []\n",
    "folder_path = 'E:\\LYQ\\data'\n",
    "#'E:\\LYQ\\data'\n",
    "#'E:/your/data/folder_path'\n",
    "data = load_data(folder_path)\n",
    "print(data.shape)\n",
    "target_col = 2  # 目标特征（例如 特征0）,Target feature (e.g. feature 0)\n",
    "range9 = list(range(9))\n",
    "all_output_metrics = []\n",
    "all_output_importance = []\n",
    "\n",
    "for model_sites in range(9):\n",
    "    output_metrics = []\n",
    "    output_importance = []\n",
    "    for model_input_feature in range(1):\n",
    "        #Model hyperparameters\n",
    "        # 模型超参数\n",
    "        datay_site = model_sites\n",
    "        target_site_index = range9[:model_sites]+range9[model_sites+1:]\n",
    "        input_feature = 2#0:WT,1:pH,2:DO,3:EC,4:TSS,5:CODMN,6:AN,7:TP,8:TN\n",
    "\n",
    "        predictions, actuals, lstm_model, test_loader, epoch_logs = LSTM_train_and_evaluate(data,param_grid, datay_site, target_site_index, target_col, input_feature)\n",
    "        #Calculate accuracy\n",
    "        # 计算精度\n",
    "        rmse, r2, mae = calculate_metrics(predictions, actuals)\n",
    "        #result\n",
    "        # 输出结果\n",
    "        print(f\"predictions shape: {predictions.shape}\")\n",
    "        print(f\"actuals shape: {actuals.shape}\")\n",
    "        print(f\"Test RMSE: {rmse:.4f}\")\n",
    "        print(f\"Test R2: {r2:.4f}\")\n",
    "        print(f\"Test MAE: {mae:.4f}\")\n",
    "        feature_importances = np.mean(pd.DataFrame(LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='zero')),axis= 0)\n",
    "        print(feature_importances)\n",
    "        \n",
    "#         feature_importanes= pd.DataFrame({f\"F{model_input_feature}\" : feature_importances.values}, index = [f'N{s}' for s in range(9)])\n",
    "        \n",
    "#         output_metrics.append([rmse, r2, mae])\n",
    "#         output_importance.append(feature_importances)\n",
    "#         epoch_logs = pd.DataFrame(epoch_logs,columns=['Epoch','Train_Loss','Val_loss','Time'])\n",
    "#         epoch_logs.to_csv(f\"LSTM_logs_allsite_1feature_batch_site{model_sites}_feature{model_input_feature}.csv\",index=False)  \n",
    "        \n",
    "#     all_output_metrics.append(pd.DataFrame(output_metrics,columns=['RMSE','R2','MAE'], index = ['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']))\n",
    "#     all_output_importance = pd.concat(output_importance,axis = 1)\n",
    "#     all_output_importance.to_csv(f\"LSTM_al1site_1feature_batch_importance_site{model_sites}.csv\",index=False)\n",
    "\n",
    "#     torch.save(lstm_model,f\"LSTM_N{target_site_index+1}_1FeatureAllSite_targetDO.pth\")\n",
    "    \n",
    "# result_output_metrics = pd.concat(all_output_metrics,axis = 1)\n",
    "\n",
    "# result_output_metrics.to_csv(f\"LSTM_al1site_1feature_batch_metrics.csv\",index=False)\n",
    "\n",
    "# all_output_metrics.to_csv(f\"LSTM_allsite_1feature_batch_metrics备用查看数据.csv\",index=False)\n",
    "#['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32ce624",
   "metadata": {},
   "source": [
    "## 所有站点所有特征all site all feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ef6e66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30642, 9, 9)\n",
      "Training with parameters: {'LSTM_input_size': 81, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 3.5644, Val Loss: 2.8110\n",
      "Epoch 2/200, Train Loss: 1.7467, Val Loss: 2.9871\n",
      "Epoch 3/200, Train Loss: 1.5520, Val Loss: 2.5800\n",
      "Epoch 4/200, Train Loss: 1.4092, Val Loss: 2.9207\n",
      "Epoch 5/200, Train Loss: 1.3192, Val Loss: 2.3488\n",
      "Epoch 6/200, Train Loss: 1.2103, Val Loss: 2.7990\n",
      "Epoch 7/200, Train Loss: 1.1642, Val Loss: 2.0542\n",
      "Epoch 8/200, Train Loss: 1.1450, Val Loss: 2.2381\n",
      "Epoch 9/200, Train Loss: 1.0917, Val Loss: 1.8651\n",
      "Epoch 10/200, Train Loss: 1.1387, Val Loss: 1.9762\n",
      "Epoch 11/200, Train Loss: 1.0953, Val Loss: 1.8019\n",
      "Epoch 12/200, Train Loss: 1.0089, Val Loss: 1.8754\n",
      "Epoch 13/200, Train Loss: 0.9826, Val Loss: 1.8519\n",
      "Epoch 14/200, Train Loss: 0.9692, Val Loss: 1.7705\n",
      "Epoch 15/200, Train Loss: 0.9370, Val Loss: 1.4801\n",
      "Epoch 16/200, Train Loss: 0.8911, Val Loss: 1.5607\n",
      "Epoch 17/200, Train Loss: 0.8699, Val Loss: 1.3855\n",
      "Epoch 18/200, Train Loss: 0.8305, Val Loss: 1.3058\n",
      "Epoch 19/200, Train Loss: 0.8287, Val Loss: 1.5612\n",
      "Epoch 20/200, Train Loss: 0.7901, Val Loss: 1.5946\n",
      "Epoch 21/200, Train Loss: 0.7980, Val Loss: 1.5873\n",
      "Epoch 22/200, Train Loss: 0.7781, Val Loss: 1.4848\n",
      "Epoch 23/200, Train Loss: 0.7486, Val Loss: 1.4783\n",
      "Epoch 24/200, Train Loss: 0.7282, Val Loss: 1.5362\n",
      "Epoch 25/200, Train Loss: 0.7009, Val Loss: 1.3324\n",
      "Epoch 26/200, Train Loss: 0.6961, Val Loss: 1.6839\n",
      "Epoch 27/200, Train Loss: 0.6678, Val Loss: 1.4422\n",
      "Epoch 28/200, Train Loss: 0.6541, Val Loss: 1.5568\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 1.5062\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.2273\n",
      "Test R2: 0.3738\n",
      "Test MAE: 0.9041\n",
      "0     0.209745\n",
      "1     0.107082\n",
      "2     0.383617\n",
      "3     0.250047\n",
      "4     0.254136\n",
      "        ...   \n",
      "76    0.425907\n",
      "77    0.015587\n",
      "78    0.007738\n",
      "79    0.000768\n",
      "80    0.011398\n",
      "Length: 81, dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 81, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 3.6479, Val Loss: 2.3945\n",
      "Epoch 2/200, Train Loss: 1.7770, Val Loss: 2.3725\n",
      "Epoch 3/200, Train Loss: 1.5653, Val Loss: 2.7274\n"
     ]
    }
   ],
   "source": [
    "#所有站点所有特征循环all site all feature \n",
    "#change the Define function input:X_origin[:,:,:,:].squeeze(),X_origin = X_origin.reshape(16,72,81),LSTM_input_size = 81\n",
    "#超参数优化\n",
    "param_grid = {\n",
    "    'LSTM_input_size' : [81],\n",
    "    'hidden_size': [64],#32,64,128\n",
    "    'num_layers': [2],#1, 2, 3\n",
    "    'learning_rate': [0.001],#0.001, 0.002, 0.005\n",
    "    'batch_size': [16],#8，16, 32\n",
    "    'dropout': [0.2],#0.1,0.2,0.3\n",
    "    'input_seq_len' : [72],#24,48,72\n",
    "    'output_seq_len' : [1]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "all_output_metrics = []\n",
    "all_output_importance = []\n",
    "folder_path = 'E:\\LYQ\\data'\n",
    "#'E:\\LYQ\\data'\n",
    "#'E:/your/data/folder_path'\n",
    "data = load_data(folder_path)\n",
    "print(data.shape)\n",
    "target_col = 2  # 目标特征（例如 特征0）,Target feature (e.g. feature 0)\n",
    "input_feature = [0,1,2,3,4,5,6,7,8]#0:WT,1:pH,2:DO,3:EC,4:TSS,5:CODMN,6:AN,7:TP,8:TN  \n",
    "target_site_index = [0,1,2,3,4,5,6,7,8]#range(9)\n",
    "\n",
    "all_output_metrics = []\n",
    "all_output_importance = []\n",
    "\n",
    "for model_sites in range(9):\n",
    "    # 模型超参数\n",
    "\n",
    "    predictions, actuals, lstm_model, test_loader, epoch_logs = LSTM_train_and_evaluate(data,param_grid, datay_site, target_site_index, target_col, input_feature)\n",
    "    #Calculate accuracy\n",
    "    # 计算精度\n",
    "    rmse, r2, mae = calculate_metrics(predictions, actuals)\n",
    "    #result\n",
    "    # 输出结果\n",
    "    print(f\"predictions shape: {predictions.shape}\")\n",
    "    print(f\"actuals shape: {actuals.shape}\")\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test R2: {r2:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    feature_importances = np.mean(pd.DataFrame(LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='zero')),axis= 0)\n",
    "    print(feature_importances)\n",
    "\n",
    "    all_output_metrics.append([rmse, r2, mae])\n",
    "    all_output_importance.append(pd.DataFrame({f\"N{model_sites}\" : feature_importances.values}, index=[f'F{s}' for s in range(81)]))\n",
    "    epoch_logs = pd.DataFrame(epoch_logs,columns=['Epoch','Train_Loss','Val_loss','Time'])\n",
    "    epoch_logs.to_csv(f\"LSTM_logs_allsiteallfeature_batch_site{model_sites}.csv\",index=False)\n",
    "    torch.save(lstm_model,f\"LSTM_N{target_site_index+1}_AllFeatureAllSite_targetDO.pth\")\n",
    "    \n",
    "result_output_metrics = pd.DataFrame(output_metrics,columns=['RMSE','R2','MAE'])\n",
    "result_output_importance = pd.concat(all_output_importance,axis = 1)\n",
    "\n",
    "result_output_metrics.to_csv(f\"LSTM_allsiteallfeature_batch_metrics_.csv\",index=False)\n",
    "result_output_importance.to_csv(f\"LSTM_1siteallfeature_logs_one_batch_importance.csv\",index=False)\n",
    "# all_output_importance.to_csv(f\"LSTM_allsiteallfeature_logs_one_batch_importance备用查看数据.csv\",index=False)\n",
    "#['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47c34a",
   "metadata": {},
   "source": [
    "## 低氧情境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a976be6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30642, 9, 9)\n",
      "Training with parameters: {'LSTM_input_size': 9, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 2.8349, Val Loss: 0.2447\n",
      "Epoch 2/200, Train Loss: 0.4510, Val Loss: 0.0691\n",
      "Epoch 3/200, Train Loss: 0.4116, Val Loss: 0.0978\n",
      "Epoch 4/200, Train Loss: 0.3905, Val Loss: 0.1160\n",
      "Epoch 5/200, Train Loss: 0.3871, Val Loss: 0.1017\n",
      "Epoch 6/200, Train Loss: 0.3666, Val Loss: 0.0684\n",
      "Epoch 7/200, Train Loss: 0.3531, Val Loss: 0.0970\n",
      "Epoch 8/200, Train Loss: 0.3349, Val Loss: 0.0639\n",
      "Epoch 9/200, Train Loss: 0.3214, Val Loss: 0.1410\n",
      "Epoch 10/200, Train Loss: 0.3130, Val Loss: 0.0686\n",
      "Epoch 11/200, Train Loss: 0.3022, Val Loss: 0.0664\n",
      "Epoch 12/200, Train Loss: 0.2891, Val Loss: 0.0808\n",
      "Epoch 13/200, Train Loss: 0.2803, Val Loss: 0.1091\n",
      "Epoch 14/200, Train Loss: 0.2735, Val Loss: 0.0813\n",
      "Epoch 15/200, Train Loss: 0.2612, Val Loss: 0.0608\n",
      "Epoch 16/200, Train Loss: 0.2455, Val Loss: 0.0626\n",
      "Epoch 17/200, Train Loss: 0.2331, Val Loss: 0.0837\n",
      "Epoch 18/200, Train Loss: 0.2291, Val Loss: 0.0628\n",
      "Epoch 19/200, Train Loss: 0.2243, Val Loss: 0.0691\n",
      "Epoch 20/200, Train Loss: 0.2129, Val Loss: 0.0756\n",
      "Epoch 21/200, Train Loss: 0.2045, Val Loss: 0.0679\n",
      "Epoch 22/200, Train Loss: 0.2003, Val Loss: 0.0717\n",
      "Epoch 23/200, Train Loss: 0.1901, Val Loss: 0.0707\n",
      "Epoch 24/200, Train Loss: 0.1864, Val Loss: 0.0687\n",
      "Epoch 25/200, Train Loss: 0.1794, Val Loss: 0.0756\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 0.0778\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.2789\n",
      "Test R2: 0.9677\n",
      "Test MAE: 0.1638\n",
      "N0总特征重要性：\n",
      "0    2.365123\n",
      "1    0.641863\n",
      "2    0.143120\n",
      "3    0.133755\n",
      "4    0.120677\n",
      "5    0.204297\n",
      "6    0.110179\n",
      "7    0.122114\n",
      "8    0.188694\n",
      "dtype: float32\n",
      "torch.Size([1, 72, 9, 9])\n",
      "N0低氧情境特征重要性：\n",
      "0    2.400133\n",
      "1    0.621754\n",
      "2    0.141328\n",
      "3    0.133242\n",
      "4    0.120083\n",
      "5    0.202658\n",
      "6    0.110394\n",
      "7    0.121184\n",
      "8    0.187051\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 9, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 1.8598, Val Loss: 0.1389\n",
      "Epoch 2/200, Train Loss: 0.3445, Val Loss: 0.1552\n",
      "Epoch 3/200, Train Loss: 0.3280, Val Loss: 0.1095\n",
      "Epoch 4/200, Train Loss: 0.3132, Val Loss: 0.0949\n",
      "Epoch 5/200, Train Loss: 0.3010, Val Loss: 0.0570\n",
      "Epoch 6/200, Train Loss: 0.2808, Val Loss: 0.0934\n",
      "Epoch 7/200, Train Loss: 0.2817, Val Loss: 0.0918\n",
      "Epoch 8/200, Train Loss: 0.2604, Val Loss: 0.1119\n",
      "Epoch 9/200, Train Loss: 0.2513, Val Loss: 0.0555\n",
      "Epoch 10/200, Train Loss: 0.2451, Val Loss: 0.0530\n",
      "Epoch 11/200, Train Loss: 0.2320, Val Loss: 0.0930\n",
      "Epoch 12/200, Train Loss: 0.2237, Val Loss: 0.0666\n",
      "Epoch 13/200, Train Loss: 0.2149, Val Loss: 0.0624\n",
      "Epoch 14/200, Train Loss: 0.2097, Val Loss: 0.0650\n",
      "Epoch 15/200, Train Loss: 0.2001, Val Loss: 0.0595\n",
      "Epoch 16/200, Train Loss: 0.1932, Val Loss: 0.0750\n",
      "Epoch 17/200, Train Loss: 0.1849, Val Loss: 0.0564\n",
      "Epoch 18/200, Train Loss: 0.1817, Val Loss: 0.0511\n",
      "Epoch 19/200, Train Loss: 0.1717, Val Loss: 0.0610\n",
      "Epoch 20/200, Train Loss: 0.1692, Val Loss: 0.0529\n",
      "Epoch 21/200, Train Loss: 0.1646, Val Loss: 0.0574\n",
      "Epoch 22/200, Train Loss: 0.1578, Val Loss: 0.0485\n",
      "Epoch 23/200, Train Loss: 0.1534, Val Loss: 0.0495\n",
      "Epoch 24/200, Train Loss: 0.1486, Val Loss: 0.0628\n",
      "Epoch 25/200, Train Loss: 0.1415, Val Loss: 0.0597\n",
      "Epoch 26/200, Train Loss: 0.1395, Val Loss: 0.0580\n",
      "Epoch 27/200, Train Loss: 0.1346, Val Loss: 0.0642\n",
      "Epoch 28/200, Train Loss: 0.1327, Val Loss: 0.0787\n",
      "Epoch 29/200, Train Loss: 0.1257, Val Loss: 0.0511\n",
      "Epoch 30/200, Train Loss: 0.1256, Val Loss: 0.0479\n",
      "Epoch 31/200, Train Loss: 0.1233, Val Loss: 0.0663\n",
      "Epoch 32/200, Train Loss: 0.1191, Val Loss: 0.0486\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 0.1070\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.3270\n",
      "Test R2: 0.9401\n",
      "Test MAE: 0.1921\n",
      "N1总特征重要性：\n",
      "0    0.398842\n",
      "1    1.907602\n",
      "2    0.152788\n",
      "3    0.192435\n",
      "4    0.133427\n",
      "5    0.206826\n",
      "6    0.080342\n",
      "7    0.101536\n",
      "8    0.230643\n",
      "dtype: float32\n",
      "torch.Size([1, 72, 9, 9])\n",
      "N1低氧情境特征重要性：\n",
      "0    0.397303\n",
      "1    1.944119\n",
      "2    0.151286\n",
      "3    0.193552\n",
      "4    0.132479\n",
      "5    0.217660\n",
      "6    0.078933\n",
      "7    0.101315\n",
      "8    0.232081\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 9, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 1.4377, Val Loss: 0.2149\n",
      "Epoch 2/200, Train Loss: 0.4011, Val Loss: 0.1976\n",
      "Epoch 3/200, Train Loss: 0.3880, Val Loss: 0.2192\n",
      "Epoch 4/200, Train Loss: 0.3740, Val Loss: 0.1965\n",
      "Epoch 5/200, Train Loss: 0.3513, Val Loss: 0.2531\n",
      "Epoch 6/200, Train Loss: 0.3415, Val Loss: 0.2257\n",
      "Epoch 7/200, Train Loss: 0.3439, Val Loss: 0.1903\n",
      "Epoch 8/200, Train Loss: 0.3278, Val Loss: 0.2284\n",
      "Epoch 9/200, Train Loss: 0.3238, Val Loss: 0.1959\n",
      "Epoch 10/200, Train Loss: 0.3128, Val Loss: 0.1836\n",
      "Epoch 11/200, Train Loss: 0.3067, Val Loss: 0.2675\n",
      "Epoch 12/200, Train Loss: 0.2909, Val Loss: 0.1808\n",
      "Epoch 13/200, Train Loss: 0.2973, Val Loss: 0.1670\n",
      "Epoch 14/200, Train Loss: 0.2855, Val Loss: 0.1928\n",
      "Epoch 15/200, Train Loss: 0.2761, Val Loss: 0.1835\n",
      "Epoch 16/200, Train Loss: 0.2699, Val Loss: 0.1890\n",
      "Epoch 17/200, Train Loss: 0.2687, Val Loss: 0.1675\n",
      "Epoch 18/200, Train Loss: 0.2567, Val Loss: 0.1610\n",
      "Epoch 19/200, Train Loss: 0.2593, Val Loss: 0.1667\n",
      "Epoch 20/200, Train Loss: 0.2580, Val Loss: 0.1546\n",
      "Epoch 21/200, Train Loss: 0.2405, Val Loss: 0.1795\n",
      "Epoch 22/200, Train Loss: 0.2469, Val Loss: 0.1678\n",
      "Epoch 23/200, Train Loss: 0.2373, Val Loss: 0.1663\n",
      "Epoch 24/200, Train Loss: 0.2373, Val Loss: 0.1615\n",
      "Epoch 25/200, Train Loss: 0.2306, Val Loss: 0.1715\n",
      "Epoch 26/200, Train Loss: 0.2314, Val Loss: 0.2037\n",
      "Epoch 27/200, Train Loss: 0.2246, Val Loss: 0.1537\n",
      "Epoch 28/200, Train Loss: 0.2204, Val Loss: 0.1638\n",
      "Epoch 29/200, Train Loss: 0.2196, Val Loss: 0.1776\n",
      "Epoch 30/200, Train Loss: 0.2165, Val Loss: 0.1627\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 0.3185\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.5644\n",
      "Test R2: 0.9426\n",
      "Test MAE: 0.3464\n",
      "N2总特征重要性：\n",
      "0    0.301755\n",
      "1    0.467454\n",
      "2    2.377898\n",
      "3    0.458241\n",
      "4    0.210106\n",
      "5    0.198586\n",
      "6    0.200758\n",
      "7    0.172804\n",
      "8    0.334169\n",
      "dtype: float32\n",
      "torch.Size([153, 72, 9, 9])\n",
      "N2低氧情境特征重要性：\n",
      "0    0.303493\n",
      "1    0.463163\n",
      "2    2.436973\n",
      "3    0.462187\n",
      "4    0.206999\n",
      "5    0.202322\n",
      "6    0.202810\n",
      "7    0.175116\n",
      "8    0.331913\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 9, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 1.5858, Val Loss: 0.1901\n",
      "Epoch 2/200, Train Loss: 0.3854, Val Loss: 0.1942\n",
      "Epoch 3/200, Train Loss: 0.3643, Val Loss: 0.2083\n",
      "Epoch 4/200, Train Loss: 0.3538, Val Loss: 0.2135\n",
      "Epoch 5/200, Train Loss: 0.3411, Val Loss: 0.1620\n",
      "Epoch 6/200, Train Loss: 0.3274, Val Loss: 0.2190\n",
      "Epoch 7/200, Train Loss: 0.3178, Val Loss: 0.1395\n",
      "Epoch 8/200, Train Loss: 0.3021, Val Loss: 0.2164\n",
      "Epoch 9/200, Train Loss: 0.2965, Val Loss: 0.1362\n",
      "Epoch 10/200, Train Loss: 0.2858, Val Loss: 0.1455\n",
      "Epoch 11/200, Train Loss: 0.2786, Val Loss: 0.1495\n",
      "Epoch 12/200, Train Loss: 0.2723, Val Loss: 0.1655\n",
      "Epoch 13/200, Train Loss: 0.2693, Val Loss: 0.1536\n",
      "Epoch 14/200, Train Loss: 0.2566, Val Loss: 0.1531\n",
      "Epoch 15/200, Train Loss: 0.2503, Val Loss: 0.1641\n",
      "Epoch 16/200, Train Loss: 0.2441, Val Loss: 0.1395\n",
      "Epoch 17/200, Train Loss: 0.2346, Val Loss: 0.1478\n",
      "Epoch 18/200, Train Loss: 0.2311, Val Loss: 0.1388\n",
      "Epoch 19/200, Train Loss: 0.2258, Val Loss: 0.1454\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 0.0949\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.3080\n",
      "Test R2: 0.9747\n",
      "Test MAE: 0.1872\n",
      "N3总特征重要性：\n",
      "0    0.308157\n",
      "1    0.570238\n",
      "2    0.240271\n",
      "3    1.993719\n",
      "4    0.354047\n",
      "5    0.382082\n",
      "6    0.220494\n",
      "7    0.208010\n",
      "8    0.293519\n",
      "dtype: float32\n",
      "torch.Size([57, 72, 9, 9])\n",
      "N3低氧情境特征重要性：\n",
      "0    0.305856\n",
      "1    0.576071\n",
      "2    0.237540\n",
      "3    1.955534\n",
      "4    0.351741\n",
      "5    0.370966\n",
      "6    0.214097\n",
      "7    0.205138\n",
      "8    0.299002\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 9, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 1.0546, Val Loss: 0.1319\n",
      "Epoch 2/200, Train Loss: 0.2937, Val Loss: 0.1463\n",
      "Epoch 3/200, Train Loss: 0.2647, Val Loss: 0.1496\n",
      "Epoch 4/200, Train Loss: 0.2338, Val Loss: 0.0973\n",
      "Epoch 5/200, Train Loss: 0.2156, Val Loss: 0.1100\n",
      "Epoch 6/200, Train Loss: 0.2037, Val Loss: 0.0981\n",
      "Epoch 7/200, Train Loss: 0.1973, Val Loss: 0.0971\n",
      "Epoch 8/200, Train Loss: 0.1907, Val Loss: 0.0925\n",
      "Epoch 9/200, Train Loss: 0.1821, Val Loss: 0.1020\n",
      "Epoch 10/200, Train Loss: 0.1767, Val Loss: 0.1131\n",
      "Epoch 11/200, Train Loss: 0.1675, Val Loss: 0.1238\n",
      "Epoch 12/200, Train Loss: 0.1661, Val Loss: 0.1019\n",
      "Epoch 13/200, Train Loss: 0.1615, Val Loss: 0.1144\n",
      "Epoch 14/200, Train Loss: 0.1569, Val Loss: 0.1237\n",
      "Epoch 15/200, Train Loss: 0.1516, Val Loss: 0.1297\n",
      "Epoch 16/200, Train Loss: 0.1486, Val Loss: 0.0881\n",
      "Epoch 17/200, Train Loss: 0.1452, Val Loss: 0.0988\n",
      "Epoch 18/200, Train Loss: 0.1407, Val Loss: 0.1016\n",
      "Epoch 19/200, Train Loss: 0.1386, Val Loss: 0.0989\n",
      "Epoch 20/200, Train Loss: 0.1346, Val Loss: 0.1105\n",
      "Epoch 21/200, Train Loss: 0.1338, Val Loss: 0.1202\n",
      "Epoch 22/200, Train Loss: 0.1318, Val Loss: 0.1039\n",
      "Epoch 23/200, Train Loss: 0.1298, Val Loss: 0.0892\n",
      "Epoch 24/200, Train Loss: 0.1281, Val Loss: 0.1031\n",
      "Epoch 25/200, Train Loss: 0.1250, Val Loss: 0.1208\n",
      "Epoch 26/200, Train Loss: 0.1260, Val Loss: 0.1192\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 0.1220\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.3492\n",
      "Test R2: 0.9737\n",
      "Test MAE: 0.2581\n",
      "N4总特征重要性：\n",
      "0    0.324310\n",
      "1    0.248812\n",
      "2    0.201231\n",
      "3    0.380384\n",
      "4    1.631742\n",
      "5    0.264108\n",
      "6    0.193317\n",
      "7    0.172368\n",
      "8    0.216604\n",
      "dtype: float32\n",
      "torch.Size([1681, 72, 9, 9])\n",
      "N4低氧情境特征重要性：\n",
      "0    0.321926\n",
      "1    0.243336\n",
      "2    0.197633\n",
      "3    0.364647\n",
      "4    1.617713\n",
      "5    0.264567\n",
      "6    0.192893\n",
      "7    0.169160\n",
      "8    0.218427\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 9, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 1.4010, Val Loss: 0.1862\n",
      "Epoch 2/200, Train Loss: 0.3526, Val Loss: 0.0667\n",
      "Epoch 3/200, Train Loss: 0.3272, Val Loss: 0.0766\n",
      "Epoch 4/200, Train Loss: 0.3217, Val Loss: 0.0828\n",
      "Epoch 5/200, Train Loss: 0.3079, Val Loss: 0.0617\n",
      "Epoch 6/200, Train Loss: 0.2980, Val Loss: 0.1045\n",
      "Epoch 7/200, Train Loss: 0.2859, Val Loss: 0.0733\n",
      "Epoch 8/200, Train Loss: 0.2840, Val Loss: 0.0589\n",
      "Epoch 9/200, Train Loss: 0.2744, Val Loss: 0.0522\n",
      "Epoch 10/200, Train Loss: 0.2643, Val Loss: 0.0541\n",
      "Epoch 11/200, Train Loss: 0.2558, Val Loss: 0.0422\n",
      "Epoch 12/200, Train Loss: 0.2488, Val Loss: 0.0684\n",
      "Epoch 13/200, Train Loss: 0.2442, Val Loss: 0.0775\n",
      "Epoch 14/200, Train Loss: 0.2344, Val Loss: 0.0502\n",
      "Epoch 15/200, Train Loss: 0.2313, Val Loss: 0.0498\n",
      "Epoch 16/200, Train Loss: 0.2273, Val Loss: 0.0618\n",
      "Epoch 17/200, Train Loss: 0.2168, Val Loss: 0.0459\n",
      "Epoch 18/200, Train Loss: 0.2131, Val Loss: 0.0513\n",
      "Epoch 19/200, Train Loss: 0.2093, Val Loss: 0.0470\n",
      "Epoch 20/200, Train Loss: 0.2072, Val Loss: 0.0479\n",
      "Epoch 21/200, Train Loss: 0.2016, Val Loss: 0.0581\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 0.0659\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.2567\n",
      "Test R2: 0.9796\n",
      "Test MAE: 0.1710\n",
      "N5总特征重要性：\n",
      "0    0.246614\n",
      "1    0.306975\n",
      "2    0.137304\n",
      "3    0.170948\n",
      "4    0.147149\n",
      "5    1.951385\n",
      "6    0.216256\n",
      "7    0.141254\n",
      "8    0.217675\n",
      "dtype: float32\n",
      "torch.Size([40, 72, 9, 9])\n",
      "N5低氧情境特征重要性：\n",
      "0    0.249129\n",
      "1    0.309755\n",
      "2    0.139707\n",
      "3    0.171213\n",
      "4    0.148203\n",
      "5    1.948179\n",
      "6    0.210317\n",
      "7    0.140593\n",
      "8    0.213371\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 9, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 1.1134, Val Loss: 0.1464\n",
      "Epoch 2/200, Train Loss: 0.4437, Val Loss: 0.1360\n",
      "Epoch 3/200, Train Loss: 0.4370, Val Loss: 0.2204\n",
      "Epoch 4/200, Train Loss: 0.4165, Val Loss: 0.1546\n",
      "Epoch 5/200, Train Loss: 0.4058, Val Loss: 0.1339\n",
      "Epoch 6/200, Train Loss: 0.4047, Val Loss: 0.1423\n",
      "Epoch 7/200, Train Loss: 0.3921, Val Loss: 0.2489\n",
      "Epoch 8/200, Train Loss: 0.3899, Val Loss: 0.1318\n",
      "Epoch 9/200, Train Loss: 0.3799, Val Loss: 0.1305\n",
      "Epoch 10/200, Train Loss: 0.3735, Val Loss: 0.1467\n",
      "Epoch 11/200, Train Loss: 0.3751, Val Loss: 0.1381\n",
      "Epoch 12/200, Train Loss: 0.3625, Val Loss: 0.1343\n",
      "Epoch 13/200, Train Loss: 0.3585, Val Loss: 0.1340\n",
      "Epoch 14/200, Train Loss: 0.3577, Val Loss: 0.1444\n",
      "Epoch 15/200, Train Loss: 0.3484, Val Loss: 0.1733\n",
      "Epoch 16/200, Train Loss: 0.3465, Val Loss: 0.1323\n",
      "Epoch 17/200, Train Loss: 0.3386, Val Loss: 0.1424\n",
      "Epoch 18/200, Train Loss: 0.3386, Val Loss: 0.1276\n",
      "Epoch 19/200, Train Loss: 0.3324, Val Loss: 0.1837\n",
      "Epoch 20/200, Train Loss: 0.3324, Val Loss: 0.1291\n",
      "Epoch 21/200, Train Loss: 0.3293, Val Loss: 0.1347\n",
      "Epoch 22/200, Train Loss: 0.3207, Val Loss: 0.1321\n",
      "Epoch 23/200, Train Loss: 0.3211, Val Loss: 0.1334\n",
      "Epoch 24/200, Train Loss: 0.3186, Val Loss: 0.1428\n",
      "Epoch 25/200, Train Loss: 0.3153, Val Loss: 0.1305\n",
      "Epoch 26/200, Train Loss: 0.3123, Val Loss: 0.1442\n",
      "Epoch 27/200, Train Loss: 0.3149, Val Loss: 0.1514\n",
      "Epoch 28/200, Train Loss: 0.3076, Val Loss: 0.1477\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 0.1501\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.3875\n",
      "Test R2: 0.9389\n",
      "Test MAE: 0.2853\n",
      "N6总特征重要性：\n",
      "0    0.327719\n",
      "1    0.241151\n",
      "2    0.146248\n",
      "3    0.306585\n",
      "4    0.145700\n",
      "5    0.403214\n",
      "6    1.986608\n",
      "7    0.308633\n",
      "8    0.251179\n",
      "dtype: float32\n",
      "torch.Size([180, 72, 9, 9])\n",
      "N6低氧情境特征重要性：\n",
      "0    0.326222\n",
      "1    0.244237\n",
      "2    0.143788\n",
      "3    0.308802\n",
      "4    0.145653\n",
      "5    0.409349\n",
      "6    2.022896\n",
      "7    0.306678\n",
      "8    0.252243\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 9, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 1.2085, Val Loss: 0.3032\n",
      "Epoch 2/200, Train Loss: 0.4875, Val Loss: 0.2917\n",
      "Epoch 3/200, Train Loss: 0.4781, Val Loss: 0.2717\n",
      "Epoch 4/200, Train Loss: 0.4580, Val Loss: 0.2641\n",
      "Epoch 5/200, Train Loss: 0.4451, Val Loss: 0.3170\n",
      "Epoch 6/200, Train Loss: 0.4474, Val Loss: 0.2517\n",
      "Epoch 7/200, Train Loss: 0.4288, Val Loss: 0.2508\n",
      "Epoch 8/200, Train Loss: 0.4163, Val Loss: 0.2541\n",
      "Epoch 9/200, Train Loss: 0.4096, Val Loss: 0.2654\n",
      "Epoch 10/200, Train Loss: 0.3973, Val Loss: 0.2505\n",
      "Epoch 11/200, Train Loss: 0.3957, Val Loss: 0.3174\n",
      "Epoch 12/200, Train Loss: 0.3885, Val Loss: 0.2526\n",
      "Epoch 13/200, Train Loss: 0.3896, Val Loss: 0.2566\n",
      "Epoch 14/200, Train Loss: 0.3746, Val Loss: 0.2525\n",
      "Epoch 15/200, Train Loss: 0.3728, Val Loss: 0.2891\n",
      "Epoch 16/200, Train Loss: 0.3674, Val Loss: 0.2777\n",
      "Epoch 17/200, Train Loss: 0.3655, Val Loss: 0.2654\n",
      "Epoch 18/200, Train Loss: 0.3537, Val Loss: 0.2563\n",
      "Epoch 19/200, Train Loss: 0.3531, Val Loss: 0.2494\n",
      "Epoch 20/200, Train Loss: 0.3469, Val Loss: 0.2600\n",
      "Epoch 21/200, Train Loss: 0.3460, Val Loss: 0.2566\n",
      "Epoch 22/200, Train Loss: 0.3404, Val Loss: 0.2522\n",
      "Epoch 23/200, Train Loss: 0.3447, Val Loss: 0.3224\n",
      "Epoch 24/200, Train Loss: 0.3372, Val Loss: 0.2585\n",
      "Epoch 25/200, Train Loss: 0.3289, Val Loss: 0.2652\n",
      "Epoch 26/200, Train Loss: 0.3285, Val Loss: 0.2544\n",
      "Epoch 27/200, Train Loss: 0.3212, Val Loss: 0.2757\n",
      "Epoch 28/200, Train Loss: 0.3177, Val Loss: 0.2815\n",
      "Epoch 29/200, Train Loss: 0.3159, Val Loss: 0.2714\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 0.1333\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.3650\n",
      "Test R2: 0.9421\n",
      "Test MAE: 0.2322\n",
      "N7总特征重要性：\n",
      "0    0.555150\n",
      "1    0.444488\n",
      "2    0.260301\n",
      "3    0.210353\n",
      "4    0.165618\n",
      "5    0.217368\n",
      "6    0.389978\n",
      "7    1.683561\n",
      "8    0.294044\n",
      "dtype: float32\n",
      "torch.Size([333, 72, 9, 9])\n",
      "N7低氧情境特征重要性：\n",
      "0    0.542298\n",
      "1    0.441755\n",
      "2    0.260022\n",
      "3    0.206566\n",
      "4    0.164024\n",
      "5    0.216494\n",
      "6    0.394983\n",
      "7    1.699731\n",
      "8    0.297167\n",
      "dtype: float32\n",
      "Training with parameters: {'LSTM_input_size': 9, 'batch_size': 16, 'dropout': 0.2, 'hidden_size': 64, 'input_seq_len': 72, 'learning_rate': 0.001, 'num_layers': 2, 'output_seq_len': 1}\n",
      "Epoch 1/200, Train Loss: 0.9333, Val Loss: 0.2501\n",
      "Epoch 2/200, Train Loss: 0.2383, Val Loss: 0.1443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Train Loss: 0.2367, Val Loss: 0.0953\n",
      "Epoch 4/200, Train Loss: 0.2136, Val Loss: 0.1408\n",
      "Epoch 5/200, Train Loss: 0.2132, Val Loss: 0.1026\n",
      "Epoch 6/200, Train Loss: 0.2014, Val Loss: 0.0981\n",
      "Epoch 7/200, Train Loss: 0.1966, Val Loss: 0.0983\n",
      "Epoch 8/200, Train Loss: 0.1883, Val Loss: 0.0979\n",
      "Epoch 9/200, Train Loss: 0.1818, Val Loss: 0.0953\n",
      "Epoch 10/200, Train Loss: 0.1775, Val Loss: 0.1006\n",
      "Epoch 11/200, Train Loss: 0.1712, Val Loss: 0.0895\n",
      "Epoch 12/200, Train Loss: 0.1648, Val Loss: 0.0927\n",
      "Epoch 13/200, Train Loss: 0.1619, Val Loss: 0.0889\n",
      "Epoch 14/200, Train Loss: 0.1573, Val Loss: 0.0944\n",
      "Epoch 15/200, Train Loss: 0.1555, Val Loss: 0.0950\n",
      "Epoch 16/200, Train Loss: 0.1482, Val Loss: 0.0986\n",
      "Epoch 17/200, Train Loss: 0.1454, Val Loss: 0.0966\n",
      "Epoch 18/200, Train Loss: 0.1449, Val Loss: 0.0886\n",
      "Epoch 19/200, Train Loss: 0.1402, Val Loss: 0.0896\n",
      "Epoch 20/200, Train Loss: 0.1378, Val Loss: 0.0970\n",
      "Epoch 21/200, Train Loss: 0.1368, Val Loss: 0.0937\n",
      "Early stopping triggered.\n",
      "Model restored to the best validation state.\n",
      "Test MSE: 0.0833\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.2887\n",
      "Test R2: 0.9776\n",
      "Test MAE: 0.2038\n",
      "N8总特征重要性：\n",
      "0    0.198263\n",
      "1    0.252184\n",
      "2    0.257778\n",
      "3    0.143684\n",
      "4    0.145043\n",
      "5    0.306592\n",
      "6    0.220425\n",
      "7    0.205134\n",
      "8    1.588480\n",
      "dtype: float32\n",
      "torch.Size([1818, 72, 9, 9])\n",
      "N8低氧情境特征重要性：\n",
      "0    0.200368\n",
      "1    0.255153\n",
      "2    0.248318\n",
      "3    0.143961\n",
      "4    0.138250\n",
      "5    0.309935\n",
      "6    0.225773\n",
      "7    0.205278\n",
      "8    1.534903\n",
      "dtype: float32\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(feature_importances)\n\u001b[0;32m     65\u001b[0m     feature_importances_lowDO\u001b[38;5;241m.\u001b[39mappend(pd\u001b[38;5;241m.\u001b[39mDataFrame(feature_importances\u001b[38;5;241m.\u001b[39mvalues))\n\u001b[1;32m---> 67\u001b[0m feature_importances_all \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_importances_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m feature_importances_lowDO \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(feature_importances_lowDO,axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     69\u001b[0m feature_importances_all\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_importances_all.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)   \n",
      "File \u001b[1;32mD:\\anaconda\\envs\\GNN\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\GNN\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\GNN\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:425\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    422\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    428\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "#所有站点单特征循环all site single feature\n",
    "#change the Define function input:X_origin[:,:,:,input_feature].squeeze(),LSTM_input_size = 9\n",
    "#超参数优化\n",
    "param_grid = {\n",
    "    'LSTM_input_size' : [9],\n",
    "    'hidden_size': [64],#32,64,128\n",
    "    'num_layers': [2],#1, 2, 3\n",
    "    'learning_rate': [0.001],#0.001, 0.002, 0.005\n",
    "    'batch_size': [16],#8，16, 32\n",
    "    'dropout': [0.2],#0.1,0.2,0.3\n",
    "    'input_seq_len' : [72],#24,48,72\n",
    "    'output_seq_len' : [1]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "feature_importances_all = []\n",
    "feature_importances_lowDO = []\n",
    "folder_path = 'E:\\LYQ\\data'\n",
    "#'E:\\LYQ\\data'\n",
    "#'E:/your/data/folder_path'\n",
    "data = load_data(folder_path)\n",
    "print(data.shape)\n",
    "target_col = 2  # 目标特征（例如 特征0）,Target feature (e.g. feature 0)\n",
    "target_site_index = [0,1,2,3,4,5,6,7,8]#range(9)\n",
    "\n",
    "for model_sites in range(9):\n",
    "    #Model hyperparameters\n",
    "    # 模型超参数\n",
    "    datay_site = model_sites\n",
    "\n",
    "    input_feature = 2#0:WT,1:pH,2:DO,3:EC,4:TSS,5:CODMN,6:AN,7:TP,8:TN\n",
    "\n",
    "    predictions, actuals, lstm_model, test_loader, epoch_logs = LSTM_train_and_evaluate(data,param_grid, datay_site, target_site_index, target_col, input_feature)\n",
    "    #Calculate accuracy\n",
    "    # 计算精度\n",
    "    rmse, r2, mae = calculate_metrics(predictions, actuals)\n",
    "    #result\n",
    "    # 输出结果\n",
    "    print(f\"predictions shape: {predictions.shape}\")\n",
    "    print(f\"actuals shape: {actuals.shape}\")\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test R2: {r2:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    feature_importances = np.mean(pd.DataFrame(LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='noise')),axis= 0)\n",
    "    print(f\"N{model_sites+1}总特征重要性：\")\n",
    "    print(feature_importances)   \n",
    "    \n",
    "    #数据划分\n",
    "    X, y = create_sequences(data, 72, 1, datay_site, target_col)\n",
    "    y = y.squeeze((-1,-2))\n",
    "        \n",
    "    mask = y.squeeze()<2\n",
    "    X_filtered = X[mask]\n",
    "    y_filtered = y[mask]\n",
    "    X_filtered,y_filtered = to_tensor(X_filtered),to_tensor(y_filtered)\n",
    "    print(X_filtered.shape)\n",
    "    if X_filtered.shape[0]<5:\n",
    "        continue\n",
    "    dataset_filtered = TensorDataset(X_filtered, y_filtered)\n",
    "    loader_filtered = DataLoader(dataset_filtered, batch_size=16, shuffle=True)\n",
    "    \n",
    "    feature_importances = np.mean(pd.DataFrame(LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='noise')),axis= 0)\n",
    "    print(f\"N{model_sites+1}低氧情境特征重要性：\")\n",
    "    print(feature_importances)\n",
    "    feature_importances_lowDO.append(pd.DataFrame(feature_importances.values))\n",
    "    \n",
    "feature_importances_all = pd.concat(feature_importances_all,axis = 1)\n",
    "feature_importances_lowDO = pd.concat(feature_importances_lowDO,axis = 1)\n",
    "feature_importances_all.to_csv(f\"feature_importances_all.csv\",index=False)   \n",
    "feature_importances_lowDO.to_csv(f\"feature_importances_lowDO.csv\",index=False)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f944f1",
   "metadata": {},
   "source": [
    "## 其他other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(test_loader)  # 创建一个迭代器\n",
    "X_sample, y_sample = next(data_iter)  # 获取一个批次数据\n",
    "print(X_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a6261f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GNN]",
   "language": "python",
   "name": "conda-env-GNN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
