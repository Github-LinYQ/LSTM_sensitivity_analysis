{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "910d412a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 前期准备preparation in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6bd1134",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "import time\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fd0176",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set random seeds to ensure reproducibility\n",
    "# 设置随机种子以保证可复现\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200ca661",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30642, 9, 9)\n"
     ]
    }
   ],
   "source": [
    "#加载数据\n",
    "def load_data(folder_path):\n",
    "    # Retrieve all CSV files from the folder\n",
    "    # 获取文件夹中的所有 CSV 文件\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]  \n",
    "    # List used to store data\n",
    "    # 用来存放数据的列表\n",
    "    data_list = []  \n",
    "    \n",
    "    for file_name in csv_files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        # Read CSV file\n",
    "        # 读取 CSV 文件\n",
    "        df = pd.read_csv(file_path,encoding='gbk') \n",
    "        #Only the first and tenth columns of data (including label data) have been selected here and can be freely adjusted\n",
    "        #这里只选中了第1列与第10列数据（包括标签数据），可自由调整\n",
    "        select_data=df.iloc[:,1:10]\n",
    "        #Assuming that the number of rows in each file is seq_1en and the number of columns is feature_stize\n",
    "        # 假设每个文件的行数是 seq_len，列数是 feature_size\n",
    "        seq_len = select_data.shape[0]  \n",
    "        feature_size = select_data.shape[1]  \n",
    "        #Convert DataFrame to NumPy array\n",
    "        # 将 DataFrame 转换为 NumPy 数组\n",
    "        data = select_data.to_numpy()\n",
    "        #Add data to data_ist\n",
    "        # 将数据添加到 data_list 中\n",
    "        data_list.append(data)\n",
    "    #Concatenate the data of all files into a large NumPy array\n",
    "    # 将所有文件的数据拼接成一个大的 NumPy 数组\n",
    "    data_array = np.array(data_list)  # shape: (site_size, seq_len, feature_size)\n",
    "    data_array = data_array.transpose(1,0,2)# shape: (seq_len, site_size, feature_size)\n",
    "    return data_array\n",
    "folder_path = 'E:/your/data/folder_path'\n",
    "data = load_data(folder_path)\n",
    "print(data.shape)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "311b353e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# EarlyStopping，patience:allowing the maximum number of training epochs without improvement in validation loss; delta： When the validation loss improves delta at least compared to the optimal loss, it is considered to have improved\n",
    "# 早停机制,patience验证损失未改善情况下允许训练的最大次数；delta：当验证损失比最佳损失至少改善delta则认为有所改善\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ea27d4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (30570, 72, 9, 9)\n",
      "y shape: (30570, 1)\n",
      "X_batch shape: torch.Size([16, 72, 9, 9])\n",
      "y_batch shape: torch.Size([16, 1])\n",
      "torch.Size([16, 72, 9, 9])\n",
      "torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "#Create a sliding window\n",
    "#制作滑动窗口\n",
    "def create_sequences(data, input_seq_len, output_seq_len, target_site_index, target_col):\n",
    "    X, y = [], []\n",
    "    #Traverse all possible sequences\n",
    "    # 遍历所有可能的序列\n",
    "    for i in range(len(data) - input_seq_len - output_seq_len + 1):  # len(data) 是 seq_len\n",
    "        #Create input data，shape:(site_size=9, input_seq_len=72, feature_size=9)\n",
    "        # 制作输入序列数据，形状是 (site_size=9, input_seq_len=72, feature_size=9)\n",
    "        X_sample = data[i:i + input_seq_len,:,  :]  # 选择 seq_len 范围的数据\n",
    "        X.append(X_sample)\n",
    "        \n",
    "        #Create output data，shape:(target_site_size=1, output_seq_len, target_feature_size=1)\n",
    "        # 制作输出序列数据，形状是 (target_site_size=1, output_seq_len, target_feature_size=1)\n",
    "        target_data = data[i + input_seq_len:i + input_seq_len + output_seq_len,target_site_index,  target_col]\n",
    "        y.append(target_data.reshape(output_seq_len,1,  1))  \n",
    "        \n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b25c9132",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN_LSTM_Model(\n",
       "  (gcn): GCNConv(9, 1)\n",
       "  (lstm): LSTM(18, 64, num_layers=2, batch_first=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义LSTM模型\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)  # 批量计算\n",
    "        #print(lstm_out.shape)\n",
    "        out = self.fc(lstm_out[:, -1, :])  # 仅使用最后时间步的隐藏状态#(batch_size,seq_len,hidden_size)\n",
    "        #out = self.fc(lstm_out[:, :output_seq_len, :])\n",
    "        #print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11603194",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#评估指标\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 计算 RMSE、R2 和 MAE\n",
    "def calculate_metrics(predictions, actuals):\n",
    "    # 计算 RMSE\n",
    "    rmse = np.sqrt(np.mean((predictions - actuals) ** 2))\n",
    "    \n",
    "    # 计算 R2\n",
    "    r2 = r2_score(actuals, predictions)\n",
    "    \n",
    "    # 计算 MAE\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    \n",
    "    return rmse, r2, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d9dded",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 定义函数（不同循环需修改）Define function (different loops need to be modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8ce19cf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Single site single feature input is X_batch = X_origin[:,:,target_site_index,input_feature].unsqueeze(-1),LSTM_input_size = 1\n",
    "#单站点单特征输入为X_batch = X_origin[:,:,target_site_index,input_feature].unsqueeze(-1),LSTM_input_size = 1\n",
    "#Single site all feature input is X_batch = X_origin[:,:,target_site_index,:].squeeze(),LSTM_input_size = 9\n",
    "#单站点所有特征输入为X_batch = X_origin[:,:,target_site_index,:].squeeze(),LSTM_input_size = 9\n",
    "#all site single feature input is X_batch = X_origin[:,:,:,input_feature].squeeze(),LSTM_input_size = 9\n",
    "#所有站点单特征输入为X_batch = X_origin[:,:,:,input_feature].squeeze(),LSTM_input_size = 9\n",
    "#all site all feature input is X_batch = X_origin.reshape(X_origin.size(0), X_origin.size(1), -1),LSTM_input_size = 81\n",
    "#所有站点所有特征输入为X_batch = X_origin.reshape(X_origin.size(0), X_origin.size(1), -1),LSTM_input_size = 81\n",
    "#Remove DO:X_batch = np.delete(X_batch,target_site_index,axis = 2)\n",
    "#剔除DO：X_batch = np.delete(X_batch,target_site_index,axis = 2)\n",
    "\n",
    "# input_batch = slice(None)\n",
    "# input_seq = slice(None)\n",
    "# input_site = target_site_index\n",
    "\n",
    "# LSTM训练和验证循环\n",
    "def LSTM_train_and_evaluate(lstm_model, train_loader, test_loader, criterion, optimizer, epochs, target_site_index, input_feature):\n",
    "    early_stopping = EarlyStopping(patience=10, delta=0.001)\n",
    "    best_model\n",
    "    for epoch in range(epochs):\n",
    "        start_time=time.time()\n",
    "        lstm_model.train()\n",
    "        train_loss = 0\n",
    "        for X_origin, y_batch in train_loader:\n",
    "            X_batch = X_origin[:,:,target_site_index,input_feature].squeeze()#(batch_size,seq_len, site_size, combined_feature_size)\n",
    "#             X_batch = np.delete(X_batch,2,axis = 2)\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            #print(y_batch.shape)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = lstm_model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # 验证\n",
    "        lstm_model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_origin, y_batch in val_loader:\n",
    "                X_batch = X_origin[:,:,target_site_index,input_feature].squeeze()\n",
    "#                 X_batch = np.delete(X_batch,2,axis = 2)\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = lstm_model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        end_time=time.time()\n",
    "        epoch_duration=end_time-start_time\n",
    "        epoch_logs.append([epoch+1,train_loss,val_loss,epoch_duration])\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "#train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, epochs)\n",
    "\n",
    "# LSTM测试集评估\n",
    "def LSTM_evaluate(lstm_model, test_loader, target_site_index, input_feature):\n",
    "    lstm_model.eval()\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_origin, y_batch in test_loader:\n",
    "            X_batch = X_origin[:,:,target_site_index,input_feature].squeeze()\n",
    "#             X_batch = np.delete(X_batch,2,axis = 2)\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = lstm_model(X_batch)\n",
    "            predictions.append(outputs.cpu().numpy())  # 将数据移回CPU\n",
    "            actuals.append(y_batch.cpu().numpy())      # 将数据移回CPU\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "    mse = mean_squared_error(actuals, predictions)\n",
    "    print(f\"Test MSE: {mse:.4f}\")\n",
    "\n",
    "    return predictions, actuals\n",
    "\n",
    "#predictions, actuals = evaluate(model, test_loader)\n",
    "#actuals.shape\n",
    "\n",
    "#lstm model sensitivity\n",
    "#LSTM特征重要性分析\n",
    "def LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='zero'):\n",
    "    \"\"\"\n",
    "    计算特征的重要性：对于每个特征，在其置零或加噪声时，观察对模型输出的影响。\n",
    "    \"\"\"\n",
    "    feature_importances_all = []\n",
    "    for X_origin, y_batch in test_loader:\n",
    "        feature_importances = []\n",
    "        X_batch = X_origin[:,:,target_site_index,input_feature].squeeze()\n",
    "#         X_batch = np.delete(X_batch,2,axis = 2)\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        lstm_model.eval()\n",
    "        baseline_output = lstm_model(X_batch).detach().cpu().numpy()  # 将数据移回CPU\n",
    "        for j in range(X_batch.shape[2]):  # 遍历特征\n",
    "            perturbed_output = []\n",
    "            X_perturbed = X_batch.clone()\n",
    "            if baseline == 'zero':\n",
    "                X_perturbed[:, :, j] = 0  # 将第 i 个特征置零\n",
    "            outputs = lstm_model(X_perturbed)\n",
    "            perturbed_output.append(outputs.detach().cpu().numpy())\n",
    "            importance = np.mean(np.abs(perturbed_output - baseline_output))\n",
    "            feature_importances.append(importance)\n",
    "        feature_importances_all.append(feature_importances)\n",
    "    return feature_importances_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47c01b4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 单站点单特征Single site single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9dbf526",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:70: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "<>:70: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 3.2389, Val Loss: 0.9915\n",
      "Epoch 2/200, Train Loss: 1.5500, Val Loss: 1.0420\n",
      "Epoch 3/200, Train Loss: 1.5020, Val Loss: 1.0785\n",
      "Epoch 4/200, Train Loss: 1.4448, Val Loss: 1.2363\n",
      "Epoch 5/200, Train Loss: 1.3729, Val Loss: 1.0240\n",
      "Epoch 6/200, Train Loss: 1.3396, Val Loss: 0.8871\n",
      "Epoch 7/200, Train Loss: 1.3293, Val Loss: 0.8433\n",
      "Epoch 8/200, Train Loss: 1.3114, Val Loss: 0.8371\n",
      "Epoch 9/200, Train Loss: 1.2899, Val Loss: 0.7977\n",
      "Epoch 10/200, Train Loss: 1.2793, Val Loss: 0.9560\n",
      "Epoch 11/200, Train Loss: 1.2624, Val Loss: 0.8622\n",
      "Epoch 12/200, Train Loss: 1.2326, Val Loss: 0.6730\n",
      "Epoch 13/200, Train Loss: 1.2260, Val Loss: 0.6633\n",
      "Epoch 14/200, Train Loss: 1.2076, Val Loss: 0.7069\n",
      "Epoch 15/200, Train Loss: 1.1810, Val Loss: 0.7563\n",
      "Epoch 16/200, Train Loss: 1.1673, Val Loss: 0.6417\n",
      "Epoch 17/200, Train Loss: 1.1066, Val Loss: 0.7578\n",
      "Epoch 18/200, Train Loss: 1.0565, Val Loss: 0.7873\n",
      "Epoch 19/200, Train Loss: 1.0082, Val Loss: 0.6095\n",
      "Epoch 20/200, Train Loss: 0.9628, Val Loss: 0.8412\n",
      "Epoch 21/200, Train Loss: 0.9258, Val Loss: 0.7405\n",
      "Epoch 22/200, Train Loss: 0.9102, Val Loss: 0.7561\n",
      "Epoch 23/200, Train Loss: 0.8802, Val Loss: 0.7279\n",
      "Epoch 24/200, Train Loss: 0.8675, Val Loss: 0.7233\n",
      "Epoch 25/200, Train Loss: 0.8644, Val Loss: 0.8806\n",
      "Epoch 26/200, Train Loss: 0.8492, Val Loss: 0.7198\n",
      "Epoch 27/200, Train Loss: 0.8378, Val Loss: 0.8797\n",
      "Epoch 28/200, Train Loss: 0.8220, Val Loss: 0.7060\n",
      "Epoch 29/200, Train Loss: 0.8088, Val Loss: 1.1226\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.2944\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1377\n",
      "Test R2: 0.4618\n",
      "Test MAE: 0.8665\n",
      "0    1.053939\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.3463, Val Loss: 2.3481\n",
      "Epoch 2/200, Train Loss: 3.1046, Val Loss: 2.2931\n",
      "Epoch 3/200, Train Loss: 2.0771, Val Loss: 1.2364\n",
      "Epoch 4/200, Train Loss: 1.8725, Val Loss: 0.9496\n",
      "Epoch 5/200, Train Loss: 1.8260, Val Loss: 0.9551\n",
      "Epoch 6/200, Train Loss: 1.8077, Val Loss: 1.0236\n",
      "Epoch 7/200, Train Loss: 1.8001, Val Loss: 1.0091\n",
      "Epoch 8/200, Train Loss: 1.7866, Val Loss: 0.9033\n",
      "Epoch 9/200, Train Loss: 1.7771, Val Loss: 1.4962\n",
      "Epoch 10/200, Train Loss: 1.8151, Val Loss: 1.2862\n",
      "Epoch 11/200, Train Loss: 1.7809, Val Loss: 1.1591\n",
      "Epoch 12/200, Train Loss: 1.7022, Val Loss: 1.6429\n",
      "Epoch 13/200, Train Loss: 1.7853, Val Loss: 1.1380\n",
      "Epoch 14/200, Train Loss: 1.7234, Val Loss: 1.4415\n",
      "Epoch 15/200, Train Loss: 1.7310, Val Loss: 1.0384\n",
      "Epoch 16/200, Train Loss: 1.6974, Val Loss: 0.8477\n",
      "Epoch 17/200, Train Loss: 1.7496, Val Loss: 1.0169\n",
      "Epoch 18/200, Train Loss: 1.7513, Val Loss: 1.0232\n",
      "Epoch 19/200, Train Loss: 1.7577, Val Loss: 1.5776\n",
      "Epoch 20/200, Train Loss: 1.7268, Val Loss: 0.9227\n",
      "Epoch 21/200, Train Loss: 1.7093, Val Loss: 1.3575\n",
      "Epoch 22/200, Train Loss: 1.6755, Val Loss: 1.3587\n",
      "Epoch 23/200, Train Loss: 1.7489, Val Loss: 1.3575\n",
      "Epoch 24/200, Train Loss: 1.7073, Val Loss: 0.8389\n",
      "Epoch 25/200, Train Loss: 1.6684, Val Loss: 1.2623\n",
      "Epoch 26/200, Train Loss: 1.6499, Val Loss: 0.7036\n",
      "Epoch 27/200, Train Loss: 1.5726, Val Loss: 0.9005\n",
      "Epoch 28/200, Train Loss: 1.5406, Val Loss: 1.1017\n",
      "Epoch 29/200, Train Loss: 1.4908, Val Loss: 1.7240\n",
      "Epoch 30/200, Train Loss: 1.4488, Val Loss: 1.6130\n",
      "Epoch 31/200, Train Loss: 1.4180, Val Loss: 0.8366\n",
      "Epoch 32/200, Train Loss: 1.3672, Val Loss: 1.3178\n",
      "Epoch 33/200, Train Loss: 1.3125, Val Loss: 1.2308\n",
      "Epoch 34/200, Train Loss: 1.2921, Val Loss: 1.4298\n",
      "Epoch 35/200, Train Loss: 1.2462, Val Loss: 1.4900\n",
      "Epoch 36/200, Train Loss: 1.2017, Val Loss: 1.6967\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.4158\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1899\n",
      "Test R2: 0.4114\n",
      "Test MAE: 0.9479\n",
      "0    5.022584\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.8657, Val Loss: 0.1023\n",
      "Epoch 2/200, Train Loss: 0.1236, Val Loss: 0.0917\n",
      "Epoch 3/200, Train Loss: 0.1076, Val Loss: 0.0590\n",
      "Epoch 4/200, Train Loss: 0.1043, Val Loss: 0.0601\n",
      "Epoch 5/200, Train Loss: 0.1006, Val Loss: 0.0764\n",
      "Epoch 6/200, Train Loss: 0.1008, Val Loss: 0.0721\n",
      "Epoch 7/200, Train Loss: 0.0996, Val Loss: 0.0570\n",
      "Epoch 8/200, Train Loss: 0.0966, Val Loss: 0.0747\n",
      "Epoch 9/200, Train Loss: 0.0963, Val Loss: 0.0585\n",
      "Epoch 10/200, Train Loss: 0.0941, Val Loss: 0.0587\n",
      "Epoch 11/200, Train Loss: 0.0938, Val Loss: 0.0838\n",
      "Epoch 12/200, Train Loss: 0.0928, Val Loss: 0.0571\n",
      "Epoch 13/200, Train Loss: 0.0930, Val Loss: 0.0577\n",
      "Epoch 14/200, Train Loss: 0.0896, Val Loss: 0.0614\n",
      "Epoch 15/200, Train Loss: 0.0892, Val Loss: 0.0688\n",
      "Epoch 16/200, Train Loss: 0.0874, Val Loss: 0.0677\n",
      "Epoch 17/200, Train Loss: 0.0854, Val Loss: 0.0625\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.0724\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.2690\n",
      "Test R2: 0.9699\n",
      "Test MAE: 0.1535\n",
      "0    2.568341\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.2469, Val Loss: 2.3119\n",
      "Epoch 2/200, Train Loss: 3.0449, Val Loss: 2.4701\n",
      "Epoch 3/200, Train Loss: 3.0212, Val Loss: 2.0683\n",
      "Epoch 4/200, Train Loss: 2.9980, Val Loss: 2.6353\n",
      "Epoch 5/200, Train Loss: 2.9539, Val Loss: 2.2319\n",
      "Epoch 6/200, Train Loss: 2.9196, Val Loss: 2.6366\n",
      "Epoch 7/200, Train Loss: 2.8955, Val Loss: 2.5281\n",
      "Epoch 8/200, Train Loss: 2.8829, Val Loss: 2.0010\n",
      "Epoch 9/200, Train Loss: 2.8844, Val Loss: 1.9319\n",
      "Epoch 10/200, Train Loss: 2.8595, Val Loss: 1.9777\n",
      "Epoch 11/200, Train Loss: 2.8564, Val Loss: 2.2142\n",
      "Epoch 12/200, Train Loss: 2.8660, Val Loss: 1.8965\n",
      "Epoch 13/200, Train Loss: 2.8335, Val Loss: 2.1619\n",
      "Epoch 14/200, Train Loss: 2.8131, Val Loss: 1.9516\n",
      "Epoch 15/200, Train Loss: 2.8048, Val Loss: 2.2035\n",
      "Epoch 16/200, Train Loss: 2.8019, Val Loss: 2.3589\n",
      "Epoch 17/200, Train Loss: 2.8050, Val Loss: 2.8150\n",
      "Epoch 18/200, Train Loss: 2.7734, Val Loss: 2.4344\n",
      "Epoch 19/200, Train Loss: 2.7589, Val Loss: 2.0622\n",
      "Epoch 20/200, Train Loss: 2.7337, Val Loss: 1.9981\n",
      "Epoch 21/200, Train Loss: 2.7112, Val Loss: 2.7746\n",
      "Epoch 22/200, Train Loss: 2.7054, Val Loss: 1.8347\n",
      "Epoch 23/200, Train Loss: 2.6976, Val Loss: 1.9855\n",
      "Epoch 24/200, Train Loss: 2.6814, Val Loss: 2.3952\n",
      "Epoch 25/200, Train Loss: 2.6812, Val Loss: 2.0096\n",
      "Epoch 26/200, Train Loss: 2.6768, Val Loss: 2.1264\n",
      "Epoch 27/200, Train Loss: 2.6845, Val Loss: 1.8834\n",
      "Epoch 28/200, Train Loss: 2.6754, Val Loss: 2.1202\n",
      "Epoch 29/200, Train Loss: 2.6687, Val Loss: 2.1900\n",
      "Epoch 30/200, Train Loss: 2.6635, Val Loss: 2.1385\n",
      "Epoch 31/200, Train Loss: 2.6381, Val Loss: 2.0693\n",
      "Epoch 32/200, Train Loss: 2.6338, Val Loss: 2.0951\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.6431\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.6257\n",
      "Test R2: -0.0989\n",
      "Test MAE: 1.4024\n",
      "0    0.913214\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.8842, Val Loss: 2.3183\n",
      "Epoch 2/200, Train Loss: 2.4090, Val Loss: 1.8980\n",
      "Epoch 3/200, Train Loss: 2.2513, Val Loss: 2.3080\n",
      "Epoch 4/200, Train Loss: 2.1075, Val Loss: 2.4326\n",
      "Epoch 5/200, Train Loss: 1.9086, Val Loss: 2.5943\n",
      "Epoch 6/200, Train Loss: 1.7349, Val Loss: 3.6257\n",
      "Epoch 7/200, Train Loss: 1.5804, Val Loss: 2.2422\n",
      "Epoch 8/200, Train Loss: 1.4588, Val Loss: 3.6285\n",
      "Epoch 9/200, Train Loss: 1.3427, Val Loss: 2.9075\n",
      "Epoch 10/200, Train Loss: 1.2544, Val Loss: 3.4960\n",
      "Epoch 11/200, Train Loss: 1.1426, Val Loss: 2.6469\n",
      "Epoch 12/200, Train Loss: 1.0536, Val Loss: 4.6643\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.9418\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.3935\n",
      "Test R2: 0.1927\n",
      "Test MAE: 1.0919\n",
      "0    9.353263\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.3511, Val Loss: 2.3992\n",
      "Epoch 2/200, Train Loss: 3.1176, Val Loss: 2.4010\n",
      "Epoch 3/200, Train Loss: 3.1239, Val Loss: 2.4845\n",
      "Epoch 4/200, Train Loss: 3.1193, Val Loss: 2.0826\n",
      "Epoch 5/200, Train Loss: 3.1186, Val Loss: 2.1628\n",
      "Epoch 6/200, Train Loss: 3.0620, Val Loss: 2.3300\n",
      "Epoch 7/200, Train Loss: 3.0257, Val Loss: 2.0611\n",
      "Epoch 8/200, Train Loss: 2.9986, Val Loss: 1.7340\n",
      "Epoch 9/200, Train Loss: 2.9836, Val Loss: 1.9538\n",
      "Epoch 10/200, Train Loss: 3.0039, Val Loss: 2.2383\n",
      "Epoch 11/200, Train Loss: 2.9545, Val Loss: 2.1231\n",
      "Epoch 12/200, Train Loss: 2.9374, Val Loss: 1.7822\n",
      "Epoch 13/200, Train Loss: 2.9103, Val Loss: 1.4646\n",
      "Epoch 14/200, Train Loss: 2.8917, Val Loss: 2.0930\n",
      "Epoch 15/200, Train Loss: 2.8920, Val Loss: 1.7376\n",
      "Epoch 16/200, Train Loss: 2.9293, Val Loss: 2.0572\n",
      "Epoch 17/200, Train Loss: 2.9054, Val Loss: 1.4633\n",
      "Epoch 18/200, Train Loss: 2.8947, Val Loss: 1.5102\n",
      "Epoch 19/200, Train Loss: 2.8630, Val Loss: 1.8089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Train Loss: 2.9298, Val Loss: 1.6608\n",
      "Epoch 21/200, Train Loss: 2.9441, Val Loss: 1.3515\n",
      "Epoch 22/200, Train Loss: 2.9320, Val Loss: 2.0818\n",
      "Epoch 23/200, Train Loss: 2.9373, Val Loss: 1.6360\n",
      "Epoch 24/200, Train Loss: 2.9127, Val Loss: 1.8944\n",
      "Epoch 25/200, Train Loss: 2.8910, Val Loss: 1.6593\n",
      "Epoch 26/200, Train Loss: 2.8913, Val Loss: 1.9019\n",
      "Epoch 27/200, Train Loss: 2.8788, Val Loss: 1.6140\n",
      "Epoch 28/200, Train Loss: 2.8813, Val Loss: 1.7253\n",
      "Epoch 29/200, Train Loss: 2.8378, Val Loss: 1.7940\n",
      "Epoch 30/200, Train Loss: 2.8082, Val Loss: 1.4873\n",
      "Epoch 31/200, Train Loss: 2.7832, Val Loss: 1.8840\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.5992\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.6122\n",
      "Test R2: -0.0806\n",
      "Test MAE: 1.3563\n",
      "0    0.330075\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.4991, Val Loss: 2.1549\n",
      "Epoch 2/200, Train Loss: 3.1224, Val Loss: 2.1408\n",
      "Epoch 3/200, Train Loss: 3.1224, Val Loss: 1.8148\n",
      "Epoch 4/200, Train Loss: 3.1184, Val Loss: 2.2299\n",
      "Epoch 5/200, Train Loss: 3.1193, Val Loss: 1.9384\n",
      "Epoch 6/200, Train Loss: 3.1149, Val Loss: 2.2989\n",
      "Epoch 7/200, Train Loss: 3.0228, Val Loss: 1.4729\n",
      "Epoch 8/200, Train Loss: 2.9449, Val Loss: 1.6420\n",
      "Epoch 9/200, Train Loss: 2.9165, Val Loss: 1.8020\n",
      "Epoch 10/200, Train Loss: 2.9133, Val Loss: 1.6778\n",
      "Epoch 11/200, Train Loss: 2.9005, Val Loss: 1.5520\n",
      "Epoch 12/200, Train Loss: 2.8840, Val Loss: 2.2264\n",
      "Epoch 13/200, Train Loss: 2.8828, Val Loss: 1.5323\n",
      "Epoch 14/200, Train Loss: 2.8717, Val Loss: 1.2745\n",
      "Epoch 15/200, Train Loss: 2.8821, Val Loss: 1.5303\n",
      "Epoch 16/200, Train Loss: 2.8726, Val Loss: 1.5846\n",
      "Epoch 17/200, Train Loss: 2.8609, Val Loss: 1.3977\n",
      "Epoch 18/200, Train Loss: 2.8578, Val Loss: 1.5176\n",
      "Epoch 19/200, Train Loss: 2.8678, Val Loss: 1.6175\n",
      "Epoch 20/200, Train Loss: 2.9433, Val Loss: 3.1536\n",
      "Epoch 21/200, Train Loss: 2.9478, Val Loss: 2.3477\n",
      "Epoch 22/200, Train Loss: 2.8977, Val Loss: 1.8486\n",
      "Epoch 23/200, Train Loss: 2.8625, Val Loss: 1.4546\n",
      "Epoch 24/200, Train Loss: 2.8563, Val Loss: 1.6120\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.9571\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.3990\n",
      "Test R2: 0.1863\n",
      "Test MAE: 1.1746\n",
      "0    1.240686\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.4501, Val Loss: 1.8970\n",
      "Epoch 2/200, Train Loss: 3.1216, Val Loss: 2.1164\n",
      "Epoch 3/200, Train Loss: 3.1234, Val Loss: 2.0155\n",
      "Epoch 4/200, Train Loss: 3.1226, Val Loss: 2.1070\n",
      "Epoch 5/200, Train Loss: 3.1212, Val Loss: 2.0717\n",
      "Epoch 6/200, Train Loss: 3.1216, Val Loss: 2.3367\n",
      "Epoch 7/200, Train Loss: 3.1201, Val Loss: 2.4729\n",
      "Epoch 8/200, Train Loss: 3.1184, Val Loss: 2.5719\n",
      "Epoch 9/200, Train Loss: 3.1202, Val Loss: 2.0505\n",
      "Epoch 10/200, Train Loss: 3.0020, Val Loss: 2.4479\n",
      "Epoch 11/200, Train Loss: 2.7152, Val Loss: 2.4198\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.4143\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1892\n",
      "Test R2: 0.4120\n",
      "Test MAE: 0.9743\n",
      "0    0.673283\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.2869, Val Loss: 1.9652\n",
      "Epoch 2/200, Train Loss: 2.7041, Val Loss: 2.4903\n",
      "Epoch 3/200, Train Loss: 2.3864, Val Loss: 2.0149\n",
      "Epoch 4/200, Train Loss: 2.3517, Val Loss: 1.9992\n",
      "Epoch 5/200, Train Loss: 2.3478, Val Loss: 2.2737\n",
      "Epoch 6/200, Train Loss: 2.3512, Val Loss: 2.1138\n",
      "Epoch 7/200, Train Loss: 2.3514, Val Loss: 1.9982\n",
      "Epoch 8/200, Train Loss: 2.3396, Val Loss: 1.8869\n",
      "Epoch 9/200, Train Loss: 2.3335, Val Loss: 1.8887\n",
      "Epoch 10/200, Train Loss: 2.3260, Val Loss: 1.9480\n",
      "Epoch 11/200, Train Loss: 2.3200, Val Loss: 1.9103\n",
      "Epoch 12/200, Train Loss: 2.3099, Val Loss: 1.6415\n",
      "Epoch 13/200, Train Loss: 2.3317, Val Loss: 1.6745\n",
      "Epoch 14/200, Train Loss: 2.3047, Val Loss: 1.8721\n",
      "Epoch 15/200, Train Loss: 2.2554, Val Loss: 2.1397\n",
      "Epoch 16/200, Train Loss: 2.3145, Val Loss: 1.7672\n",
      "Epoch 17/200, Train Loss: 2.3064, Val Loss: 1.6989\n",
      "Epoch 18/200, Train Loss: 2.2962, Val Loss: 1.4975\n",
      "Epoch 19/200, Train Loss: 2.2997, Val Loss: 1.5626\n",
      "Epoch 20/200, Train Loss: 2.2969, Val Loss: 1.6311\n",
      "Epoch 21/200, Train Loss: 2.2938, Val Loss: 1.7395\n",
      "Epoch 22/200, Train Loss: 2.2962, Val Loss: 1.3800\n",
      "Epoch 23/200, Train Loss: 2.2714, Val Loss: 2.0448\n",
      "Epoch 24/200, Train Loss: 2.2362, Val Loss: 1.8863\n",
      "Epoch 25/200, Train Loss: 2.1952, Val Loss: 1.9901\n",
      "Epoch 26/200, Train Loss: 2.2549, Val Loss: 1.6420\n",
      "Epoch 27/200, Train Loss: 2.2373, Val Loss: 1.8470\n",
      "Epoch 28/200, Train Loss: 2.2411, Val Loss: 1.4140\n",
      "Epoch 29/200, Train Loss: 2.2221, Val Loss: 1.5172\n",
      "Epoch 30/200, Train Loss: 2.1510, Val Loss: 1.9760\n",
      "Epoch 31/200, Train Loss: 2.2796, Val Loss: 2.3183\n",
      "Epoch 32/200, Train Loss: 2.2458, Val Loss: 1.4587\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.2232\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.7953\n",
      "Test R2: -0.3401\n",
      "Test MAE: 1.5046\n",
      "0    6.63316\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.5462, Val Loss: 0.6925\n",
      "Epoch 2/200, Train Loss: 1.2660, Val Loss: 0.7991\n",
      "Epoch 3/200, Train Loss: 1.2269, Val Loss: 0.7680\n",
      "Epoch 4/200, Train Loss: 1.1890, Val Loss: 0.7599\n",
      "Epoch 5/200, Train Loss: 1.1660, Val Loss: 0.7958\n",
      "Epoch 6/200, Train Loss: 1.1344, Val Loss: 0.8907\n",
      "Epoch 7/200, Train Loss: 1.1066, Val Loss: 0.8498\n",
      "Epoch 8/200, Train Loss: 1.0919, Val Loss: 0.9502\n",
      "Epoch 9/200, Train Loss: 1.0746, Val Loss: 0.8659\n",
      "Epoch 10/200, Train Loss: 1.0613, Val Loss: 0.8358\n",
      "Epoch 11/200, Train Loss: 1.0536, Val Loss: 0.8735\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.1221\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.0593\n",
      "Test R2: 0.3715\n",
      "Test MAE: 0.8012\n",
      "0    3.175233\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.2439, Val Loss: 2.7271\n",
      "Epoch 2/200, Train Loss: 3.5468, Val Loss: 1.7454\n",
      "Epoch 3/200, Train Loss: 2.3919, Val Loss: 1.1713\n",
      "Epoch 4/200, Train Loss: 1.4404, Val Loss: 1.2024\n",
      "Epoch 5/200, Train Loss: 1.3917, Val Loss: 1.5823\n",
      "Epoch 6/200, Train Loss: 1.0711, Val Loss: 1.1642\n",
      "Epoch 7/200, Train Loss: 1.0095, Val Loss: 1.2315\n",
      "Epoch 8/200, Train Loss: 0.9492, Val Loss: 1.2990\n",
      "Epoch 9/200, Train Loss: 0.9281, Val Loss: 1.3430\n",
      "Epoch 10/200, Train Loss: 0.9042, Val Loss: 1.4522\n",
      "Epoch 11/200, Train Loss: 0.8766, Val Loss: 1.6439\n",
      "Epoch 12/200, Train Loss: 0.8776, Val Loss: 1.5609\n",
      "Epoch 13/200, Train Loss: 0.8501, Val Loss: 1.5459\n",
      "Epoch 14/200, Train Loss: 0.8614, Val Loss: 1.5026\n",
      "Epoch 15/200, Train Loss: 0.8409, Val Loss: 1.3114\n",
      "Epoch 16/200, Train Loss: 0.8224, Val Loss: 1.3826\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.9558\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.9777\n",
      "Test R2: 0.4646\n",
      "Test MAE: 0.7446\n",
      "0    2.648667\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.5394, Val Loss: 0.0634\n",
      "Epoch 2/200, Train Loss: 0.0980, Val Loss: 0.0539\n",
      "Epoch 3/200, Train Loss: 0.0892, Val Loss: 0.0543\n",
      "Epoch 4/200, Train Loss: 0.0896, Val Loss: 0.0667\n",
      "Epoch 5/200, Train Loss: 0.0879, Val Loss: 0.0648\n",
      "Epoch 6/200, Train Loss: 0.0852, Val Loss: 0.0495\n",
      "Epoch 7/200, Train Loss: 0.0850, Val Loss: 0.0669\n",
      "Epoch 8/200, Train Loss: 0.0813, Val Loss: 0.0450\n",
      "Epoch 9/200, Train Loss: 0.0809, Val Loss: 0.0479\n",
      "Epoch 10/200, Train Loss: 0.0802, Val Loss: 0.0504\n",
      "Epoch 11/200, Train Loss: 0.0774, Val Loss: 0.0440\n",
      "Epoch 12/200, Train Loss: 0.0765, Val Loss: 0.0586\n",
      "Epoch 13/200, Train Loss: 0.0758, Val Loss: 0.0451\n",
      "Epoch 14/200, Train Loss: 0.0741, Val Loss: 0.0462\n",
      "Epoch 15/200, Train Loss: 0.0740, Val Loss: 0.0502\n",
      "Epoch 16/200, Train Loss: 0.0739, Val Loss: 0.0602\n",
      "Epoch 17/200, Train Loss: 0.0735, Val Loss: 0.0456\n",
      "Epoch 18/200, Train Loss: 0.0727, Val Loss: 0.0425\n",
      "Epoch 19/200, Train Loss: 0.0722, Val Loss: 0.0469\n",
      "Epoch 20/200, Train Loss: 0.0722, Val Loss: 0.0461\n",
      "Epoch 21/200, Train Loss: 0.0713, Val Loss: 0.0429\n",
      "Epoch 22/200, Train Loss: 0.0710, Val Loss: 0.0608\n",
      "Epoch 23/200, Train Loss: 0.0715, Val Loss: 0.0445\n",
      "Epoch 24/200, Train Loss: 0.0713, Val Loss: 0.0438\n",
      "Epoch 25/200, Train Loss: 0.0701, Val Loss: 0.0466\n",
      "Epoch 26/200, Train Loss: 0.0695, Val Loss: 0.0465\n",
      "Epoch 27/200, Train Loss: 0.0698, Val Loss: 0.0437\n",
      "Epoch 28/200, Train Loss: 0.0695, Val Loss: 0.0418\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.1110\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.3332\n",
      "Test R2: 0.9378\n",
      "Test MAE: 0.1817\n",
      "0    5.812212\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.3277, Val Loss: 4.4134\n",
      "Epoch 2/200, Train Loss: 3.3493, Val Loss: 2.8910\n",
      "Epoch 3/200, Train Loss: 3.3314, Val Loss: 3.1120\n",
      "Epoch 4/200, Train Loss: 3.3321, Val Loss: 3.7523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200, Train Loss: 3.2978, Val Loss: 3.1882\n",
      "Epoch 6/200, Train Loss: 3.3123, Val Loss: 4.2462\n",
      "Epoch 7/200, Train Loss: 3.2805, Val Loss: 4.3137\n",
      "Epoch 8/200, Train Loss: 3.2622, Val Loss: 2.9066\n",
      "Epoch 9/200, Train Loss: 3.2404, Val Loss: 3.9027\n",
      "Epoch 10/200, Train Loss: 3.2263, Val Loss: 3.2925\n",
      "Epoch 11/200, Train Loss: 3.2094, Val Loss: 2.9100\n",
      "Epoch 12/200, Train Loss: 3.2020, Val Loss: 4.7766\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.7527\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.3239\n",
      "Test R2: 0.0182\n",
      "Test MAE: 1.1203\n",
      "0    0.210704\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.7991, Val Loss: 2.2493\n",
      "Epoch 2/200, Train Loss: 2.6609, Val Loss: 2.1772\n",
      "Epoch 3/200, Train Loss: 2.5249, Val Loss: 2.0116\n",
      "Epoch 4/200, Train Loss: 2.4138, Val Loss: 2.0932\n",
      "Epoch 5/200, Train Loss: 2.3195, Val Loss: 1.7767\n",
      "Epoch 6/200, Train Loss: 2.2090, Val Loss: 1.6032\n",
      "Epoch 7/200, Train Loss: 2.0238, Val Loss: 2.1891\n",
      "Epoch 8/200, Train Loss: 1.8568, Val Loss: 1.5880\n",
      "Epoch 9/200, Train Loss: 1.7257, Val Loss: 1.5720\n",
      "Epoch 10/200, Train Loss: 1.5903, Val Loss: 1.6396\n",
      "Epoch 11/200, Train Loss: 1.5011, Val Loss: 1.5570\n",
      "Epoch 12/200, Train Loss: 1.4336, Val Loss: 1.7209\n",
      "Epoch 13/200, Train Loss: 1.3151, Val Loss: 1.8058\n",
      "Epoch 14/200, Train Loss: 1.2482, Val Loss: 2.1550\n",
      "Epoch 15/200, Train Loss: 1.2028, Val Loss: 1.7811\n",
      "Epoch 16/200, Train Loss: 1.1305, Val Loss: 1.6545\n",
      "Epoch 17/200, Train Loss: 1.0886, Val Loss: 1.7665\n",
      "Epoch 18/200, Train Loss: 1.0195, Val Loss: 1.7882\n",
      "Epoch 19/200, Train Loss: 0.9797, Val Loss: 2.0756\n",
      "Epoch 20/200, Train Loss: 0.9247, Val Loss: 1.9806\n",
      "Epoch 21/200, Train Loss: 0.9406, Val Loss: 2.4398\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.4277\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.8514\n",
      "Test R2: -0.9200\n",
      "Test MAE: 1.5490\n",
      "0    1.094657\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.3248, Val Loss: 4.0768\n",
      "Epoch 2/200, Train Loss: 3.2549, Val Loss: 3.7992\n",
      "Epoch 3/200, Train Loss: 3.1296, Val Loss: 4.6903\n",
      "Epoch 4/200, Train Loss: 3.1120, Val Loss: 5.0588\n",
      "Epoch 5/200, Train Loss: 3.0998, Val Loss: 4.5295\n",
      "Epoch 6/200, Train Loss: 3.1062, Val Loss: 4.4836\n",
      "Epoch 7/200, Train Loss: 3.1112, Val Loss: 4.8366\n",
      "Epoch 8/200, Train Loss: 3.0938, Val Loss: 4.9440\n",
      "Epoch 9/200, Train Loss: 3.0873, Val Loss: 4.8756\n",
      "Epoch 10/200, Train Loss: 3.1792, Val Loss: 5.1268\n",
      "Epoch 11/200, Train Loss: 3.1303, Val Loss: 4.9060\n",
      "Epoch 12/200, Train Loss: 3.1077, Val Loss: 4.9546\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.3866\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1776\n",
      "Test R2: 0.2233\n",
      "Test MAE: 0.9967\n",
      "0    0.754026\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.4136, Val Loss: 3.2735\n",
      "Epoch 2/200, Train Loss: 3.5547, Val Loss: 3.3653\n",
      "Epoch 3/200, Train Loss: 3.5598, Val Loss: 2.2615\n",
      "Epoch 4/200, Train Loss: 3.5566, Val Loss: 2.8534\n",
      "Epoch 5/200, Train Loss: 3.5595, Val Loss: 3.1479\n",
      "Epoch 6/200, Train Loss: 3.5558, Val Loss: 2.6391\n",
      "Epoch 7/200, Train Loss: 3.4636, Val Loss: 2.8434\n",
      "Epoch 8/200, Train Loss: 3.2950, Val Loss: 4.0365\n",
      "Epoch 9/200, Train Loss: 3.2549, Val Loss: 2.1959\n",
      "Epoch 10/200, Train Loss: 3.2395, Val Loss: 2.7091\n",
      "Epoch 11/200, Train Loss: 3.2418, Val Loss: 4.3334\n",
      "Epoch 12/200, Train Loss: 3.4268, Val Loss: 2.8947\n",
      "Epoch 13/200, Train Loss: 3.2937, Val Loss: 3.2244\n",
      "Epoch 14/200, Train Loss: 3.2619, Val Loss: 2.9907\n",
      "Epoch 15/200, Train Loss: 3.2648, Val Loss: 2.7523\n",
      "Epoch 16/200, Train Loss: 3.2172, Val Loss: 3.0313\n",
      "Epoch 17/200, Train Loss: 3.1375, Val Loss: 3.8236\n",
      "Epoch 18/200, Train Loss: 3.1134, Val Loss: 2.6070\n",
      "Epoch 19/200, Train Loss: 3.0916, Val Loss: 2.9357\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.5918\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.2617\n",
      "Test R2: 0.1083\n",
      "Test MAE: 1.0469\n",
      "0    0.338594\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.3923, Val Loss: 3.6321\n",
      "Epoch 2/200, Train Loss: 3.5578, Val Loss: 2.9395\n",
      "Epoch 3/200, Train Loss: 3.5532, Val Loss: 3.3516\n",
      "Epoch 4/200, Train Loss: 3.5547, Val Loss: 3.1531\n",
      "Epoch 5/200, Train Loss: 3.5547, Val Loss: 3.1205\n",
      "Epoch 6/200, Train Loss: 3.0519, Val Loss: 3.9660\n",
      "Epoch 7/200, Train Loss: 2.3166, Val Loss: 3.4200\n",
      "Epoch 8/200, Train Loss: 2.2976, Val Loss: 3.7175\n",
      "Epoch 9/200, Train Loss: 2.2709, Val Loss: 4.1570\n",
      "Epoch 10/200, Train Loss: 2.2774, Val Loss: 2.7013\n",
      "Epoch 11/200, Train Loss: 2.2667, Val Loss: 3.1297\n",
      "Epoch 12/200, Train Loss: 2.2644, Val Loss: 2.8284\n",
      "Epoch 13/200, Train Loss: 2.2623, Val Loss: 2.0099\n",
      "Epoch 14/200, Train Loss: 2.2572, Val Loss: 3.1221\n",
      "Epoch 15/200, Train Loss: 2.2539, Val Loss: 2.2659\n",
      "Epoch 16/200, Train Loss: 2.2447, Val Loss: 2.7209\n",
      "Epoch 17/200, Train Loss: 2.2442, Val Loss: 2.6732\n",
      "Epoch 18/200, Train Loss: 2.2454, Val Loss: 2.5052\n",
      "Epoch 19/200, Train Loss: 2.2390, Val Loss: 2.7537\n",
      "Epoch 20/200, Train Loss: 2.2357, Val Loss: 2.8333\n",
      "Epoch 21/200, Train Loss: 2.3250, Val Loss: 3.4256\n",
      "Epoch 22/200, Train Loss: 2.2556, Val Loss: 2.5972\n",
      "Epoch 23/200, Train Loss: 2.2475, Val Loss: 2.5421\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.7593\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.8714\n",
      "Test R2: 0.5747\n",
      "Test MAE: 0.7082\n",
      "0    1.954271\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.2998, Val Loss: 2.9380\n",
      "Epoch 2/200, Train Loss: 2.6946, Val Loss: 4.8986\n",
      "Epoch 3/200, Train Loss: 2.6412, Val Loss: 5.7312\n",
      "Epoch 4/200, Train Loss: 2.6216, Val Loss: 4.2281\n",
      "Epoch 5/200, Train Loss: 2.6059, Val Loss: 4.4588\n",
      "Epoch 6/200, Train Loss: 2.6007, Val Loss: 3.1261\n",
      "Epoch 7/200, Train Loss: 2.5916, Val Loss: 5.2047\n",
      "Epoch 8/200, Train Loss: 2.5777, Val Loss: 4.0678\n",
      "Epoch 9/200, Train Loss: 2.5676, Val Loss: 4.3529\n",
      "Epoch 10/200, Train Loss: 2.5581, Val Loss: 3.1003\n",
      "Epoch 11/200, Train Loss: 2.5666, Val Loss: 3.8171\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.3437\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1592\n",
      "Test R2: 0.2474\n",
      "Test MAE: 0.9563\n",
      "0    2.259054\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.7341, Val Loss: 1.4635\n",
      "Epoch 2/200, Train Loss: 1.8332, Val Loss: 1.4768\n",
      "Epoch 3/200, Train Loss: 1.8144, Val Loss: 1.4606\n",
      "Epoch 4/200, Train Loss: 1.8028, Val Loss: 1.4417\n",
      "Epoch 5/200, Train Loss: 1.7853, Val Loss: 1.4572\n",
      "Epoch 6/200, Train Loss: 1.7800, Val Loss: 1.5558\n",
      "Epoch 7/200, Train Loss: 1.7600, Val Loss: 1.4823\n",
      "Epoch 8/200, Train Loss: 1.7519, Val Loss: 1.4206\n",
      "Epoch 9/200, Train Loss: 1.7547, Val Loss: 1.4397\n",
      "Epoch 10/200, Train Loss: 1.7416, Val Loss: 1.5834\n",
      "Epoch 11/200, Train Loss: 1.7323, Val Loss: 1.4936\n",
      "Epoch 12/200, Train Loss: 1.7365, Val Loss: 1.7048\n",
      "Epoch 13/200, Train Loss: 1.7197, Val Loss: 1.4626\n",
      "Epoch 14/200, Train Loss: 1.7219, Val Loss: 1.5840\n",
      "Epoch 15/200, Train Loss: 1.6938, Val Loss: 1.5328\n",
      "Epoch 16/200, Train Loss: 1.6911, Val Loss: 1.5610\n",
      "Epoch 17/200, Train Loss: 1.6627, Val Loss: 1.6055\n",
      "Epoch 18/200, Train Loss: 1.6999, Val Loss: 1.4870\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.9690\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.7231\n",
      "Test R2: 0.4652\n",
      "Test MAE: 1.4200\n",
      "0    1.179163\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.2608, Val Loss: 4.4736\n",
      "Epoch 2/200, Train Loss: 3.7351, Val Loss: 3.9087\n",
      "Epoch 3/200, Train Loss: 2.8614, Val Loss: 1.5689\n",
      "Epoch 4/200, Train Loss: 1.7872, Val Loss: 2.1043\n",
      "Epoch 5/200, Train Loss: 1.7186, Val Loss: 1.4807\n",
      "Epoch 6/200, Train Loss: 1.6561, Val Loss: 1.5531\n",
      "Epoch 7/200, Train Loss: 1.6403, Val Loss: 1.1948\n",
      "Epoch 8/200, Train Loss: 1.5876, Val Loss: 1.9704\n",
      "Epoch 9/200, Train Loss: 1.5629, Val Loss: 2.3393\n",
      "Epoch 10/200, Train Loss: 1.5313, Val Loss: 2.8057\n",
      "Epoch 11/200, Train Loss: 1.4959, Val Loss: 1.8307\n",
      "Epoch 12/200, Train Loss: 1.4781, Val Loss: 2.2417\n",
      "Epoch 13/200, Train Loss: 1.4693, Val Loss: 1.7535\n",
      "Epoch 14/200, Train Loss: 1.4881, Val Loss: 2.3204\n",
      "Epoch 15/200, Train Loss: 1.4368, Val Loss: 2.1736\n",
      "Epoch 16/200, Train Loss: 1.4244, Val Loss: 2.8776\n",
      "Epoch 17/200, Train Loss: 1.4229, Val Loss: 2.3151\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.7797\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.3340\n",
      "Test R2: 0.6794\n",
      "Test MAE: 1.0430\n",
      "0    1.545924\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.3705, Val Loss: 0.2448\n",
      "Epoch 2/200, Train Loss: 0.2083, Val Loss: 0.2142\n",
      "Epoch 3/200, Train Loss: 0.2010, Val Loss: 0.1921\n",
      "Epoch 4/200, Train Loss: 0.1964, Val Loss: 0.2179\n",
      "Epoch 5/200, Train Loss: 0.1953, Val Loss: 0.2055\n",
      "Epoch 6/200, Train Loss: 0.1910, Val Loss: 0.2019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200, Train Loss: 0.1900, Val Loss: 0.1937\n",
      "Epoch 8/200, Train Loss: 0.1885, Val Loss: 0.2100\n",
      "Epoch 9/200, Train Loss: 0.1896, Val Loss: 0.2010\n",
      "Epoch 10/200, Train Loss: 0.1863, Val Loss: 0.1830\n",
      "Epoch 11/200, Train Loss: 0.1848, Val Loss: 0.1842\n",
      "Epoch 12/200, Train Loss: 0.1841, Val Loss: 0.1949\n",
      "Epoch 13/200, Train Loss: 0.1831, Val Loss: 0.2171\n",
      "Epoch 14/200, Train Loss: 0.1824, Val Loss: 0.1914\n",
      "Epoch 15/200, Train Loss: 0.1837, Val Loss: 0.2024\n",
      "Epoch 16/200, Train Loss: 0.1796, Val Loss: 0.1818\n",
      "Epoch 17/200, Train Loss: 0.1774, Val Loss: 0.2125\n",
      "Epoch 18/200, Train Loss: 0.1747, Val Loss: 0.1693\n",
      "Epoch 19/200, Train Loss: 0.1729, Val Loss: 0.1734\n",
      "Epoch 20/200, Train Loss: 0.1705, Val Loss: 0.1739\n",
      "Epoch 21/200, Train Loss: 0.1668, Val Loss: 0.1709\n",
      "Epoch 22/200, Train Loss: 0.1667, Val Loss: 0.1580\n",
      "Epoch 23/200, Train Loss: 0.1647, Val Loss: 0.1504\n",
      "Epoch 24/200, Train Loss: 0.1618, Val Loss: 0.1436\n",
      "Epoch 25/200, Train Loss: 0.1643, Val Loss: 0.1481\n",
      "Epoch 26/200, Train Loss: 0.1605, Val Loss: 0.1542\n",
      "Epoch 27/200, Train Loss: 0.1613, Val Loss: 0.1587\n",
      "Epoch 28/200, Train Loss: 0.1602, Val Loss: 0.1503\n",
      "Epoch 29/200, Train Loss: 0.1584, Val Loss: 0.1492\n",
      "Epoch 30/200, Train Loss: 0.1587, Val Loss: 0.1471\n",
      "Epoch 31/200, Train Loss: 0.1562, Val Loss: 0.1409\n",
      "Epoch 32/200, Train Loss: 0.1583, Val Loss: 0.1458\n",
      "Epoch 33/200, Train Loss: 0.1571, Val Loss: 0.1531\n",
      "Epoch 34/200, Train Loss: 0.1555, Val Loss: 0.1480\n",
      "Epoch 35/200, Train Loss: 0.1544, Val Loss: 0.1608\n",
      "Epoch 36/200, Train Loss: 0.1559, Val Loss: 0.1459\n",
      "Epoch 37/200, Train Loss: 0.1542, Val Loss: 0.1633\n",
      "Epoch 38/200, Train Loss: 0.1535, Val Loss: 0.1462\n",
      "Epoch 39/200, Train Loss: 0.1519, Val Loss: 0.1529\n",
      "Epoch 40/200, Train Loss: 0.1511, Val Loss: 0.1458\n",
      "Epoch 41/200, Train Loss: 0.1516, Val Loss: 0.2079\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.3004\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.5481\n",
      "Test R2: 0.9459\n",
      "Test MAE: 0.3254\n",
      "0    7.833606\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.2261, Val Loss: 4.6107\n",
      "Epoch 2/200, Train Loss: 3.6719, Val Loss: 3.4127\n",
      "Epoch 3/200, Train Loss: 3.6262, Val Loss: 3.3750\n",
      "Epoch 4/200, Train Loss: 3.6082, Val Loss: 3.7278\n",
      "Epoch 5/200, Train Loss: 3.6041, Val Loss: 4.1590\n",
      "Epoch 6/200, Train Loss: 3.5881, Val Loss: 3.8972\n",
      "Epoch 7/200, Train Loss: 3.5752, Val Loss: 4.6633\n",
      "Epoch 8/200, Train Loss: 3.5783, Val Loss: 3.5210\n",
      "Epoch 9/200, Train Loss: 3.5687, Val Loss: 3.3622\n",
      "Epoch 10/200, Train Loss: 3.5136, Val Loss: 3.6879\n",
      "Epoch 11/200, Train Loss: 3.2804, Val Loss: 4.2569\n",
      "Epoch 12/200, Train Loss: 3.3020, Val Loss: 3.5975\n",
      "Epoch 13/200, Train Loss: 2.6258, Val Loss: 2.8146\n",
      "Epoch 14/200, Train Loss: 2.4365, Val Loss: 2.3038\n",
      "Epoch 15/200, Train Loss: 2.3739, Val Loss: 3.4575\n",
      "Epoch 16/200, Train Loss: 2.3298, Val Loss: 3.1504\n",
      "Epoch 17/200, Train Loss: 2.2908, Val Loss: 3.3341\n",
      "Epoch 18/200, Train Loss: 2.1694, Val Loss: 3.3815\n",
      "Epoch 19/200, Train Loss: 2.1219, Val Loss: 3.4681\n",
      "Epoch 20/200, Train Loss: 2.0693, Val Loss: 3.7719\n",
      "Epoch 21/200, Train Loss: 2.0356, Val Loss: 2.9932\n",
      "Epoch 22/200, Train Loss: 2.1117, Val Loss: 4.2434\n",
      "Epoch 23/200, Train Loss: 2.0172, Val Loss: 2.7999\n",
      "Epoch 24/200, Train Loss: 1.9590, Val Loss: 3.5600\n",
      "Early stopping triggered.\n",
      "Test MSE: 4.4160\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 2.1014\n",
      "Test R2: 0.2045\n",
      "Test MAE: 1.7096\n",
      "0    2.510333\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.4580, Val Loss: 3.6011\n",
      "Epoch 2/200, Train Loss: 2.7485, Val Loss: 4.7870\n",
      "Epoch 3/200, Train Loss: 2.6591, Val Loss: 3.8755\n",
      "Epoch 4/200, Train Loss: 2.5920, Val Loss: 3.0921\n",
      "Epoch 5/200, Train Loss: 2.5151, Val Loss: 4.1191\n",
      "Epoch 6/200, Train Loss: 2.3898, Val Loss: 2.9273\n",
      "Epoch 7/200, Train Loss: 2.1504, Val Loss: 2.3851\n",
      "Epoch 8/200, Train Loss: 1.9243, Val Loss: 2.4515\n",
      "Epoch 9/200, Train Loss: 1.6608, Val Loss: 1.8756\n",
      "Epoch 10/200, Train Loss: 1.4427, Val Loss: 1.9833\n",
      "Epoch 11/200, Train Loss: 1.2888, Val Loss: 1.9602\n",
      "Epoch 12/200, Train Loss: 1.1719, Val Loss: 1.4620\n",
      "Epoch 13/200, Train Loss: 1.0983, Val Loss: 1.4910\n",
      "Epoch 14/200, Train Loss: 1.0303, Val Loss: 1.7370\n",
      "Epoch 15/200, Train Loss: 0.9466, Val Loss: 1.8200\n",
      "Epoch 16/200, Train Loss: 0.8711, Val Loss: 1.7371\n",
      "Epoch 17/200, Train Loss: 0.7959, Val Loss: 1.5696\n",
      "Epoch 18/200, Train Loss: 0.7317, Val Loss: 1.7061\n",
      "Epoch 19/200, Train Loss: 0.7462, Val Loss: 1.4520\n",
      "Epoch 20/200, Train Loss: 0.6866, Val Loss: 1.9044\n",
      "Epoch 21/200, Train Loss: 0.6587, Val Loss: 1.5471\n",
      "Epoch 22/200, Train Loss: 0.7042, Val Loss: 1.6179\n",
      "Epoch 23/200, Train Loss: 0.5923, Val Loss: 2.4628\n",
      "Epoch 24/200, Train Loss: 0.6358, Val Loss: 1.9158\n",
      "Epoch 25/200, Train Loss: 0.5494, Val Loss: 1.8935\n",
      "Epoch 26/200, Train Loss: 0.5554, Val Loss: 1.9247\n",
      "Epoch 27/200, Train Loss: 0.5069, Val Loss: 1.5631\n",
      "Epoch 28/200, Train Loss: 0.5044, Val Loss: 1.6083\n",
      "Epoch 29/200, Train Loss: 0.5226, Val Loss: 1.7811\n",
      "Early stopping triggered.\n",
      "Test MSE: 4.4706\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 2.1144\n",
      "Test R2: 0.1947\n",
      "Test MAE: 1.7464\n",
      "0    1.669788\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.8993, Val Loss: 3.1663\n",
      "Epoch 2/200, Train Loss: 2.5616, Val Loss: 5.5235\n",
      "Epoch 3/200, Train Loss: 2.5577, Val Loss: 4.2550\n",
      "Epoch 4/200, Train Loss: 2.5293, Val Loss: 5.0968\n",
      "Epoch 5/200, Train Loss: 2.4314, Val Loss: 4.9068\n",
      "Epoch 6/200, Train Loss: 2.3115, Val Loss: 5.3152\n",
      "Epoch 7/200, Train Loss: 2.3146, Val Loss: 4.1162\n",
      "Epoch 8/200, Train Loss: 2.2175, Val Loss: 6.7678\n",
      "Epoch 9/200, Train Loss: 2.1428, Val Loss: 5.6837\n",
      "Epoch 10/200, Train Loss: 2.0976, Val Loss: 5.4132\n",
      "Epoch 11/200, Train Loss: 2.0418, Val Loss: 5.2791\n",
      "Early stopping triggered.\n",
      "Test MSE: 4.1320\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 2.0327\n",
      "Test R2: 0.2557\n",
      "Test MAE: 1.7045\n",
      "0    1.586739\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.3975, Val Loss: 4.3924\n",
      "Epoch 2/200, Train Loss: 3.2174, Val Loss: 2.6546\n",
      "Epoch 3/200, Train Loss: 3.1140, Val Loss: 2.9411\n",
      "Epoch 4/200, Train Loss: 3.0988, Val Loss: 2.4832\n",
      "Epoch 5/200, Train Loss: 3.0749, Val Loss: 2.8498\n",
      "Epoch 6/200, Train Loss: 3.0658, Val Loss: 2.4184\n",
      "Epoch 7/200, Train Loss: 3.0697, Val Loss: 2.6273\n",
      "Epoch 8/200, Train Loss: 3.0743, Val Loss: 2.8466\n",
      "Epoch 9/200, Train Loss: 3.0589, Val Loss: 2.7960\n",
      "Epoch 10/200, Train Loss: 3.0742, Val Loss: 2.8256\n",
      "Epoch 11/200, Train Loss: 3.0398, Val Loss: 3.1859\n",
      "Epoch 12/200, Train Loss: 3.0390, Val Loss: 2.4948\n",
      "Epoch 13/200, Train Loss: 3.0339, Val Loss: 3.4102\n",
      "Epoch 14/200, Train Loss: 3.0528, Val Loss: 2.8369\n",
      "Epoch 15/200, Train Loss: 3.0329, Val Loss: 3.1580\n",
      "Epoch 16/200, Train Loss: 3.0579, Val Loss: 2.7150\n",
      "Early stopping triggered.\n",
      "Test MSE: 5.1551\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 2.2705\n",
      "Test R2: 0.0714\n",
      "Test MAE: 1.8914\n",
      "0    1.228673\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.3738, Val Loss: 3.5856\n",
      "Epoch 2/200, Train Loss: 3.7441, Val Loss: 3.7386\n",
      "Epoch 3/200, Train Loss: 3.4819, Val Loss: 2.7322\n",
      "Epoch 4/200, Train Loss: 2.0214, Val Loss: 2.7764\n",
      "Epoch 5/200, Train Loss: 1.9849, Val Loss: 1.9339\n",
      "Epoch 6/200, Train Loss: 1.9652, Val Loss: 2.3593\n",
      "Epoch 7/200, Train Loss: 1.9333, Val Loss: 2.4864\n",
      "Epoch 8/200, Train Loss: 1.9232, Val Loss: 1.9248\n",
      "Epoch 9/200, Train Loss: 1.9162, Val Loss: 2.5351\n",
      "Epoch 10/200, Train Loss: 1.8963, Val Loss: 2.9010\n",
      "Epoch 11/200, Train Loss: 1.8808, Val Loss: 3.5570\n",
      "Epoch 12/200, Train Loss: 1.8712, Val Loss: 2.2295\n",
      "Epoch 13/200, Train Loss: 1.8640, Val Loss: 2.4704\n",
      "Epoch 14/200, Train Loss: 1.8407, Val Loss: 2.4530\n",
      "Epoch 15/200, Train Loss: 1.8431, Val Loss: 2.5087\n",
      "Epoch 16/200, Train Loss: 1.8251, Val Loss: 2.5795\n",
      "Epoch 17/200, Train Loss: 1.8159, Val Loss: 2.8019\n",
      "Epoch 18/200, Train Loss: 1.9428, Val Loss: 2.4266\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.4028\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.8447\n",
      "Test R2: 0.3870\n",
      "Test MAE: 1.4679\n",
      "0    3.328346\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.3505, Val Loss: 4.1722\n",
      "Epoch 2/200, Train Loss: 3.6475, Val Loss: 4.5335\n",
      "Epoch 3/200, Train Loss: 3.3129, Val Loss: 7.7570\n",
      "Epoch 4/200, Train Loss: 3.1595, Val Loss: 4.1333\n",
      "Epoch 5/200, Train Loss: 3.3946, Val Loss: 4.7668\n",
      "Epoch 6/200, Train Loss: 2.5754, Val Loss: 4.1426\n",
      "Epoch 7/200, Train Loss: 2.2846, Val Loss: 2.8029\n",
      "Epoch 8/200, Train Loss: 2.1314, Val Loss: 2.5947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200, Train Loss: 2.0333, Val Loss: 3.5074\n",
      "Epoch 10/200, Train Loss: 1.9414, Val Loss: 4.2370\n",
      "Epoch 11/200, Train Loss: 1.8792, Val Loss: 3.9735\n",
      "Epoch 12/200, Train Loss: 1.7692, Val Loss: 3.5829\n",
      "Epoch 13/200, Train Loss: 1.6618, Val Loss: 3.0205\n",
      "Epoch 14/200, Train Loss: 1.5656, Val Loss: 3.8096\n",
      "Epoch 15/200, Train Loss: 1.4476, Val Loss: 3.4340\n",
      "Epoch 16/200, Train Loss: 1.3819, Val Loss: 3.9786\n",
      "Epoch 17/200, Train Loss: 1.3042, Val Loss: 3.7103\n",
      "Epoch 18/200, Train Loss: 1.1925, Val Loss: 4.3616\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.9262\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.9815\n",
      "Test R2: 0.2927\n",
      "Test MAE: 1.5715\n",
      "0    1.658502\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.2860, Val Loss: 2.8976\n",
      "Epoch 2/200, Train Loss: 1.3003, Val Loss: 2.7489\n",
      "Epoch 3/200, Train Loss: 1.2835, Val Loss: 3.8122\n",
      "Epoch 4/200, Train Loss: 1.2835, Val Loss: 3.3084\n",
      "Epoch 5/200, Train Loss: 1.2752, Val Loss: 3.4106\n",
      "Epoch 6/200, Train Loss: 1.2775, Val Loss: 3.3835\n",
      "Epoch 7/200, Train Loss: 1.2723, Val Loss: 3.3942\n",
      "Epoch 8/200, Train Loss: 1.2684, Val Loss: 3.5164\n",
      "Epoch 9/200, Train Loss: 1.2637, Val Loss: 3.3342\n",
      "Epoch 10/200, Train Loss: 1.2635, Val Loss: 3.2747\n",
      "Epoch 11/200, Train Loss: 1.2621, Val Loss: 3.9144\n",
      "Epoch 12/200, Train Loss: 1.2636, Val Loss: 3.2789\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.4140\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1891\n",
      "Test R2: 0.6232\n",
      "Test MAE: 0.9341\n",
      "0    2.475388\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.2439, Val Loss: 1.9861\n",
      "Epoch 2/200, Train Loss: 2.6890, Val Loss: 1.9651\n",
      "Epoch 3/200, Train Loss: 2.4929, Val Loss: 1.6134\n",
      "Epoch 4/200, Train Loss: 1.7142, Val Loss: 2.1219\n",
      "Epoch 5/200, Train Loss: 1.6536, Val Loss: 2.4972\n",
      "Epoch 6/200, Train Loss: 1.6241, Val Loss: 1.4868\n",
      "Epoch 7/200, Train Loss: 1.6292, Val Loss: 2.4710\n",
      "Epoch 8/200, Train Loss: 1.6064, Val Loss: 1.8203\n",
      "Epoch 9/200, Train Loss: 1.6154, Val Loss: 1.8485\n",
      "Epoch 10/200, Train Loss: 1.5935, Val Loss: 1.8436\n",
      "Epoch 11/200, Train Loss: 1.5784, Val Loss: 2.3464\n",
      "Epoch 12/200, Train Loss: 1.5733, Val Loss: 2.4923\n",
      "Epoch 13/200, Train Loss: 1.5625, Val Loss: 2.1708\n",
      "Epoch 14/200, Train Loss: 1.5516, Val Loss: 2.4313\n",
      "Epoch 15/200, Train Loss: 1.5488, Val Loss: 2.0124\n",
      "Epoch 16/200, Train Loss: 1.5314, Val Loss: 2.5652\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.3088\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1440\n",
      "Test R2: 0.6512\n",
      "Test MAE: 0.8677\n",
      "0    1.272717\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.5927, Val Loss: 0.1740\n",
      "Epoch 2/200, Train Loss: 0.1860, Val Loss: 0.2025\n",
      "Epoch 3/200, Train Loss: 0.1767, Val Loss: 0.1540\n",
      "Epoch 4/200, Train Loss: 0.1761, Val Loss: 0.1477\n",
      "Epoch 5/200, Train Loss: 0.1690, Val Loss: 0.1462\n",
      "Epoch 6/200, Train Loss: 0.1659, Val Loss: 0.1539\n",
      "Epoch 7/200, Train Loss: 0.1606, Val Loss: 0.1516\n",
      "Epoch 8/200, Train Loss: 0.1599, Val Loss: 0.1458\n",
      "Epoch 9/200, Train Loss: 0.1557, Val Loss: 0.1293\n",
      "Epoch 10/200, Train Loss: 0.1547, Val Loss: 0.1420\n",
      "Epoch 11/200, Train Loss: 0.1504, Val Loss: 0.1612\n",
      "Epoch 12/200, Train Loss: 0.1480, Val Loss: 0.1414\n",
      "Epoch 13/200, Train Loss: 0.1457, Val Loss: 0.1368\n",
      "Epoch 14/200, Train Loss: 0.1449, Val Loss: 0.1338\n",
      "Epoch 15/200, Train Loss: 0.1415, Val Loss: 0.1297\n",
      "Epoch 16/200, Train Loss: 0.1409, Val Loss: 0.1255\n",
      "Epoch 17/200, Train Loss: 0.1386, Val Loss: 0.1268\n",
      "Epoch 18/200, Train Loss: 0.1379, Val Loss: 0.1257\n",
      "Epoch 19/200, Train Loss: 0.1348, Val Loss: 0.1354\n",
      "Epoch 20/200, Train Loss: 0.1340, Val Loss: 0.1329\n",
      "Epoch 21/200, Train Loss: 0.1345, Val Loss: 0.1177\n",
      "Epoch 22/200, Train Loss: 0.1319, Val Loss: 0.1220\n",
      "Epoch 23/200, Train Loss: 0.1300, Val Loss: 0.1163\n",
      "Epoch 24/200, Train Loss: 0.1275, Val Loss: 0.1204\n",
      "Epoch 25/200, Train Loss: 0.1272, Val Loss: 0.1167\n",
      "Epoch 26/200, Train Loss: 0.1248, Val Loss: 0.1236\n",
      "Epoch 27/200, Train Loss: 0.1242, Val Loss: 0.1171\n",
      "Epoch 28/200, Train Loss: 0.1223, Val Loss: 0.1121\n",
      "Epoch 29/200, Train Loss: 0.1214, Val Loss: 0.1175\n",
      "Epoch 30/200, Train Loss: 0.1198, Val Loss: 0.1125\n",
      "Epoch 31/200, Train Loss: 0.1188, Val Loss: 0.1094\n",
      "Epoch 32/200, Train Loss: 0.1185, Val Loss: 0.1236\n",
      "Epoch 33/200, Train Loss: 0.1161, Val Loss: 0.1102\n",
      "Epoch 34/200, Train Loss: 0.1166, Val Loss: 0.1128\n",
      "Epoch 35/200, Train Loss: 0.1149, Val Loss: 0.1087\n",
      "Epoch 36/200, Train Loss: 0.1131, Val Loss: 0.1138\n",
      "Epoch 37/200, Train Loss: 0.1117, Val Loss: 0.1306\n",
      "Epoch 38/200, Train Loss: 0.1117, Val Loss: 0.1159\n",
      "Epoch 39/200, Train Loss: 0.1120, Val Loss: 0.1119\n",
      "Epoch 40/200, Train Loss: 0.1102, Val Loss: 0.1275\n",
      "Epoch 41/200, Train Loss: 0.1099, Val Loss: 0.1197\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.0924\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.3040\n",
      "Test R2: 0.9754\n",
      "Test MAE: 0.1864\n",
      "0    5.896101\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.0290, Val Loss: 1.2633\n",
      "Epoch 2/200, Train Loss: 2.0346, Val Loss: 1.3339\n",
      "Epoch 3/200, Train Loss: 1.9413, Val Loss: 1.2815\n",
      "Epoch 4/200, Train Loss: 1.9129, Val Loss: 1.4046\n",
      "Epoch 5/200, Train Loss: 1.8577, Val Loss: 1.3833\n",
      "Epoch 6/200, Train Loss: 1.7963, Val Loss: 1.8399\n",
      "Epoch 7/200, Train Loss: 1.7098, Val Loss: 1.5451\n",
      "Epoch 8/200, Train Loss: 1.6636, Val Loss: 1.5648\n",
      "Epoch 9/200, Train Loss: 1.6132, Val Loss: 1.3838\n",
      "Epoch 10/200, Train Loss: 1.5697, Val Loss: 1.4511\n",
      "Epoch 11/200, Train Loss: 1.5348, Val Loss: 1.4613\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.3794\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.5425\n",
      "Test R2: 0.3659\n",
      "Test MAE: 1.2570\n",
      "0    0.664548\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.9362, Val Loss: 1.8764\n",
      "Epoch 2/200, Train Loss: 2.1126, Val Loss: 1.7263\n",
      "Epoch 3/200, Train Loss: 2.0635, Val Loss: 1.7010\n",
      "Epoch 4/200, Train Loss: 2.0005, Val Loss: 1.8175\n",
      "Epoch 5/200, Train Loss: 1.8966, Val Loss: 1.9758\n",
      "Epoch 6/200, Train Loss: 1.7109, Val Loss: 2.4103\n",
      "Epoch 7/200, Train Loss: 1.4849, Val Loss: 2.6522\n",
      "Epoch 8/200, Train Loss: 1.2967, Val Loss: 1.7504\n",
      "Epoch 9/200, Train Loss: 1.3395, Val Loss: 2.1599\n",
      "Epoch 10/200, Train Loss: 1.0592, Val Loss: 1.7893\n",
      "Epoch 11/200, Train Loss: 0.9870, Val Loss: 2.1906\n",
      "Epoch 12/200, Train Loss: 1.0225, Val Loss: 1.9495\n",
      "Epoch 13/200, Train Loss: 0.8585, Val Loss: 2.0617\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.0095\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.7348\n",
      "Test R2: 0.1980\n",
      "Test MAE: 1.4185\n",
      "0    2.59273\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.4105, Val Loss: 1.9991\n",
      "Epoch 2/200, Train Loss: 2.5153, Val Loss: 2.9240\n",
      "Epoch 3/200, Train Loss: 2.1706, Val Loss: 2.7642\n",
      "Epoch 4/200, Train Loss: 2.1323, Val Loss: 3.1715\n",
      "Epoch 5/200, Train Loss: 2.1232, Val Loss: 2.9304\n",
      "Epoch 6/200, Train Loss: 2.1088, Val Loss: 3.1702\n",
      "Epoch 7/200, Train Loss: 2.1213, Val Loss: 3.1086\n",
      "Epoch 8/200, Train Loss: 2.1006, Val Loss: 2.9142\n",
      "Epoch 9/200, Train Loss: 2.1560, Val Loss: 2.8572\n",
      "Epoch 10/200, Train Loss: 2.1149, Val Loss: 2.9070\n",
      "Epoch 11/200, Train Loss: 2.1211, Val Loss: 3.2215\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.6958\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.6419\n",
      "Test R2: 0.2816\n",
      "Test MAE: 1.3452\n",
      "0    2.531695\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.4878, Val Loss: 1.9719\n",
      "Epoch 2/200, Train Loss: 2.6925, Val Loss: 1.9964\n",
      "Epoch 3/200, Train Loss: 2.6939, Val Loss: 2.0223\n",
      "Epoch 4/200, Train Loss: 2.6970, Val Loss: 1.9915\n",
      "Epoch 5/200, Train Loss: 2.6935, Val Loss: 2.0034\n",
      "Epoch 6/200, Train Loss: 2.6884, Val Loss: 1.9669\n",
      "Epoch 7/200, Train Loss: 2.6119, Val Loss: 1.7509\n",
      "Epoch 8/200, Train Loss: 2.5997, Val Loss: 1.7071\n",
      "Epoch 9/200, Train Loss: 2.5886, Val Loss: 1.6970\n",
      "Epoch 10/200, Train Loss: 2.5916, Val Loss: 1.8076\n",
      "Epoch 11/200, Train Loss: 2.5834, Val Loss: 1.7092\n",
      "Epoch 12/200, Train Loss: 2.6711, Val Loss: 1.7043\n",
      "Epoch 13/200, Train Loss: 2.6140, Val Loss: 1.8912\n",
      "Epoch 14/200, Train Loss: 2.5912, Val Loss: 1.6558\n",
      "Epoch 15/200, Train Loss: 2.5923, Val Loss: 1.6955\n",
      "Epoch 16/200, Train Loss: 2.5864, Val Loss: 1.7878\n",
      "Epoch 17/200, Train Loss: 2.5865, Val Loss: 1.6848\n",
      "Epoch 18/200, Train Loss: 2.5752, Val Loss: 1.6415\n",
      "Epoch 19/200, Train Loss: 2.6038, Val Loss: 2.0445\n",
      "Epoch 20/200, Train Loss: 2.6541, Val Loss: 1.8486\n",
      "Epoch 21/200, Train Loss: 2.6103, Val Loss: 1.8597\n",
      "Epoch 22/200, Train Loss: 2.5902, Val Loss: 1.6571\n",
      "Epoch 23/200, Train Loss: 2.5849, Val Loss: 1.6876\n",
      "Epoch 24/200, Train Loss: 2.6002, Val Loss: 1.8126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200, Train Loss: 2.5909, Val Loss: 1.6860\n",
      "Epoch 26/200, Train Loss: 2.5849, Val Loss: 1.5935\n",
      "Epoch 27/200, Train Loss: 2.6164, Val Loss: 1.6497\n",
      "Epoch 28/200, Train Loss: 2.5839, Val Loss: 1.8164\n",
      "Epoch 29/200, Train Loss: 2.5793, Val Loss: 1.7080\n",
      "Epoch 30/200, Train Loss: 2.5658, Val Loss: 1.7469\n",
      "Epoch 31/200, Train Loss: 2.5707, Val Loss: 1.9797\n",
      "Epoch 32/200, Train Loss: 2.6655, Val Loss: 1.7494\n",
      "Epoch 33/200, Train Loss: 2.6086, Val Loss: 1.6680\n",
      "Epoch 34/200, Train Loss: 2.5740, Val Loss: 1.7064\n",
      "Epoch 35/200, Train Loss: 2.5737, Val Loss: 1.6253\n",
      "Epoch 36/200, Train Loss: 2.5667, Val Loss: 1.9751\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.9122\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.9779\n",
      "Test R2: -0.0426\n",
      "Test MAE: 1.6376\n",
      "0    0.071197\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.4112, Val Loss: 1.9802\n",
      "Epoch 2/200, Train Loss: 2.6923, Val Loss: 2.1167\n",
      "Epoch 3/200, Train Loss: 2.7025, Val Loss: 1.9790\n",
      "Epoch 4/200, Train Loss: 2.6963, Val Loss: 2.0006\n",
      "Epoch 5/200, Train Loss: 2.6942, Val Loss: 2.0323\n",
      "Epoch 6/200, Train Loss: 2.6955, Val Loss: 1.9962\n",
      "Epoch 7/200, Train Loss: 2.6979, Val Loss: 1.9862\n",
      "Epoch 8/200, Train Loss: 2.6966, Val Loss: 1.9977\n",
      "Epoch 9/200, Train Loss: 2.1957, Val Loss: 2.1204\n",
      "Epoch 10/200, Train Loss: 1.9646, Val Loss: 2.4706\n",
      "Epoch 11/200, Train Loss: 1.9434, Val Loss: 2.1557\n",
      "Epoch 12/200, Train Loss: 1.9380, Val Loss: 2.0995\n",
      "Epoch 13/200, Train Loss: 1.9272, Val Loss: 2.4218\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.1916\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.4804\n",
      "Test R2: 0.4160\n",
      "Test MAE: 1.2463\n",
      "0    1.311592\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.4309, Val Loss: 2.0092\n",
      "Epoch 2/200, Train Loss: 2.6924, Val Loss: 2.0013\n",
      "Epoch 3/200, Train Loss: 2.6970, Val Loss: 2.0083\n",
      "Epoch 4/200, Train Loss: 2.6103, Val Loss: 2.1115\n",
      "Epoch 5/200, Train Loss: 2.5571, Val Loss: 2.2058\n",
      "Epoch 6/200, Train Loss: 2.5506, Val Loss: 2.0986\n",
      "Epoch 7/200, Train Loss: 2.4993, Val Loss: 2.0854\n",
      "Epoch 8/200, Train Loss: 2.4990, Val Loss: 2.2307\n",
      "Epoch 9/200, Train Loss: 2.5285, Val Loss: 2.0784\n",
      "Epoch 10/200, Train Loss: 2.3997, Val Loss: 2.1103\n",
      "Epoch 11/200, Train Loss: 2.2136, Val Loss: 1.8499\n",
      "Epoch 12/200, Train Loss: 2.1787, Val Loss: 1.7790\n",
      "Epoch 13/200, Train Loss: 2.1090, Val Loss: 1.9882\n",
      "Epoch 14/200, Train Loss: 2.0332, Val Loss: 1.8912\n",
      "Epoch 15/200, Train Loss: 2.1053, Val Loss: 1.9671\n",
      "Epoch 16/200, Train Loss: 2.0505, Val Loss: 1.7475\n",
      "Epoch 17/200, Train Loss: 1.9589, Val Loss: 1.6956\n",
      "Epoch 18/200, Train Loss: 1.9268, Val Loss: 1.8286\n",
      "Epoch 19/200, Train Loss: 1.9210, Val Loss: 2.1224\n",
      "Epoch 20/200, Train Loss: 1.8832, Val Loss: 2.2038\n",
      "Epoch 21/200, Train Loss: 1.8392, Val Loss: 1.9333\n",
      "Epoch 22/200, Train Loss: 1.7929, Val Loss: 1.9053\n",
      "Epoch 23/200, Train Loss: 1.7725, Val Loss: 1.8908\n",
      "Epoch 24/200, Train Loss: 1.7691, Val Loss: 1.9262\n",
      "Epoch 25/200, Train Loss: 1.8184, Val Loss: 2.3535\n",
      "Epoch 26/200, Train Loss: 1.6988, Val Loss: 1.9747\n",
      "Epoch 27/200, Train Loss: 1.6709, Val Loss: 2.2885\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.7149\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.9274\n",
      "Test R2: 0.0100\n",
      "Test MAE: 1.6147\n",
      "0    1.005756\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.0511, Val Loss: 3.1806\n",
      "Epoch 2/200, Train Loss: 1.4701, Val Loss: 2.7802\n",
      "Epoch 3/200, Train Loss: 1.4303, Val Loss: 2.7808\n",
      "Epoch 4/200, Train Loss: 1.4100, Val Loss: 2.7594\n",
      "Epoch 5/200, Train Loss: 1.3866, Val Loss: 2.7413\n",
      "Epoch 6/200, Train Loss: 1.3792, Val Loss: 3.4219\n",
      "Epoch 7/200, Train Loss: 1.3748, Val Loss: 2.4809\n",
      "Epoch 8/200, Train Loss: 1.3620, Val Loss: 2.4993\n",
      "Epoch 9/200, Train Loss: 1.3516, Val Loss: 3.1220\n",
      "Epoch 10/200, Train Loss: 1.3526, Val Loss: 2.5307\n",
      "Epoch 11/200, Train Loss: 1.3485, Val Loss: 2.9556\n",
      "Epoch 12/200, Train Loss: 1.3502, Val Loss: 2.9376\n",
      "Epoch 13/200, Train Loss: 1.3482, Val Loss: 2.5227\n",
      "Epoch 14/200, Train Loss: 1.3783, Val Loss: 2.8032\n",
      "Epoch 15/200, Train Loss: 1.3403, Val Loss: 2.6082\n",
      "Epoch 16/200, Train Loss: 1.3250, Val Loss: 2.6665\n",
      "Epoch 17/200, Train Loss: 1.3220, Val Loss: 2.8827\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.6715\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.2929\n",
      "Test R2: 0.6393\n",
      "Test MAE: 1.0451\n",
      "0    4.796689\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.9377, Val Loss: 4.0407\n",
      "Epoch 2/200, Train Loss: 3.6632, Val Loss: 3.8116\n",
      "Epoch 3/200, Train Loss: 3.6636, Val Loss: 3.9059\n",
      "Epoch 4/200, Train Loss: 3.6701, Val Loss: 3.8403\n",
      "Epoch 5/200, Train Loss: 3.6632, Val Loss: 4.0129\n",
      "Epoch 6/200, Train Loss: 3.6663, Val Loss: 3.5832\n",
      "Epoch 7/200, Train Loss: 3.6659, Val Loss: 3.5655\n",
      "Epoch 8/200, Train Loss: 3.6702, Val Loss: 3.6960\n",
      "Epoch 9/200, Train Loss: 3.6639, Val Loss: 3.9892\n",
      "Epoch 10/200, Train Loss: 3.6663, Val Loss: 3.8724\n",
      "Epoch 11/200, Train Loss: 3.6614, Val Loss: 3.2099\n",
      "Epoch 12/200, Train Loss: 3.6646, Val Loss: 3.6310\n",
      "Epoch 13/200, Train Loss: 3.6622, Val Loss: 4.0099\n",
      "Epoch 14/200, Train Loss: 3.6691, Val Loss: 4.1837\n",
      "Epoch 15/200, Train Loss: 3.6636, Val Loss: 3.5734\n",
      "Epoch 16/200, Train Loss: 3.6651, Val Loss: 3.6978\n",
      "Epoch 17/200, Train Loss: 3.6656, Val Loss: 3.9040\n",
      "Epoch 18/200, Train Loss: 3.6663, Val Loss: 3.4578\n",
      "Epoch 19/200, Train Loss: 3.6644, Val Loss: 3.8725\n",
      "Epoch 20/200, Train Loss: 3.6634, Val Loss: 3.4148\n",
      "Epoch 21/200, Train Loss: 3.6684, Val Loss: 3.9580\n",
      "Early stopping triggered.\n",
      "Test MSE: 4.6996\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 2.1679\n",
      "Test R2: -0.0142\n",
      "Test MAE: 1.9024\n",
      "0    0.0\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 0.9186, Val Loss: 0.1188\n",
      "Epoch 2/200, Train Loss: 0.1561, Val Loss: 0.1133\n",
      "Epoch 3/200, Train Loss: 0.1343, Val Loss: 0.0961\n",
      "Epoch 4/200, Train Loss: 0.1072, Val Loss: 0.0899\n",
      "Epoch 5/200, Train Loss: 0.0985, Val Loss: 0.0994\n",
      "Epoch 6/200, Train Loss: 0.0956, Val Loss: 0.0933\n",
      "Epoch 7/200, Train Loss: 0.0939, Val Loss: 0.0889\n",
      "Epoch 8/200, Train Loss: 0.0916, Val Loss: 0.0863\n",
      "Epoch 9/200, Train Loss: 0.0907, Val Loss: 0.1004\n",
      "Epoch 10/200, Train Loss: 0.0902, Val Loss: 0.0898\n",
      "Epoch 11/200, Train Loss: 0.0907, Val Loss: 0.0988\n",
      "Epoch 12/200, Train Loss: 0.0891, Val Loss: 0.0840\n",
      "Epoch 13/200, Train Loss: 0.0881, Val Loss: 0.0888\n",
      "Epoch 14/200, Train Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 15/200, Train Loss: 0.0872, Val Loss: 0.0903\n",
      "Epoch 16/200, Train Loss: 0.0863, Val Loss: 0.0819\n",
      "Epoch 17/200, Train Loss: 0.0861, Val Loss: 0.0864\n",
      "Epoch 18/200, Train Loss: 0.0855, Val Loss: 0.0815\n",
      "Epoch 19/200, Train Loss: 0.0853, Val Loss: 0.0831\n",
      "Epoch 20/200, Train Loss: 0.0846, Val Loss: 0.0880\n",
      "Epoch 21/200, Train Loss: 0.0845, Val Loss: 0.0808\n",
      "Epoch 22/200, Train Loss: 0.0839, Val Loss: 0.0812\n",
      "Epoch 23/200, Train Loss: 0.0825, Val Loss: 0.0824\n",
      "Epoch 24/200, Train Loss: 0.0837, Val Loss: 0.0969\n",
      "Epoch 25/200, Train Loss: 0.0812, Val Loss: 0.0892\n",
      "Epoch 26/200, Train Loss: 0.0811, Val Loss: 0.0878\n",
      "Epoch 27/200, Train Loss: 0.0810, Val Loss: 0.0810\n",
      "Epoch 28/200, Train Loss: 0.0790, Val Loss: 0.0907\n",
      "Epoch 29/200, Train Loss: 0.0790, Val Loss: 0.0863\n",
      "Epoch 30/200, Train Loss: 0.0784, Val Loss: 0.0818\n",
      "Epoch 31/200, Train Loss: 0.0778, Val Loss: 0.0831\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.0669\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.2587\n",
      "Test R2: 0.9856\n",
      "Test MAE: 0.1291\n",
      "0    4.726404\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.2835, Val Loss: 1.4220\n",
      "Epoch 2/200, Train Loss: 2.5329, Val Loss: 1.2839\n",
      "Epoch 3/200, Train Loss: 2.5135, Val Loss: 1.8776\n",
      "Epoch 4/200, Train Loss: 2.4977, Val Loss: 1.7980\n",
      "Epoch 5/200, Train Loss: 2.4874, Val Loss: 1.4838\n",
      "Epoch 6/200, Train Loss: 2.4944, Val Loss: 1.6893\n",
      "Epoch 7/200, Train Loss: 2.4815, Val Loss: 1.7970\n",
      "Epoch 8/200, Train Loss: 2.4645, Val Loss: 1.6649\n",
      "Epoch 9/200, Train Loss: 2.4537, Val Loss: 1.5725\n",
      "Epoch 10/200, Train Loss: 2.4619, Val Loss: 2.0802\n",
      "Epoch 11/200, Train Loss: 2.4651, Val Loss: 1.6634\n",
      "Epoch 12/200, Train Loss: 2.4443, Val Loss: 1.6071\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.4512\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.8577\n",
      "Test R2: 0.2552\n",
      "Test MAE: 1.5279\n",
      "0    1.152907\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.3967, Val Loss: 3.3010\n",
      "Epoch 2/200, Train Loss: 1.9119, Val Loss: 3.4818\n",
      "Epoch 3/200, Train Loss: 1.8795, Val Loss: 4.0416\n",
      "Epoch 4/200, Train Loss: 1.8294, Val Loss: 3.5425\n",
      "Epoch 5/200, Train Loss: 1.8167, Val Loss: 3.1279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss: 1.7713, Val Loss: 3.8486\n",
      "Epoch 7/200, Train Loss: 1.7394, Val Loss: 2.9787\n",
      "Epoch 8/200, Train Loss: 1.7114, Val Loss: 3.3107\n",
      "Epoch 9/200, Train Loss: 1.6727, Val Loss: 3.5792\n",
      "Epoch 10/200, Train Loss: 1.6590, Val Loss: 4.1144\n",
      "Epoch 11/200, Train Loss: 1.6277, Val Loss: 4.0057\n",
      "Epoch 12/200, Train Loss: 1.5937, Val Loss: 3.9737\n",
      "Epoch 13/200, Train Loss: 1.5682, Val Loss: 3.3418\n",
      "Epoch 14/200, Train Loss: 1.5512, Val Loss: 3.4269\n",
      "Epoch 15/200, Train Loss: 1.5325, Val Loss: 4.0297\n",
      "Epoch 16/200, Train Loss: 1.5316, Val Loss: 3.7481\n",
      "Epoch 17/200, Train Loss: 1.4152, Val Loss: 4.0384\n",
      "Early stopping triggered.\n",
      "Test MSE: 4.7788\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 2.1860\n",
      "Test R2: -0.0313\n",
      "Test MAE: 1.8185\n",
      "0    3.766946\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.9578, Val Loss: 4.6487\n",
      "Epoch 2/200, Train Loss: 3.4189, Val Loss: 3.0221\n",
      "Epoch 3/200, Train Loss: 3.4151, Val Loss: 3.1708\n",
      "Epoch 4/200, Train Loss: 3.3035, Val Loss: 3.3945\n",
      "Epoch 5/200, Train Loss: 3.2434, Val Loss: 3.1578\n",
      "Epoch 6/200, Train Loss: 3.1894, Val Loss: 3.2465\n",
      "Epoch 7/200, Train Loss: 3.1937, Val Loss: 2.8623\n",
      "Epoch 8/200, Train Loss: 3.1971, Val Loss: 3.5621\n",
      "Epoch 9/200, Train Loss: 3.1768, Val Loss: 3.4972\n",
      "Epoch 10/200, Train Loss: 3.1406, Val Loss: 2.9342\n",
      "Epoch 11/200, Train Loss: 3.1071, Val Loss: 3.2760\n",
      "Epoch 12/200, Train Loss: 3.0448, Val Loss: 3.0541\n",
      "Epoch 13/200, Train Loss: 3.0605, Val Loss: 2.6985\n",
      "Epoch 14/200, Train Loss: 3.0875, Val Loss: 2.7941\n",
      "Epoch 15/200, Train Loss: 2.8953, Val Loss: 3.8989\n",
      "Epoch 16/200, Train Loss: 2.7320, Val Loss: 4.8933\n",
      "Epoch 17/200, Train Loss: 2.6141, Val Loss: 4.1281\n",
      "Epoch 18/200, Train Loss: 2.5293, Val Loss: 3.3735\n",
      "Epoch 19/200, Train Loss: 2.4448, Val Loss: 3.5946\n",
      "Epoch 20/200, Train Loss: 2.3469, Val Loss: 3.9013\n",
      "Epoch 21/200, Train Loss: 2.2955, Val Loss: 3.4068\n",
      "Epoch 22/200, Train Loss: 2.2838, Val Loss: 3.5015\n",
      "Epoch 23/200, Train Loss: 2.1869, Val Loss: 3.2978\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.7431\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.6562\n",
      "Test R2: 0.4080\n",
      "Test MAE: 1.3753\n",
      "0    3.384661\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.0452, Val Loss: 3.7977\n",
      "Epoch 2/200, Train Loss: 2.0405, Val Loss: 2.7447\n",
      "Epoch 3/200, Train Loss: 2.0113, Val Loss: 3.2240\n",
      "Epoch 4/200, Train Loss: 1.9874, Val Loss: 3.2992\n",
      "Epoch 5/200, Train Loss: 1.9597, Val Loss: 2.9924\n",
      "Epoch 6/200, Train Loss: 1.9149, Val Loss: 2.5400\n",
      "Epoch 7/200, Train Loss: 1.8794, Val Loss: 2.6024\n",
      "Epoch 8/200, Train Loss: 1.8294, Val Loss: 3.4624\n",
      "Epoch 9/200, Train Loss: 1.7550, Val Loss: 3.1241\n",
      "Epoch 10/200, Train Loss: 1.7147, Val Loss: 2.4811\n",
      "Epoch 11/200, Train Loss: 1.6799, Val Loss: 2.4502\n",
      "Epoch 12/200, Train Loss: 1.6692, Val Loss: 2.6429\n",
      "Epoch 13/200, Train Loss: 1.6324, Val Loss: 2.3189\n",
      "Epoch 14/200, Train Loss: 1.5853, Val Loss: 2.9442\n",
      "Epoch 15/200, Train Loss: 1.4953, Val Loss: 2.5391\n",
      "Epoch 16/200, Train Loss: 1.4949, Val Loss: 2.5331\n",
      "Epoch 17/200, Train Loss: 1.4374, Val Loss: 2.7258\n",
      "Epoch 18/200, Train Loss: 1.3824, Val Loss: 2.4280\n",
      "Epoch 19/200, Train Loss: 1.3819, Val Loss: 2.6604\n",
      "Epoch 20/200, Train Loss: 1.2851, Val Loss: 2.7177\n",
      "Epoch 21/200, Train Loss: 1.2356, Val Loss: 2.3128\n",
      "Epoch 22/200, Train Loss: 1.1470, Val Loss: 2.7318\n",
      "Epoch 23/200, Train Loss: 1.1357, Val Loss: 2.8649\n",
      "Epoch 24/200, Train Loss: 1.0643, Val Loss: 2.7423\n",
      "Epoch 25/200, Train Loss: 0.9953, Val Loss: 3.0368\n",
      "Epoch 26/200, Train Loss: 0.9304, Val Loss: 2.6068\n",
      "Epoch 27/200, Train Loss: 0.8863, Val Loss: 2.7836\n",
      "Epoch 28/200, Train Loss: 0.8377, Val Loss: 2.6636\n",
      "Epoch 29/200, Train Loss: 0.8208, Val Loss: 2.4342\n",
      "Epoch 30/200, Train Loss: 0.7294, Val Loss: 2.8738\n",
      "Epoch 31/200, Train Loss: 0.6875, Val Loss: 3.1302\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.0295\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.4246\n",
      "Test R2: 0.5620\n",
      "Test MAE: 1.0870\n",
      "0    2.824726\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.9950, Val Loss: 3.3808\n",
      "Epoch 2/200, Train Loss: 3.6642, Val Loss: 3.4792\n",
      "Epoch 3/200, Train Loss: 3.4234, Val Loss: 2.5332\n",
      "Epoch 4/200, Train Loss: 1.8856, Val Loss: 2.6956\n",
      "Epoch 5/200, Train Loss: 1.8152, Val Loss: 2.5131\n",
      "Epoch 6/200, Train Loss: 1.8027, Val Loss: 2.5314\n",
      "Epoch 7/200, Train Loss: 1.7899, Val Loss: 2.8037\n",
      "Epoch 8/200, Train Loss: 1.8025, Val Loss: 2.6423\n",
      "Epoch 9/200, Train Loss: 1.7794, Val Loss: 2.6243\n",
      "Epoch 10/200, Train Loss: 1.7797, Val Loss: 2.6066\n",
      "Epoch 11/200, Train Loss: 1.7661, Val Loss: 3.1041\n",
      "Epoch 12/200, Train Loss: 1.7618, Val Loss: 2.7619\n",
      "Epoch 13/200, Train Loss: 1.7590, Val Loss: 2.6355\n",
      "Epoch 14/200, Train Loss: 1.7464, Val Loss: 2.5911\n",
      "Epoch 15/200, Train Loss: 1.7534, Val Loss: 2.7709\n",
      "Early stopping triggered.\n",
      "Test MSE: 6.7741\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 2.6027\n",
      "Test R2: -0.4619\n",
      "Test MAE: 2.2226\n",
      "0    5.701564\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.7427, Val Loss: 1.5424\n",
      "Epoch 2/200, Train Loss: 2.1702, Val Loss: 1.4231\n",
      "Epoch 3/200, Train Loss: 2.1154, Val Loss: 1.8938\n",
      "Epoch 4/200, Train Loss: 2.1615, Val Loss: 1.4138\n",
      "Epoch 5/200, Train Loss: 2.1468, Val Loss: 1.6560\n",
      "Epoch 6/200, Train Loss: 2.1154, Val Loss: 1.5187\n",
      "Epoch 7/200, Train Loss: 1.8989, Val Loss: 1.2310\n",
      "Epoch 8/200, Train Loss: 1.6946, Val Loss: 1.2810\n",
      "Epoch 9/200, Train Loss: 1.7294, Val Loss: 1.3322\n",
      "Epoch 10/200, Train Loss: 1.5944, Val Loss: 1.1900\n",
      "Epoch 11/200, Train Loss: 1.5197, Val Loss: 1.2565\n",
      "Epoch 12/200, Train Loss: 1.7078, Val Loss: 1.3748\n",
      "Epoch 13/200, Train Loss: 1.6664, Val Loss: 1.2499\n",
      "Epoch 14/200, Train Loss: 1.5574, Val Loss: 1.2696\n",
      "Epoch 15/200, Train Loss: 1.4963, Val Loss: 1.1598\n",
      "Epoch 16/200, Train Loss: 1.4564, Val Loss: 1.3258\n",
      "Epoch 17/200, Train Loss: 1.3649, Val Loss: 1.3273\n",
      "Epoch 18/200, Train Loss: 1.3292, Val Loss: 1.2216\n",
      "Epoch 19/200, Train Loss: 1.3292, Val Loss: 1.3937\n",
      "Epoch 20/200, Train Loss: 1.2901, Val Loss: 1.3525\n",
      "Epoch 21/200, Train Loss: 1.2540, Val Loss: 1.3353\n",
      "Epoch 22/200, Train Loss: 1.2677, Val Loss: 1.3877\n",
      "Epoch 23/200, Train Loss: 1.2959, Val Loss: 1.3051\n",
      "Epoch 24/200, Train Loss: 1.1980, Val Loss: 1.2203\n",
      "Epoch 25/200, Train Loss: 1.1501, Val Loss: 1.4174\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.2732\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.8092\n",
      "Test R2: 0.2936\n",
      "Test MAE: 1.3056\n",
      "0    3.09537\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.8609, Val Loss: 1.3359\n",
      "Epoch 2/200, Train Loss: 1.1762, Val Loss: 1.5965\n",
      "Epoch 3/200, Train Loss: 1.1722, Val Loss: 1.5471\n",
      "Epoch 4/200, Train Loss: 1.1647, Val Loss: 1.2446\n",
      "Epoch 5/200, Train Loss: 1.1602, Val Loss: 1.2627\n",
      "Epoch 6/200, Train Loss: 1.1567, Val Loss: 1.2668\n",
      "Epoch 7/200, Train Loss: 1.1585, Val Loss: 1.2812\n",
      "Epoch 8/200, Train Loss: 1.1488, Val Loss: 1.4831\n",
      "Epoch 9/200, Train Loss: 1.1415, Val Loss: 1.5776\n",
      "Epoch 10/200, Train Loss: 1.1406, Val Loss: 1.4366\n",
      "Epoch 11/200, Train Loss: 1.1369, Val Loss: 1.2370\n",
      "Epoch 12/200, Train Loss: 1.1250, Val Loss: 1.4237\n",
      "Epoch 13/200, Train Loss: 1.1228, Val Loss: 1.5880\n",
      "Epoch 14/200, Train Loss: 1.1167, Val Loss: 1.3581\n",
      "Epoch 15/200, Train Loss: 1.1015, Val Loss: 1.5009\n",
      "Epoch 16/200, Train Loss: 1.0832, Val Loss: 1.1741\n",
      "Epoch 17/200, Train Loss: 1.0734, Val Loss: 1.3580\n",
      "Epoch 18/200, Train Loss: 1.0943, Val Loss: 1.1360\n",
      "Epoch 19/200, Train Loss: 1.0652, Val Loss: 1.3373\n",
      "Epoch 20/200, Train Loss: 1.0498, Val Loss: 1.5464\n",
      "Epoch 21/200, Train Loss: 1.0494, Val Loss: 1.1379\n",
      "Epoch 22/200, Train Loss: 1.0454, Val Loss: 1.4953\n",
      "Epoch 23/200, Train Loss: 1.0418, Val Loss: 1.6421\n",
      "Epoch 24/200, Train Loss: 1.0412, Val Loss: 1.2421\n",
      "Epoch 25/200, Train Loss: 1.0557, Val Loss: 1.3541\n",
      "Epoch 26/200, Train Loss: 1.0667, Val Loss: 1.1789\n",
      "Epoch 27/200, Train Loss: 1.0601, Val Loss: 1.4343\n",
      "Epoch 28/200, Train Loss: 1.0582, Val Loss: 1.2305\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.9583\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.9789\n",
      "Test R2: 0.7028\n",
      "Test MAE: 0.7784\n",
      "0    2.95733\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.1989, Val Loss: 1.7960\n",
      "Epoch 2/200, Train Loss: 2.7256, Val Loss: 1.6378\n",
      "Epoch 3/200, Train Loss: 2.7181, Val Loss: 1.7152\n",
      "Epoch 4/200, Train Loss: 2.7156, Val Loss: 1.5487\n",
      "Epoch 5/200, Train Loss: 2.5088, Val Loss: 1.0578\n",
      "Epoch 6/200, Train Loss: 1.9389, Val Loss: 1.0530\n",
      "Epoch 7/200, Train Loss: 1.6411, Val Loss: 1.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Train Loss: 1.6103, Val Loss: 1.0428\n",
      "Epoch 9/200, Train Loss: 1.5497, Val Loss: 1.1833\n",
      "Epoch 10/200, Train Loss: 1.5796, Val Loss: 1.1538\n",
      "Epoch 11/200, Train Loss: 1.5297, Val Loss: 1.2188\n",
      "Epoch 12/200, Train Loss: 1.5225, Val Loss: 1.0387\n",
      "Epoch 13/200, Train Loss: 1.4996, Val Loss: 1.2386\n",
      "Epoch 14/200, Train Loss: 1.5263, Val Loss: 1.2256\n",
      "Epoch 15/200, Train Loss: 1.4953, Val Loss: 1.2369\n",
      "Epoch 16/200, Train Loss: 1.4922, Val Loss: 1.3942\n",
      "Epoch 17/200, Train Loss: 1.4765, Val Loss: 1.1897\n",
      "Early stopping triggered.\n",
      "Test MSE: 4.0335\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 2.0084\n",
      "Test R2: -0.2509\n",
      "Test MAE: 1.6704\n",
      "0    2.174266\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.2009, Val Loss: 0.0572\n",
      "Epoch 2/200, Train Loss: 0.1599, Val Loss: 0.1123\n",
      "Epoch 3/200, Train Loss: 0.1538, Val Loss: 0.0526\n",
      "Epoch 4/200, Train Loss: 0.1529, Val Loss: 0.0508\n",
      "Epoch 5/200, Train Loss: 0.1510, Val Loss: 0.0494\n",
      "Epoch 6/200, Train Loss: 0.1520, Val Loss: 0.0462\n",
      "Epoch 7/200, Train Loss: 0.1467, Val Loss: 0.0487\n",
      "Epoch 8/200, Train Loss: 0.1469, Val Loss: 0.0508\n",
      "Epoch 9/200, Train Loss: 0.1450, Val Loss: 0.0535\n",
      "Epoch 10/200, Train Loss: 0.1444, Val Loss: 0.0429\n",
      "Epoch 11/200, Train Loss: 0.1421, Val Loss: 0.0514\n",
      "Epoch 12/200, Train Loss: 0.1411, Val Loss: 0.0445\n",
      "Epoch 13/200, Train Loss: 0.1413, Val Loss: 0.0466\n",
      "Epoch 14/200, Train Loss: 0.1398, Val Loss: 0.0489\n",
      "Epoch 15/200, Train Loss: 0.1383, Val Loss: 0.0431\n",
      "Epoch 16/200, Train Loss: 0.1377, Val Loss: 0.0433\n",
      "Epoch 17/200, Train Loss: 0.1375, Val Loss: 0.0627\n",
      "Epoch 18/200, Train Loss: 0.1360, Val Loss: 0.0479\n",
      "Epoch 19/200, Train Loss: 0.1430, Val Loss: 0.0443\n",
      "Epoch 20/200, Train Loss: 0.1349, Val Loss: 0.0458\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.0501\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.2239\n",
      "Test R2: 0.9844\n",
      "Test MAE: 0.1401\n",
      "0    5.292203\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.9866, Val Loss: 1.7245\n",
      "Epoch 2/200, Train Loss: 2.3158, Val Loss: 2.0307\n",
      "Epoch 3/200, Train Loss: 2.2385, Val Loss: 2.1813\n",
      "Epoch 4/200, Train Loss: 2.1925, Val Loss: 2.1891\n",
      "Epoch 5/200, Train Loss: 2.1708, Val Loss: 1.5912\n",
      "Epoch 6/200, Train Loss: 2.1618, Val Loss: 2.1189\n",
      "Epoch 7/200, Train Loss: 2.1294, Val Loss: 2.1893\n",
      "Epoch 8/200, Train Loss: 2.1035, Val Loss: 2.0158\n",
      "Epoch 9/200, Train Loss: 2.0745, Val Loss: 1.9437\n",
      "Epoch 10/200, Train Loss: 2.0741, Val Loss: 2.0185\n",
      "Epoch 11/200, Train Loss: 2.0426, Val Loss: 1.9873\n",
      "Epoch 12/200, Train Loss: 2.0279, Val Loss: 1.8809\n",
      "Epoch 13/200, Train Loss: 1.9816, Val Loss: 2.1236\n",
      "Epoch 14/200, Train Loss: 1.9558, Val Loss: 1.9751\n",
      "Epoch 15/200, Train Loss: 1.9370, Val Loss: 2.5940\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.2188\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.7941\n",
      "Test R2: 0.0017\n",
      "Test MAE: 1.4182\n",
      "0    9.38208\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.9459, Val Loss: 1.8314\n",
      "Epoch 2/200, Train Loss: 2.2598, Val Loss: 1.6706\n",
      "Epoch 3/200, Train Loss: 2.2100, Val Loss: 2.1477\n",
      "Epoch 4/200, Train Loss: 2.1664, Val Loss: 1.8137\n",
      "Epoch 5/200, Train Loss: 2.1258, Val Loss: 2.2691\n",
      "Epoch 6/200, Train Loss: 2.0902, Val Loss: 1.9716\n",
      "Epoch 7/200, Train Loss: 2.0584, Val Loss: 2.4013\n",
      "Epoch 8/200, Train Loss: 2.0104, Val Loss: 1.9506\n",
      "Epoch 9/200, Train Loss: 1.9702, Val Loss: 2.4973\n",
      "Epoch 10/200, Train Loss: 1.9009, Val Loss: 2.0358\n",
      "Epoch 11/200, Train Loss: 1.7800, Val Loss: 2.3310\n",
      "Epoch 12/200, Train Loss: 1.6689, Val Loss: 3.5392\n",
      "Early stopping triggered.\n",
      "Test MSE: 4.1697\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 2.0420\n",
      "Test R2: -0.2932\n",
      "Test MAE: 1.6058\n",
      "0    1.751392\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.2734, Val Loss: 2.1323\n",
      "Epoch 2/200, Train Loss: 2.7262, Val Loss: 1.6539\n",
      "Epoch 3/200, Train Loss: 2.7223, Val Loss: 1.5872\n",
      "Epoch 4/200, Train Loss: 2.7000, Val Loss: 1.5757\n",
      "Epoch 5/200, Train Loss: 2.7233, Val Loss: 1.6446\n",
      "Epoch 6/200, Train Loss: 2.7223, Val Loss: 1.7418\n",
      "Epoch 7/200, Train Loss: 2.7137, Val Loss: 1.5203\n",
      "Epoch 8/200, Train Loss: 2.6458, Val Loss: 1.8069\n",
      "Epoch 9/200, Train Loss: 2.5290, Val Loss: 2.2128\n",
      "Epoch 10/200, Train Loss: 2.4777, Val Loss: 1.9893\n",
      "Epoch 11/200, Train Loss: 2.5187, Val Loss: 2.2002\n",
      "Epoch 12/200, Train Loss: 2.4707, Val Loss: 1.7294\n",
      "Epoch 13/200, Train Loss: 2.4811, Val Loss: 1.9852\n",
      "Epoch 14/200, Train Loss: 2.4429, Val Loss: 2.3104\n",
      "Epoch 15/200, Train Loss: 2.4502, Val Loss: 2.2133\n",
      "Epoch 16/200, Train Loss: 2.5131, Val Loss: 1.6357\n",
      "Epoch 17/200, Train Loss: 2.4511, Val Loss: 2.3965\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.4000\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.8439\n",
      "Test R2: -0.0544\n",
      "Test MAE: 1.4441\n",
      "0    0.04051\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.2768, Val Loss: 1.7225\n",
      "Epoch 2/200, Train Loss: 2.7215, Val Loss: 1.6466\n",
      "Epoch 3/200, Train Loss: 2.7218, Val Loss: 1.6151\n",
      "Epoch 4/200, Train Loss: 2.7214, Val Loss: 1.5445\n",
      "Epoch 5/200, Train Loss: 2.7233, Val Loss: 1.5680\n",
      "Epoch 6/200, Train Loss: 2.7251, Val Loss: 1.7575\n",
      "Epoch 7/200, Train Loss: 2.7281, Val Loss: 1.5792\n",
      "Epoch 8/200, Train Loss: 2.7228, Val Loss: 1.4585\n",
      "Epoch 9/200, Train Loss: 2.7195, Val Loss: 1.7307\n",
      "Epoch 10/200, Train Loss: 2.7247, Val Loss: 1.8676\n",
      "Epoch 11/200, Train Loss: 2.7218, Val Loss: 1.6274\n",
      "Epoch 12/200, Train Loss: 2.7261, Val Loss: 1.6656\n",
      "Epoch 13/200, Train Loss: 2.7215, Val Loss: 1.9419\n",
      "Epoch 14/200, Train Loss: 2.7225, Val Loss: 1.8593\n",
      "Epoch 15/200, Train Loss: 2.7129, Val Loss: 1.6185\n",
      "Epoch 16/200, Train Loss: 2.6478, Val Loss: 1.5327\n",
      "Epoch 17/200, Train Loss: 2.6353, Val Loss: 1.7665\n",
      "Epoch 18/200, Train Loss: 2.6553, Val Loss: 1.7642\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.4515\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.8578\n",
      "Test R2: -0.0704\n",
      "Test MAE: 1.4451\n",
      "0    0.000188\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.3146, Val Loss: 1.7363\n",
      "Epoch 2/200, Train Loss: 2.7278, Val Loss: 1.6640\n",
      "Epoch 3/200, Train Loss: 2.7215, Val Loss: 1.5876\n",
      "Epoch 4/200, Train Loss: 2.7255, Val Loss: 1.7489\n",
      "Epoch 5/200, Train Loss: 2.7235, Val Loss: 1.8658\n",
      "Epoch 6/200, Train Loss: 2.7197, Val Loss: 1.5258\n",
      "Epoch 7/200, Train Loss: 2.5888, Val Loss: 2.2908\n",
      "Epoch 8/200, Train Loss: 2.4618, Val Loss: 2.3603\n",
      "Epoch 9/200, Train Loss: 2.4429, Val Loss: 2.1077\n",
      "Epoch 10/200, Train Loss: 2.4363, Val Loss: 2.3603\n",
      "Epoch 11/200, Train Loss: 2.4524, Val Loss: 2.1479\n",
      "Epoch 12/200, Train Loss: 2.4827, Val Loss: 1.6309\n",
      "Epoch 13/200, Train Loss: 2.5374, Val Loss: 2.1306\n",
      "Epoch 14/200, Train Loss: 2.4981, Val Loss: 1.5349\n",
      "Epoch 15/200, Train Loss: 2.5120, Val Loss: 1.9616\n",
      "Epoch 16/200, Train Loss: 2.6620, Val Loss: 1.5203\n",
      "Epoch 17/200, Train Loss: 2.5253, Val Loss: 1.5615\n",
      "Epoch 18/200, Train Loss: 2.5196, Val Loss: 1.7312\n",
      "Epoch 19/200, Train Loss: 2.4888, Val Loss: 2.3472\n",
      "Epoch 20/200, Train Loss: 2.4529, Val Loss: 2.2491\n",
      "Epoch 21/200, Train Loss: 2.5806, Val Loss: 1.5441\n",
      "Epoch 22/200, Train Loss: 2.5409, Val Loss: 2.0291\n",
      "Epoch 23/200, Train Loss: 2.4419, Val Loss: 2.2657\n",
      "Epoch 24/200, Train Loss: 2.4278, Val Loss: 2.2136\n",
      "Epoch 25/200, Train Loss: 2.3704, Val Loss: 2.2901\n",
      "Epoch 26/200, Train Loss: 2.4698, Val Loss: 1.9205\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.2082\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.7912\n",
      "Test R2: 0.0050\n",
      "Test MAE: 1.4016\n",
      "0    0.10351\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.2747, Val Loss: 1.6534\n",
      "Epoch 2/200, Train Loss: 2.7227, Val Loss: 1.5101\n",
      "Epoch 3/200, Train Loss: 2.7232, Val Loss: 1.8993\n",
      "Epoch 4/200, Train Loss: 2.7065, Val Loss: 1.9421\n",
      "Epoch 5/200, Train Loss: 2.6612, Val Loss: 2.0070\n",
      "Epoch 6/200, Train Loss: 2.6486, Val Loss: 2.0997\n",
      "Epoch 7/200, Train Loss: 2.6495, Val Loss: 2.0204\n",
      "Epoch 8/200, Train Loss: 2.6383, Val Loss: 2.1855\n",
      "Epoch 9/200, Train Loss: 2.6365, Val Loss: 1.8054\n",
      "Epoch 10/200, Train Loss: 2.6318, Val Loss: 1.9949\n",
      "Epoch 11/200, Train Loss: 2.6032, Val Loss: 1.6887\n",
      "Epoch 12/200, Train Loss: 2.6186, Val Loss: 2.2561\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.3144\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.8205\n",
      "Test R2: -0.0279\n",
      "Test MAE: 1.4092\n",
      "0    2.10949\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.6497, Val Loss: 1.8103\n",
      "Epoch 2/200, Train Loss: 1.2548, Val Loss: 2.1216\n",
      "Epoch 3/200, Train Loss: 1.2549, Val Loss: 1.4072\n",
      "Epoch 4/200, Train Loss: 1.2511, Val Loss: 1.6640\n",
      "Epoch 5/200, Train Loss: 1.2494, Val Loss: 1.6973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss: 1.2435, Val Loss: 1.8034\n",
      "Epoch 7/200, Train Loss: 1.2386, Val Loss: 1.6446\n",
      "Epoch 8/200, Train Loss: 1.2376, Val Loss: 1.8677\n",
      "Epoch 9/200, Train Loss: 1.2372, Val Loss: 1.5498\n",
      "Epoch 10/200, Train Loss: 1.2337, Val Loss: 1.5622\n",
      "Epoch 11/200, Train Loss: 1.2346, Val Loss: 1.8121\n",
      "Epoch 12/200, Train Loss: 1.2368, Val Loss: 1.4565\n",
      "Epoch 13/200, Train Loss: 1.2347, Val Loss: 1.8536\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.3605\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1664\n",
      "Test R2: 0.4461\n",
      "Test MAE: 0.9877\n",
      "0    1.403514\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.2979, Val Loss: 0.9521\n",
      "Epoch 2/200, Train Loss: 1.9791, Val Loss: 0.9503\n",
      "Epoch 3/200, Train Loss: 1.9732, Val Loss: 0.9731\n",
      "Epoch 4/200, Train Loss: 1.9351, Val Loss: 1.0165\n",
      "Epoch 5/200, Train Loss: 1.3516, Val Loss: 0.7832\n",
      "Epoch 6/200, Train Loss: 1.2131, Val Loss: 0.7654\n",
      "Epoch 7/200, Train Loss: 1.1970, Val Loss: 0.8385\n",
      "Epoch 8/200, Train Loss: 1.1845, Val Loss: 0.7979\n",
      "Epoch 9/200, Train Loss: 1.1738, Val Loss: 0.8912\n",
      "Epoch 10/200, Train Loss: 1.1615, Val Loss: 0.7710\n",
      "Epoch 11/200, Train Loss: 1.1638, Val Loss: 0.8478\n",
      "Epoch 12/200, Train Loss: 1.1634, Val Loss: 0.8757\n",
      "Epoch 13/200, Train Loss: 1.1563, Val Loss: 0.7300\n",
      "Epoch 14/200, Train Loss: 1.1532, Val Loss: 0.9792\n",
      "Epoch 15/200, Train Loss: 1.1458, Val Loss: 0.9665\n",
      "Epoch 16/200, Train Loss: 1.1298, Val Loss: 0.7372\n",
      "Epoch 17/200, Train Loss: 1.1215, Val Loss: 0.7918\n",
      "Epoch 18/200, Train Loss: 1.1196, Val Loss: 0.7324\n",
      "Epoch 19/200, Train Loss: 1.1143, Val Loss: 0.8233\n",
      "Epoch 20/200, Train Loss: 1.0981, Val Loss: 0.9069\n",
      "Epoch 21/200, Train Loss: 1.1033, Val Loss: 1.1137\n",
      "Epoch 22/200, Train Loss: 1.0896, Val Loss: 0.7982\n",
      "Epoch 23/200, Train Loss: 1.0775, Val Loss: 0.7820\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.1935\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.0925\n",
      "Test R2: 0.5141\n",
      "Test MAE: 0.8784\n",
      "0    1.261585\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 0.9525, Val Loss: 0.1646\n",
      "Epoch 2/200, Train Loss: 0.3118, Val Loss: 0.1441\n",
      "Epoch 3/200, Train Loss: 0.3061, Val Loss: 0.1396\n",
      "Epoch 4/200, Train Loss: 0.3027, Val Loss: 0.1525\n",
      "Epoch 5/200, Train Loss: 0.2975, Val Loss: 0.1362\n",
      "Epoch 6/200, Train Loss: 0.2980, Val Loss: 0.1454\n",
      "Epoch 7/200, Train Loss: 0.2976, Val Loss: 0.1639\n",
      "Epoch 8/200, Train Loss: 0.2961, Val Loss: 0.1448\n",
      "Epoch 9/200, Train Loss: 0.2938, Val Loss: 0.1632\n",
      "Epoch 10/200, Train Loss: 0.2916, Val Loss: 0.1410\n",
      "Epoch 11/200, Train Loss: 0.2951, Val Loss: 0.1462\n",
      "Epoch 12/200, Train Loss: 0.2943, Val Loss: 0.1452\n",
      "Epoch 13/200, Train Loss: 0.2893, Val Loss: 0.1466\n",
      "Epoch 14/200, Train Loss: 0.2894, Val Loss: 0.1438\n",
      "Epoch 15/200, Train Loss: 0.2881, Val Loss: 0.1401\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.1272\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.3566\n",
      "Test R2: 0.9482\n",
      "Test MAE: 0.2466\n",
      "0    5.394052\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.9491, Val Loss: 1.5278\n",
      "Epoch 2/200, Train Loss: 1.4371, Val Loss: 1.3397\n",
      "Epoch 3/200, Train Loss: 1.4667, Val Loss: 1.3224\n",
      "Epoch 4/200, Train Loss: 1.4017, Val Loss: 1.7375\n",
      "Epoch 5/200, Train Loss: 1.3801, Val Loss: 1.3939\n",
      "Epoch 6/200, Train Loss: 1.3772, Val Loss: 1.3520\n",
      "Epoch 7/200, Train Loss: 1.3575, Val Loss: 1.4269\n",
      "Epoch 8/200, Train Loss: 1.3488, Val Loss: 1.5107\n",
      "Epoch 9/200, Train Loss: 1.3369, Val Loss: 1.2768\n",
      "Epoch 10/200, Train Loss: 1.3183, Val Loss: 1.3415\n",
      "Epoch 11/200, Train Loss: 1.3172, Val Loss: 1.3316\n",
      "Epoch 12/200, Train Loss: 1.3159, Val Loss: 1.7619\n",
      "Epoch 13/200, Train Loss: 1.3022, Val Loss: 1.3250\n",
      "Epoch 14/200, Train Loss: 1.2972, Val Loss: 1.5428\n",
      "Epoch 15/200, Train Loss: 1.2972, Val Loss: 1.4105\n",
      "Epoch 16/200, Train Loss: 1.2986, Val Loss: 1.3837\n",
      "Epoch 17/200, Train Loss: 1.2858, Val Loss: 1.4392\n",
      "Epoch 18/200, Train Loss: 1.2861, Val Loss: 1.3410\n",
      "Epoch 19/200, Train Loss: 1.4335, Val Loss: 0.9707\n",
      "Epoch 20/200, Train Loss: 1.5405, Val Loss: 1.3849\n",
      "Epoch 21/200, Train Loss: 1.3645, Val Loss: 1.1849\n",
      "Epoch 22/200, Train Loss: 1.2035, Val Loss: 1.2292\n",
      "Epoch 23/200, Train Loss: 1.3367, Val Loss: 1.5623\n",
      "Epoch 24/200, Train Loss: 1.2725, Val Loss: 1.2105\n",
      "Epoch 25/200, Train Loss: 1.2181, Val Loss: 1.5112\n",
      "Epoch 26/200, Train Loss: 1.2699, Val Loss: 1.3142\n",
      "Epoch 27/200, Train Loss: 1.2863, Val Loss: 1.4279\n",
      "Epoch 28/200, Train Loss: 1.2837, Val Loss: 1.4023\n",
      "Epoch 29/200, Train Loss: 1.2805, Val Loss: 1.3097\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.9860\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.4093\n",
      "Test R2: 0.1914\n",
      "Test MAE: 1.1791\n",
      "0    1.973022\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.9411, Val Loss: 1.0998\n",
      "Epoch 2/200, Train Loss: 1.4716, Val Loss: 1.0482\n",
      "Epoch 3/200, Train Loss: 1.4155, Val Loss: 1.3376\n",
      "Epoch 4/200, Train Loss: 1.3856, Val Loss: 0.9628\n",
      "Epoch 5/200, Train Loss: 1.3427, Val Loss: 1.0485\n",
      "Epoch 6/200, Train Loss: 1.3055, Val Loss: 1.1108\n",
      "Epoch 7/200, Train Loss: 1.2767, Val Loss: 1.0668\n",
      "Epoch 8/200, Train Loss: 1.2729, Val Loss: 1.2373\n",
      "Epoch 9/200, Train Loss: 1.2554, Val Loss: 1.2310\n",
      "Epoch 10/200, Train Loss: 1.2440, Val Loss: 1.2341\n",
      "Epoch 11/200, Train Loss: 1.2410, Val Loss: 1.1555\n",
      "Epoch 12/200, Train Loss: 1.2172, Val Loss: 1.2774\n",
      "Epoch 13/200, Train Loss: 1.2110, Val Loss: 1.2551\n",
      "Epoch 14/200, Train Loss: 1.1865, Val Loss: 1.1326\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.5394\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.2407\n",
      "Test R2: 0.3732\n",
      "Test MAE: 1.0256\n",
      "0    1.40241\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.3161, Val Loss: 1.0418\n",
      "Epoch 2/200, Train Loss: 1.9765, Val Loss: 0.9776\n",
      "Epoch 3/200, Train Loss: 1.9341, Val Loss: 0.9680\n",
      "Epoch 4/200, Train Loss: 1.9704, Val Loss: 1.0436\n",
      "Epoch 5/200, Train Loss: 1.9704, Val Loss: 1.0160\n",
      "Epoch 6/200, Train Loss: 1.9071, Val Loss: 0.9762\n",
      "Epoch 7/200, Train Loss: 1.8840, Val Loss: 0.9509\n",
      "Epoch 8/200, Train Loss: 1.8606, Val Loss: 0.9778\n",
      "Epoch 9/200, Train Loss: 1.9012, Val Loss: 1.0048\n",
      "Epoch 10/200, Train Loss: 1.8831, Val Loss: 0.9665\n",
      "Epoch 11/200, Train Loss: 1.8586, Val Loss: 0.9720\n",
      "Epoch 12/200, Train Loss: 1.8754, Val Loss: 1.0094\n",
      "Epoch 13/200, Train Loss: 1.8665, Val Loss: 0.9610\n",
      "Epoch 14/200, Train Loss: 1.8636, Val Loss: 1.0087\n",
      "Epoch 15/200, Train Loss: 1.8557, Val Loss: 0.9630\n",
      "Epoch 16/200, Train Loss: 1.8559, Val Loss: 0.9504\n",
      "Epoch 17/200, Train Loss: 1.8528, Val Loss: 0.9814\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.7021\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.6438\n",
      "Test R2: -0.1002\n",
      "Test MAE: 1.3813\n",
      "0    1.566319\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.3804, Val Loss: 0.9480\n",
      "Epoch 2/200, Train Loss: 1.8696, Val Loss: 0.9934\n",
      "Epoch 3/200, Train Loss: 1.6543, Val Loss: 1.0961\n",
      "Epoch 4/200, Train Loss: 1.6345, Val Loss: 1.3124\n",
      "Epoch 5/200, Train Loss: 1.6314, Val Loss: 1.1284\n",
      "Epoch 6/200, Train Loss: 1.5977, Val Loss: 1.2810\n",
      "Epoch 7/200, Train Loss: 1.6240, Val Loss: 1.0601\n",
      "Epoch 8/200, Train Loss: 1.5987, Val Loss: 1.2503\n",
      "Epoch 9/200, Train Loss: 1.5871, Val Loss: 1.1930\n",
      "Epoch 10/200, Train Loss: 1.5657, Val Loss: 1.1458\n",
      "Epoch 11/200, Train Loss: 1.5474, Val Loss: 1.1667\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.6789\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.2957\n",
      "Test R2: 0.3164\n",
      "Test MAE: 1.0493\n",
      "0    0.746677\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.3962, Val Loss: 0.9674\n",
      "Epoch 2/200, Train Loss: 1.9772, Val Loss: 0.9943\n",
      "Epoch 3/200, Train Loss: 1.9771, Val Loss: 0.9569\n",
      "Epoch 4/200, Train Loss: 1.9769, Val Loss: 0.9984\n",
      "Epoch 5/200, Train Loss: 1.9760, Val Loss: 0.9504\n",
      "Epoch 6/200, Train Loss: 1.9766, Val Loss: 1.0236\n",
      "Epoch 7/200, Train Loss: 1.9757, Val Loss: 0.9637\n",
      "Epoch 8/200, Train Loss: 1.9789, Val Loss: 1.0171\n",
      "Epoch 9/200, Train Loss: 1.9740, Val Loss: 1.0019\n",
      "Epoch 10/200, Train Loss: 1.9755, Val Loss: 0.9516\n",
      "Epoch 11/200, Train Loss: 1.9756, Val Loss: 0.9518\n",
      "Epoch 12/200, Train Loss: 1.9767, Val Loss: 0.9709\n",
      "Epoch 13/200, Train Loss: 1.9791, Val Loss: 0.9934\n",
      "Epoch 14/200, Train Loss: 1.9744, Val Loss: 0.9598\n",
      "Epoch 15/200, Train Loss: 1.9759, Val Loss: 0.9506\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.8207\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.6795\n",
      "Test R2: -0.1485\n",
      "Test MAE: 1.4031\n",
      "0    0.0\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.2832, Val Loss: 1.1241\n",
      "Epoch 2/200, Train Loss: 1.6066, Val Loss: 1.1668\n",
      "Epoch 3/200, Train Loss: 1.5964, Val Loss: 1.2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Train Loss: 1.5998, Val Loss: 1.1690\n",
      "Epoch 5/200, Train Loss: 1.5871, Val Loss: 1.0787\n",
      "Epoch 6/200, Train Loss: 1.5798, Val Loss: 1.1853\n",
      "Epoch 7/200, Train Loss: 1.5591, Val Loss: 1.3331\n",
      "Epoch 8/200, Train Loss: 1.5536, Val Loss: 1.1192\n",
      "Epoch 9/200, Train Loss: 1.6061, Val Loss: 1.2035\n",
      "Epoch 10/200, Train Loss: 1.5404, Val Loss: 1.1202\n",
      "Epoch 11/200, Train Loss: 1.5007, Val Loss: 1.2354\n",
      "Epoch 12/200, Train Loss: 1.4720, Val Loss: 1.4656\n",
      "Epoch 13/200, Train Loss: 1.4546, Val Loss: 1.1811\n",
      "Epoch 14/200, Train Loss: 1.4083, Val Loss: 1.1813\n",
      "Epoch 15/200, Train Loss: 1.4144, Val Loss: 1.2845\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.5173\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.5866\n",
      "Test R2: -0.0249\n",
      "Test MAE: 1.3024\n",
      "0    2.122486\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.0116, Val Loss: 1.1353\n",
      "Epoch 2/200, Train Loss: 1.5155, Val Loss: 1.1430\n",
      "Epoch 3/200, Train Loss: 1.5113, Val Loss: 1.1334\n",
      "Epoch 4/200, Train Loss: 1.5045, Val Loss: 1.1430\n",
      "Epoch 5/200, Train Loss: 1.5038, Val Loss: 1.1628\n",
      "Epoch 6/200, Train Loss: 1.5004, Val Loss: 1.1373\n",
      "Epoch 7/200, Train Loss: 1.4946, Val Loss: 1.1664\n",
      "Epoch 8/200, Train Loss: 1.4876, Val Loss: 1.1389\n",
      "Epoch 9/200, Train Loss: 1.4897, Val Loss: 1.1431\n",
      "Epoch 10/200, Train Loss: 1.4834, Val Loss: 1.1651\n",
      "Epoch 11/200, Train Loss: 1.4809, Val Loss: 1.1606\n",
      "Epoch 12/200, Train Loss: 1.4788, Val Loss: 1.1515\n",
      "Epoch 13/200, Train Loss: 1.4848, Val Loss: 1.1741\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.3538\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1635\n",
      "Test R2: 0.4118\n",
      "Test MAE: 0.8344\n",
      "0    1.906046\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.4525, Val Loss: 1.4073\n",
      "Epoch 2/200, Train Loss: 2.1351, Val Loss: 1.4392\n",
      "Epoch 3/200, Train Loss: 2.1401, Val Loss: 1.4245\n",
      "Epoch 4/200, Train Loss: 2.1376, Val Loss: 1.3865\n",
      "Epoch 5/200, Train Loss: 2.1409, Val Loss: 1.4652\n",
      "Epoch 6/200, Train Loss: 2.1363, Val Loss: 1.4246\n",
      "Epoch 7/200, Train Loss: 2.1344, Val Loss: 1.3784\n",
      "Epoch 8/200, Train Loss: 2.1362, Val Loss: 1.5882\n",
      "Epoch 9/200, Train Loss: 2.0946, Val Loss: 1.1175\n",
      "Epoch 10/200, Train Loss: 1.7581, Val Loss: 1.5265\n",
      "Epoch 11/200, Train Loss: 1.6337, Val Loss: 1.1783\n",
      "Epoch 12/200, Train Loss: 1.6668, Val Loss: 1.1884\n",
      "Epoch 13/200, Train Loss: 1.5910, Val Loss: 1.3740\n",
      "Epoch 14/200, Train Loss: 1.5667, Val Loss: 1.4351\n",
      "Epoch 15/200, Train Loss: 1.5552, Val Loss: 1.3036\n",
      "Epoch 16/200, Train Loss: 1.5266, Val Loss: 1.3736\n",
      "Epoch 17/200, Train Loss: 1.5240, Val Loss: 1.0637\n",
      "Epoch 18/200, Train Loss: 1.5195, Val Loss: 1.2244\n",
      "Epoch 19/200, Train Loss: 1.4963, Val Loss: 1.3816\n",
      "Epoch 20/200, Train Loss: 1.5014, Val Loss: 1.1414\n",
      "Epoch 21/200, Train Loss: 1.6385, Val Loss: 1.2805\n",
      "Epoch 22/200, Train Loss: 1.5186, Val Loss: 1.4177\n",
      "Epoch 23/200, Train Loss: 1.5115, Val Loss: 1.2825\n",
      "Epoch 24/200, Train Loss: 1.5006, Val Loss: 1.7263\n",
      "Epoch 25/200, Train Loss: 1.4728, Val Loss: 1.6009\n",
      "Epoch 26/200, Train Loss: 1.4711, Val Loss: 1.5723\n",
      "Epoch 27/200, Train Loss: 1.5175, Val Loss: 1.3008\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.9836\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.9917\n",
      "Test R2: 0.5726\n",
      "Test MAE: 0.7829\n",
      "0    2.443508\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.0852, Val Loss: 0.2798\n",
      "Epoch 2/200, Train Loss: 0.3463, Val Loss: 0.2505\n",
      "Epoch 3/200, Train Loss: 0.3365, Val Loss: 0.2481\n",
      "Epoch 4/200, Train Loss: 0.3338, Val Loss: 0.2967\n",
      "Epoch 5/200, Train Loss: 0.3269, Val Loss: 0.2534\n",
      "Epoch 6/200, Train Loss: 0.3259, Val Loss: 0.2565\n",
      "Epoch 7/200, Train Loss: 0.3181, Val Loss: 0.2745\n",
      "Epoch 8/200, Train Loss: 0.3163, Val Loss: 0.2664\n",
      "Epoch 9/200, Train Loss: 0.3061, Val Loss: 0.2944\n",
      "Epoch 10/200, Train Loss: 0.3045, Val Loss: 0.2541\n",
      "Epoch 11/200, Train Loss: 0.2996, Val Loss: 0.2517\n",
      "Epoch 12/200, Train Loss: 0.2921, Val Loss: 0.2691\n",
      "Epoch 13/200, Train Loss: 0.2908, Val Loss: 0.2539\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.1449\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.3807\n",
      "Test R2: 0.9370\n",
      "Test MAE: 0.2564\n",
      "0    4.647262\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.3463, Val Loss: 1.4373\n",
      "Epoch 2/200, Train Loss: 1.9218, Val Loss: 1.1352\n",
      "Epoch 3/200, Train Loss: 1.8396, Val Loss: 1.8491\n",
      "Epoch 4/200, Train Loss: 1.6136, Val Loss: 1.7064\n",
      "Epoch 5/200, Train Loss: 1.8635, Val Loss: 1.9140\n",
      "Epoch 6/200, Train Loss: 1.5988, Val Loss: 2.1649\n",
      "Epoch 7/200, Train Loss: 1.4822, Val Loss: 2.4665\n",
      "Epoch 8/200, Train Loss: 1.4662, Val Loss: 1.8498\n",
      "Epoch 9/200, Train Loss: 1.4611, Val Loss: 2.0183\n",
      "Epoch 10/200, Train Loss: 1.4463, Val Loss: 1.9760\n",
      "Epoch 11/200, Train Loss: 1.4357, Val Loss: 1.8886\n",
      "Epoch 12/200, Train Loss: 1.4263, Val Loss: 1.8385\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.9486\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.3959\n",
      "Test R2: 0.1533\n",
      "Test MAE: 1.0907\n",
      "0    2.363592\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.3045, Val Loss: 1.7187\n",
      "Epoch 2/200, Train Loss: 1.9087, Val Loss: 1.7823\n",
      "Epoch 3/200, Train Loss: 1.8468, Val Loss: 1.3417\n",
      "Epoch 4/200, Train Loss: 1.7441, Val Loss: 1.7149\n",
      "Epoch 5/200, Train Loss: 1.6029, Val Loss: 1.9035\n",
      "Epoch 6/200, Train Loss: 1.5197, Val Loss: 2.2258\n",
      "Epoch 7/200, Train Loss: 1.4488, Val Loss: 2.0782\n",
      "Epoch 8/200, Train Loss: 1.4033, Val Loss: 2.2647\n",
      "Epoch 9/200, Train Loss: 1.3608, Val Loss: 2.3946\n",
      "Epoch 10/200, Train Loss: 1.2944, Val Loss: 2.6662\n",
      "Epoch 11/200, Train Loss: 1.2412, Val Loss: 2.9389\n",
      "Epoch 12/200, Train Loss: 1.1991, Val Loss: 3.3811\n",
      "Epoch 13/200, Train Loss: 1.1461, Val Loss: 2.6474\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.3326\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.5273\n",
      "Test R2: -0.0135\n",
      "Test MAE: 1.2118\n",
      "0    2.433023\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.5606, Val Loss: 1.5103\n",
      "Epoch 2/200, Train Loss: 2.1423, Val Loss: 1.3873\n",
      "Epoch 3/200, Train Loss: 2.1380, Val Loss: 1.4811\n",
      "Epoch 4/200, Train Loss: 2.1374, Val Loss: 1.4048\n",
      "Epoch 5/200, Train Loss: 2.1391, Val Loss: 1.3971\n",
      "Epoch 6/200, Train Loss: 2.1382, Val Loss: 1.7760\n",
      "Epoch 7/200, Train Loss: 2.1371, Val Loss: 1.4213\n",
      "Epoch 8/200, Train Loss: 2.1359, Val Loss: 1.3040\n",
      "Epoch 9/200, Train Loss: 2.1364, Val Loss: 1.2939\n",
      "Epoch 10/200, Train Loss: 2.1330, Val Loss: 1.3350\n",
      "Epoch 11/200, Train Loss: 2.1246, Val Loss: 1.4844\n",
      "Epoch 12/200, Train Loss: 2.1161, Val Loss: 1.4036\n",
      "Epoch 13/200, Train Loss: 2.1265, Val Loss: 1.3657\n",
      "Epoch 14/200, Train Loss: 2.1292, Val Loss: 1.3891\n",
      "Epoch 15/200, Train Loss: 2.1299, Val Loss: 1.6786\n",
      "Epoch 16/200, Train Loss: 2.1085, Val Loss: 1.5019\n",
      "Epoch 17/200, Train Loss: 2.1084, Val Loss: 1.5502\n",
      "Epoch 18/200, Train Loss: 2.1319, Val Loss: 1.5867\n",
      "Epoch 19/200, Train Loss: 2.1304, Val Loss: 1.6201\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.2669\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.5056\n",
      "Test R2: 0.0150\n",
      "Test MAE: 1.2298\n",
      "0    0.041412\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.6297, Val Loss: 1.4591\n",
      "Epoch 2/200, Train Loss: 1.9083, Val Loss: 1.3455\n",
      "Epoch 3/200, Train Loss: 1.8578, Val Loss: 1.1998\n",
      "Epoch 4/200, Train Loss: 1.8910, Val Loss: 1.3618\n",
      "Epoch 5/200, Train Loss: 1.8565, Val Loss: 1.2720\n",
      "Epoch 6/200, Train Loss: 1.8763, Val Loss: 1.3910\n",
      "Epoch 7/200, Train Loss: 1.8468, Val Loss: 1.2397\n",
      "Epoch 8/200, Train Loss: 1.8091, Val Loss: 1.2605\n",
      "Epoch 9/200, Train Loss: 1.7713, Val Loss: 1.2635\n",
      "Epoch 10/200, Train Loss: 1.7486, Val Loss: 1.1923\n",
      "Epoch 11/200, Train Loss: 1.6942, Val Loss: 1.2409\n",
      "Epoch 12/200, Train Loss: 1.6875, Val Loss: 1.2089\n",
      "Epoch 13/200, Train Loss: 1.6701, Val Loss: 1.3024\n",
      "Epoch 14/200, Train Loss: 1.5730, Val Loss: 1.3259\n",
      "Epoch 15/200, Train Loss: 1.5473, Val Loss: 1.2808\n",
      "Epoch 16/200, Train Loss: 1.5469, Val Loss: 1.2897\n",
      "Epoch 17/200, Train Loss: 1.7411, Val Loss: 1.1815\n",
      "Epoch 18/200, Train Loss: 1.7149, Val Loss: 1.4361\n",
      "Epoch 19/200, Train Loss: 1.7079, Val Loss: 1.2572\n",
      "Epoch 20/200, Train Loss: 1.6754, Val Loss: 1.2897\n",
      "Epoch 21/200, Train Loss: 1.6934, Val Loss: 1.2116\n",
      "Epoch 22/200, Train Loss: 1.6924, Val Loss: 1.3451\n",
      "Epoch 23/200, Train Loss: 1.6991, Val Loss: 1.1511\n",
      "Epoch 24/200, Train Loss: 1.8136, Val Loss: 1.2115\n",
      "Epoch 25/200, Train Loss: 1.8027, Val Loss: 1.1615\n",
      "Epoch 26/200, Train Loss: 1.7905, Val Loss: 1.1607\n",
      "Epoch 27/200, Train Loss: 1.7921, Val Loss: 1.1929\n",
      "Epoch 28/200, Train Loss: 1.7935, Val Loss: 1.2282\n",
      "Epoch 29/200, Train Loss: 1.7678, Val Loss: 1.1769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200, Train Loss: 1.7747, Val Loss: 1.2035\n",
      "Epoch 31/200, Train Loss: 1.7418, Val Loss: 1.2288\n",
      "Epoch 32/200, Train Loss: 1.7036, Val Loss: 1.2871\n",
      "Epoch 33/200, Train Loss: 1.7287, Val Loss: 1.2805\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.9666\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.4023\n",
      "Test R2: 0.1455\n",
      "Test MAE: 1.0673\n",
      "0    0.507165\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.5573, Val Loss: 1.4299\n",
      "Epoch 2/200, Train Loss: 2.1374, Val Loss: 1.3785\n",
      "Epoch 3/200, Train Loss: 2.1395, Val Loss: 1.5282\n",
      "Epoch 4/200, Train Loss: 2.1389, Val Loss: 1.5073\n",
      "Epoch 5/200, Train Loss: 2.1395, Val Loss: 1.3643\n",
      "Epoch 6/200, Train Loss: 2.1366, Val Loss: 1.4904\n",
      "Epoch 7/200, Train Loss: 2.1393, Val Loss: 1.4397\n",
      "Epoch 8/200, Train Loss: 2.1385, Val Loss: 1.3680\n",
      "Epoch 9/200, Train Loss: 2.1367, Val Loss: 1.2844\n",
      "Epoch 10/200, Train Loss: 2.1367, Val Loss: 1.4722\n",
      "Epoch 11/200, Train Loss: 2.1393, Val Loss: 1.3299\n",
      "Epoch 12/200, Train Loss: 2.1406, Val Loss: 1.4860\n",
      "Epoch 13/200, Train Loss: 2.1376, Val Loss: 1.4942\n",
      "Epoch 14/200, Train Loss: 2.1367, Val Loss: 1.5268\n",
      "Epoch 15/200, Train Loss: 2.1345, Val Loss: 1.4654\n",
      "Epoch 16/200, Train Loss: 2.1393, Val Loss: 1.4773\n",
      "Epoch 17/200, Train Loss: 2.1368, Val Loss: 1.4489\n",
      "Epoch 18/200, Train Loss: 2.1397, Val Loss: 1.2857\n",
      "Epoch 19/200, Train Loss: 2.1391, Val Loss: 1.4004\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.3078\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.5191\n",
      "Test R2: -0.0028\n",
      "Test MAE: 1.2413\n",
      "0    0.0\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.5036, Val Loss: 1.3140\n",
      "Epoch 2/200, Train Loss: 2.1370, Val Loss: 1.4360\n",
      "Epoch 3/200, Train Loss: 2.1293, Val Loss: 1.3038\n",
      "Epoch 4/200, Train Loss: 2.1358, Val Loss: 1.4451\n",
      "Epoch 5/200, Train Loss: 2.1260, Val Loss: 1.3936\n",
      "Epoch 6/200, Train Loss: 2.1169, Val Loss: 1.2479\n",
      "Epoch 7/200, Train Loss: 2.1234, Val Loss: 1.4622\n",
      "Epoch 8/200, Train Loss: 2.1110, Val Loss: 1.3481\n",
      "Epoch 9/200, Train Loss: 2.1005, Val Loss: 1.2120\n",
      "Epoch 10/200, Train Loss: 2.0917, Val Loss: 1.1831\n",
      "Epoch 11/200, Train Loss: 2.1081, Val Loss: 1.4340\n",
      "Epoch 12/200, Train Loss: 2.0787, Val Loss: 1.2620\n",
      "Epoch 13/200, Train Loss: 2.0685, Val Loss: 1.2138\n",
      "Epoch 14/200, Train Loss: 2.0387, Val Loss: 1.2268\n",
      "Epoch 15/200, Train Loss: 2.0825, Val Loss: 1.2118\n",
      "Epoch 16/200, Train Loss: 2.0838, Val Loss: 1.4014\n",
      "Epoch 17/200, Train Loss: 2.0787, Val Loss: 1.1786\n",
      "Epoch 18/200, Train Loss: 2.0444, Val Loss: 1.2261\n",
      "Epoch 19/200, Train Loss: 2.1060, Val Loss: 1.2781\n",
      "Epoch 20/200, Train Loss: 2.0018, Val Loss: 1.3944\n",
      "Epoch 21/200, Train Loss: 1.9553, Val Loss: 1.2100\n",
      "Epoch 22/200, Train Loss: 1.9325, Val Loss: 1.1730\n",
      "Epoch 23/200, Train Loss: 1.9114, Val Loss: 1.3078\n",
      "Epoch 24/200, Train Loss: 1.8938, Val Loss: 1.3287\n",
      "Epoch 25/200, Train Loss: 1.8706, Val Loss: 1.2909\n",
      "Epoch 26/200, Train Loss: 1.8646, Val Loss: 1.2274\n",
      "Epoch 27/200, Train Loss: 1.8281, Val Loss: 1.2240\n",
      "Epoch 28/200, Train Loss: 1.8024, Val Loss: 1.1907\n",
      "Epoch 29/200, Train Loss: 1.7720, Val Loss: 1.1936\n",
      "Epoch 30/200, Train Loss: 1.7856, Val Loss: 1.3220\n",
      "Epoch 31/200, Train Loss: 1.7255, Val Loss: 1.2767\n",
      "Epoch 32/200, Train Loss: 1.6929, Val Loss: 1.2687\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.6698\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.6339\n",
      "Test R2: -0.1600\n",
      "Test MAE: 1.3063\n",
      "0    0.616428\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.7771, Val Loss: 1.1689\n",
      "Epoch 2/200, Train Loss: 1.2998, Val Loss: 1.1397\n",
      "Epoch 3/200, Train Loss: 1.3010, Val Loss: 1.1992\n",
      "Epoch 4/200, Train Loss: 1.2776, Val Loss: 1.3372\n",
      "Epoch 5/200, Train Loss: 1.2825, Val Loss: 1.1648\n",
      "Epoch 6/200, Train Loss: 1.2744, Val Loss: 1.1305\n",
      "Epoch 7/200, Train Loss: 1.2945, Val Loss: 1.0922\n",
      "Epoch 8/200, Train Loss: 1.2790, Val Loss: 1.0850\n",
      "Epoch 9/200, Train Loss: 1.2761, Val Loss: 1.1082\n",
      "Epoch 10/200, Train Loss: 1.2786, Val Loss: 1.1861\n",
      "Epoch 11/200, Train Loss: 1.2652, Val Loss: 1.1915\n",
      "Epoch 12/200, Train Loss: 1.2666, Val Loss: 1.1451\n",
      "Epoch 13/200, Train Loss: 1.2558, Val Loss: 1.2370\n",
      "Epoch 14/200, Train Loss: 1.2522, Val Loss: 1.2417\n",
      "Epoch 15/200, Train Loss: 1.2451, Val Loss: 1.2024\n",
      "Epoch 16/200, Train Loss: 1.2480, Val Loss: 1.1522\n",
      "Epoch 17/200, Train Loss: 1.2387, Val Loss: 1.1715\n",
      "Epoch 18/200, Train Loss: 1.2403, Val Loss: 1.1146\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.4023\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1842\n",
      "Test R2: 0.6237\n",
      "Test MAE: 0.9691\n",
      "0    2.580722\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.9210, Val Loss: 3.3979\n",
      "Epoch 2/200, Train Loss: 3.1838, Val Loss: 0.9943\n",
      "Epoch 3/200, Train Loss: 2.3502, Val Loss: 2.0225\n",
      "Epoch 4/200, Train Loss: 2.2786, Val Loss: 1.0590\n",
      "Epoch 5/200, Train Loss: 2.2188, Val Loss: 1.2717\n",
      "Epoch 6/200, Train Loss: 2.0313, Val Loss: 1.1724\n",
      "Epoch 7/200, Train Loss: 1.9240, Val Loss: 0.8160\n",
      "Epoch 8/200, Train Loss: 1.8705, Val Loss: 1.2014\n",
      "Epoch 9/200, Train Loss: 1.8313, Val Loss: 0.9137\n",
      "Epoch 10/200, Train Loss: 1.8358, Val Loss: 0.9209\n",
      "Epoch 11/200, Train Loss: 1.7866, Val Loss: 0.9274\n",
      "Epoch 12/200, Train Loss: 1.7585, Val Loss: 0.9251\n",
      "Epoch 13/200, Train Loss: 1.7197, Val Loss: 1.0776\n",
      "Epoch 14/200, Train Loss: 1.6816, Val Loss: 1.7365\n",
      "Epoch 15/200, Train Loss: 1.6218, Val Loss: 1.1148\n",
      "Epoch 16/200, Train Loss: 1.6092, Val Loss: 1.0449\n",
      "Epoch 17/200, Train Loss: 1.5243, Val Loss: 1.0776\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.4640\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.2099\n",
      "Test R2: 0.6072\n",
      "Test MAE: 1.0202\n",
      "0    2.996551\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 0.7463, Val Loss: 0.0988\n",
      "Epoch 2/200, Train Loss: 0.1104, Val Loss: 0.1342\n",
      "Epoch 3/200, Train Loss: 0.1053, Val Loss: 0.0896\n",
      "Epoch 4/200, Train Loss: 0.1033, Val Loss: 0.0950\n",
      "Epoch 5/200, Train Loss: 0.0988, Val Loss: 0.0791\n",
      "Epoch 6/200, Train Loss: 0.0948, Val Loss: 0.0773\n",
      "Epoch 7/200, Train Loss: 0.0932, Val Loss: 0.0912\n",
      "Epoch 8/200, Train Loss: 0.0923, Val Loss: 0.0730\n",
      "Epoch 9/200, Train Loss: 0.0887, Val Loss: 0.0812\n",
      "Epoch 10/200, Train Loss: 0.0883, Val Loss: 0.0925\n",
      "Epoch 11/200, Train Loss: 0.0874, Val Loss: 0.0752\n",
      "Epoch 12/200, Train Loss: 0.0872, Val Loss: 0.0815\n",
      "Epoch 13/200, Train Loss: 0.0859, Val Loss: 0.0738\n",
      "Epoch 14/200, Train Loss: 0.0846, Val Loss: 0.0715\n",
      "Epoch 15/200, Train Loss: 0.0836, Val Loss: 0.0744\n",
      "Epoch 16/200, Train Loss: 0.0844, Val Loss: 0.0741\n",
      "Epoch 17/200, Train Loss: 0.0833, Val Loss: 0.0833\n",
      "Epoch 18/200, Train Loss: 0.0828, Val Loss: 0.0730\n",
      "Epoch 19/200, Train Loss: 0.0819, Val Loss: 0.0725\n",
      "Epoch 20/200, Train Loss: 0.0821, Val Loss: 0.0742\n",
      "Epoch 21/200, Train Loss: 0.0816, Val Loss: 0.0881\n",
      "Epoch 22/200, Train Loss: 0.0807, Val Loss: 0.0738\n",
      "Epoch 23/200, Train Loss: 0.0806, Val Loss: 0.0719\n",
      "Epoch 24/200, Train Loss: 0.0790, Val Loss: 0.0724\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.0643\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.2536\n",
      "Test R2: 0.9827\n",
      "Test MAE: 0.1781\n",
      "0    5.346024\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.8619, Val Loss: 2.3530\n",
      "Epoch 2/200, Train Loss: 1.8643, Val Loss: 2.1247\n",
      "Epoch 3/200, Train Loss: 1.8152, Val Loss: 2.1193\n",
      "Epoch 4/200, Train Loss: 1.8219, Val Loss: 2.5643\n",
      "Epoch 5/200, Train Loss: 2.0833, Val Loss: 2.1337\n",
      "Epoch 6/200, Train Loss: 1.8470, Val Loss: 1.9032\n",
      "Epoch 7/200, Train Loss: 1.7899, Val Loss: 2.3118\n",
      "Epoch 8/200, Train Loss: 1.8265, Val Loss: 1.8498\n",
      "Epoch 9/200, Train Loss: 1.8036, Val Loss: 2.1869\n",
      "Epoch 10/200, Train Loss: 1.8790, Val Loss: 2.0782\n",
      "Epoch 11/200, Train Loss: 1.8542, Val Loss: 2.2340\n",
      "Epoch 12/200, Train Loss: 1.8385, Val Loss: 1.8819\n",
      "Epoch 13/200, Train Loss: 1.8213, Val Loss: 2.2686\n",
      "Epoch 14/200, Train Loss: 1.8367, Val Loss: 2.6044\n",
      "Epoch 15/200, Train Loss: 1.8013, Val Loss: 2.3326\n",
      "Epoch 16/200, Train Loss: 1.8237, Val Loss: 2.2772\n",
      "Epoch 17/200, Train Loss: 1.7834, Val Loss: 2.4245\n",
      "Epoch 18/200, Train Loss: 1.9307, Val Loss: 2.2414\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.0690\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.4384\n",
      "Test R2: 0.4448\n",
      "Test MAE: 1.2046\n",
      "0    2.09578\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.3163, Val Loss: 5.0550\n",
      "Epoch 2/200, Train Loss: 2.8670, Val Loss: 6.5019\n",
      "Epoch 3/200, Train Loss: 2.8446, Val Loss: 6.0101\n",
      "Epoch 4/200, Train Loss: 2.8202, Val Loss: 4.2794\n",
      "Epoch 5/200, Train Loss: 2.8040, Val Loss: 5.3318\n",
      "Epoch 6/200, Train Loss: 2.7386, Val Loss: 5.6005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200, Train Loss: 2.6124, Val Loss: 5.5899\n",
      "Epoch 8/200, Train Loss: 2.4478, Val Loss: 4.2727\n",
      "Epoch 9/200, Train Loss: 2.2765, Val Loss: 4.6957\n",
      "Epoch 10/200, Train Loss: 2.0230, Val Loss: 5.3010\n",
      "Epoch 11/200, Train Loss: 1.8271, Val Loss: 6.7253\n",
      "Epoch 12/200, Train Loss: 1.6408, Val Loss: 4.5143\n",
      "Epoch 13/200, Train Loss: 1.4536, Val Loss: 3.5278\n",
      "Epoch 14/200, Train Loss: 1.3632, Val Loss: 5.3291\n",
      "Epoch 15/200, Train Loss: 1.2904, Val Loss: 4.9914\n",
      "Epoch 16/200, Train Loss: 1.1643, Val Loss: 3.5733\n",
      "Epoch 17/200, Train Loss: 1.1139, Val Loss: 6.9710\n",
      "Epoch 18/200, Train Loss: 1.0622, Val Loss: 6.1861\n",
      "Epoch 19/200, Train Loss: 0.9959, Val Loss: 6.5969\n",
      "Epoch 20/200, Train Loss: 0.9177, Val Loss: 4.5631\n",
      "Epoch 21/200, Train Loss: 0.8922, Val Loss: 6.1101\n",
      "Epoch 22/200, Train Loss: 0.8698, Val Loss: 5.2171\n",
      "Epoch 23/200, Train Loss: 0.8330, Val Loss: 4.8223\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.7877\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.9462\n",
      "Test R2: -0.0163\n",
      "Test MAE: 1.5581\n",
      "0    2.0834\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.5572, Val Loss: 7.3102\n",
      "Epoch 2/200, Train Loss: 2.6369, Val Loss: 7.8163\n",
      "Epoch 3/200, Train Loss: 2.5792, Val Loss: 8.2321\n",
      "Epoch 4/200, Train Loss: 2.4973, Val Loss: 11.0026\n",
      "Epoch 5/200, Train Loss: 2.4375, Val Loss: 7.3290\n",
      "Epoch 6/200, Train Loss: 2.3935, Val Loss: 9.3956\n",
      "Epoch 7/200, Train Loss: 2.4071, Val Loss: 8.7919\n",
      "Epoch 8/200, Train Loss: 2.2827, Val Loss: 9.0877\n",
      "Epoch 9/200, Train Loss: 2.0596, Val Loss: 9.2794\n",
      "Epoch 10/200, Train Loss: 1.8740, Val Loss: 8.9355\n",
      "Epoch 11/200, Train Loss: 1.7217, Val Loss: 11.0376\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.4558\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.5671\n",
      "Test R2: 0.3410\n",
      "Test MAE: 1.2320\n",
      "0    1.156478\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.9853, Val Loss: 3.0733\n",
      "Epoch 2/200, Train Loss: 3.6920, Val Loss: 3.5901\n",
      "Epoch 3/200, Train Loss: 3.4734, Val Loss: 3.6161\n",
      "Epoch 4/200, Train Loss: 3.3748, Val Loss: 3.8611\n",
      "Epoch 5/200, Train Loss: 3.4718, Val Loss: 3.6633\n",
      "Epoch 6/200, Train Loss: 2.5527, Val Loss: 1.4393\n",
      "Epoch 7/200, Train Loss: 1.9491, Val Loss: 1.6337\n",
      "Epoch 8/200, Train Loss: 1.7698, Val Loss: 2.0161\n",
      "Epoch 9/200, Train Loss: 1.6474, Val Loss: 1.7143\n",
      "Epoch 10/200, Train Loss: 3.2158, Val Loss: 3.9408\n",
      "Epoch 11/200, Train Loss: 2.5096, Val Loss: 1.3797\n",
      "Epoch 12/200, Train Loss: 1.6888, Val Loss: 1.3717\n",
      "Epoch 13/200, Train Loss: 2.2084, Val Loss: 1.4388\n",
      "Epoch 14/200, Train Loss: 1.5888, Val Loss: 1.7598\n",
      "Epoch 15/200, Train Loss: 1.4638, Val Loss: 1.6874\n",
      "Epoch 16/200, Train Loss: 1.3709, Val Loss: 2.0317\n",
      "Epoch 17/200, Train Loss: 1.3116, Val Loss: 1.7036\n",
      "Epoch 18/200, Train Loss: 1.2435, Val Loss: 1.9276\n",
      "Epoch 19/200, Train Loss: 1.1828, Val Loss: 1.4939\n",
      "Epoch 20/200, Train Loss: 1.1078, Val Loss: 1.8270\n",
      "Epoch 21/200, Train Loss: 1.1093, Val Loss: 2.3405\n",
      "Epoch 22/200, Train Loss: 1.0484, Val Loss: 1.8434\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.7739\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.3319\n",
      "Test R2: 0.5240\n",
      "Test MAE: 1.0353\n",
      "0    1.541783\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 4.0794, Val Loss: 3.5520\n",
      "Epoch 2/200, Train Loss: 3.7040, Val Loss: 2.1689\n",
      "Epoch 3/200, Train Loss: 3.6060, Val Loss: 2.3405\n",
      "Epoch 4/200, Train Loss: 2.3861, Val Loss: 3.0844\n",
      "Epoch 5/200, Train Loss: 2.3206, Val Loss: 1.9369\n",
      "Epoch 6/200, Train Loss: 2.2946, Val Loss: 3.3945\n",
      "Epoch 7/200, Train Loss: 2.2779, Val Loss: 2.3323\n",
      "Epoch 8/200, Train Loss: 2.1518, Val Loss: 2.4439\n",
      "Epoch 9/200, Train Loss: 2.4317, Val Loss: 3.4844\n",
      "Epoch 10/200, Train Loss: 2.0501, Val Loss: 2.1763\n",
      "Epoch 11/200, Train Loss: 1.9108, Val Loss: 1.9629\n",
      "Epoch 12/200, Train Loss: 1.8900, Val Loss: 2.7320\n",
      "Epoch 13/200, Train Loss: 1.8689, Val Loss: 2.2650\n",
      "Epoch 14/200, Train Loss: 1.8384, Val Loss: 2.0185\n",
      "Epoch 15/200, Train Loss: 1.8393, Val Loss: 1.9039\n",
      "Epoch 16/200, Train Loss: 1.8192, Val Loss: 2.2218\n",
      "Epoch 17/200, Train Loss: 1.8163, Val Loss: 2.2174\n",
      "Epoch 18/200, Train Loss: 1.7813, Val Loss: 2.1882\n",
      "Epoch 19/200, Train Loss: 1.7788, Val Loss: 2.1648\n",
      "Epoch 20/200, Train Loss: 1.7304, Val Loss: 2.0977\n",
      "Epoch 21/200, Train Loss: 1.7317, Val Loss: 2.6755\n",
      "Epoch 22/200, Train Loss: 1.6825, Val Loss: 2.4818\n",
      "Epoch 23/200, Train Loss: 1.8534, Val Loss: 2.2254\n",
      "Epoch 24/200, Train Loss: 1.8113, Val Loss: 1.8028\n",
      "Epoch 25/200, Train Loss: 1.6479, Val Loss: 2.1005\n",
      "Epoch 26/200, Train Loss: 1.5767, Val Loss: 2.4173\n",
      "Epoch 27/200, Train Loss: 1.5706, Val Loss: 2.3352\n",
      "Epoch 28/200, Train Loss: 1.4892, Val Loss: 2.2143\n",
      "Epoch 29/200, Train Loss: 1.5175, Val Loss: 2.3984\n",
      "Epoch 30/200, Train Loss: 1.3931, Val Loss: 2.3597\n",
      "Epoch 31/200, Train Loss: 1.2904, Val Loss: 2.3812\n",
      "Epoch 32/200, Train Loss: 1.2420, Val Loss: 2.2651\n",
      "Epoch 33/200, Train Loss: 1.1306, Val Loss: 2.1723\n",
      "Epoch 34/200, Train Loss: 1.0699, Val Loss: 1.8771\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.7338\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.6534\n",
      "Test R2: 0.2664\n",
      "Test MAE: 1.3963\n",
      "0    3.293729\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 3.9705, Val Loss: 3.8439\n",
      "Epoch 2/200, Train Loss: 3.7064, Val Loss: 2.8036\n",
      "Epoch 3/200, Train Loss: 3.6995, Val Loss: 3.1911\n",
      "Epoch 4/200, Train Loss: 3.7033, Val Loss: 3.0608\n",
      "Epoch 5/200, Train Loss: 3.7008, Val Loss: 2.8332\n",
      "Epoch 6/200, Train Loss: 3.7018, Val Loss: 3.0281\n",
      "Epoch 7/200, Train Loss: 3.7034, Val Loss: 3.1033\n",
      "Epoch 8/200, Train Loss: 3.7023, Val Loss: 3.0765\n",
      "Epoch 9/200, Train Loss: 3.6816, Val Loss: 3.7091\n",
      "Epoch 10/200, Train Loss: 3.5990, Val Loss: 3.8576\n",
      "Epoch 11/200, Train Loss: 3.6036, Val Loss: 4.1407\n",
      "Epoch 12/200, Train Loss: 3.6038, Val Loss: 3.9742\n",
      "Early stopping triggered.\n",
      "Test MSE: 3.7479\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.9360\n",
      "Test R2: -0.0057\n",
      "Test MAE: 1.5981\n",
      "0    0.05549\n",
      "dtype: float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18256\\AppData\\Local\\Temp\\ipykernel_21256\\1127783596.py:70: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  result_output_metrics.index = result_output_importance.index = ['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']\n",
      "C:\\Users\\18256\\AppData\\Local\\Temp\\ipykernel_21256\\1127783596.py:70: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  result_output_metrics.index = result_output_importance.index = ['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']\n",
      "C:\\Users\\18256\\AppData\\Local\\Temp\\ipykernel_21256\\1127783596.py:70: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  result_output_metrics.index = result_output_importance.index = ['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m result_output_metrics \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_output_metrics,axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     69\u001b[0m result_output_importance \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_output_importance,axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m result_output_metrics\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m result_output_importance\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTSS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCODMn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTSS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCODMn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     72\u001b[0m result_output_metrics\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM_1site_1feature_batch_metrics.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     73\u001b[0m result_output_importance\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM_1site_1feature_batch_importance.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "#单站点单特征循环Single site single feature\n",
    "#change the Define function.input: X_origin[:,:,target_site_index,input_feature].unsqueeze(-1),LSTM_input_size = 1\n",
    "all_output_metrics = []\n",
    "all_output_importance = []\n",
    "\n",
    "for model_sites in range(9):\n",
    "    output_metrics = []\n",
    "    output_importance = []\n",
    "    for model_input_feature in range(9):\n",
    "        #Model hyperparameters\n",
    "        # 模型超参数\n",
    "        LSTM_input_size = 1\n",
    "        LSTM_hidden_size = 64  \n",
    "        LSTM_num_layers = 2\n",
    "\n",
    "        input_seq_len = 72  # 输入序列长度,Input sequence length\n",
    "        output_seq_len = 1  # 输出序列长度,output sequence length\n",
    "        target_site_index = model_sites  # 目标站点（例如 站点0）,Target site (e.g. site 0)\n",
    "        target_col = 2  # 目标特征（例如 特征0）,Target feature (e.g. feature 0)\n",
    "        batch_size = 16\n",
    "\n",
    "        X, y = create_sequences(data, input_seq_len, output_seq_len, target_site_index, target_col)\n",
    "        y = y.squeeze((-1,-2))\n",
    "        #Divide the training set，validation set and test set 7:1:2\n",
    "        # 划分训练集验证集和测试集7：1：2\n",
    "        train_size, val_size, test_size = 0.7, 0.1, 0.2\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size/(train_size+val_size+test_size), shuffle=False)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size/(train_size+val_size), shuffle=False)\n",
    "        X_train, X_val, X_test = to_tensor(X_train), to_tensor(X_val), to_tensor(X_test)\n",
    "        y_train, y_val, y_test = to_tensor(y_train), to_tensor(y_val), to_tensor(y_test)\n",
    "        # create DataLoader\n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        val_dataset = TensorDataset(X_val, y_val)\n",
    "        test_dataset = TensorDataset(X_test, y_test)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        lstm_model = LSTMModel(LSTM_input_size, LSTM_hidden_size, LSTM_num_layers, output_seq_len)\n",
    "        lstm_model.to(device)\n",
    "\n",
    "        epochs=200\n",
    "        learning_rate = 0.001\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
    "        epoch_logs=[]\n",
    "        input_feature = model_input_feature#0:WT,1:pH,2:DO,3:EC,4:TSS,5:CODMN,6:AN,7:TP,8:TN\n",
    "\n",
    "        LSTM_train_and_evaluate(lstm_model, train_loader, val_loader, criterion, optimizer, epochs, target_site_index, input_feature)\n",
    "        predictions, actuals = LSTM_evaluate(lstm_model, test_loader, target_site_index, input_feature)\n",
    "        #Calculate accuracy\n",
    "        # 计算精度\n",
    "        rmse, r2, mae = calculate_metrics(predictions, actuals)\n",
    "        #result\n",
    "        # 输出结果\n",
    "        print(f\"predictions shape: {predictions.shape}\")\n",
    "        print(f\"actuals shape: {actuals.shape}\")\n",
    "        print(f\"Test RMSE: {rmse:.4f}\")\n",
    "        print(f\"Test R2: {r2:.4f}\")\n",
    "        print(f\"Test MAE: {mae:.4f}\")\n",
    "        feature_importances = np.mean(pd.DataFrame(LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='zero')),axis= 0)\n",
    "        print(feature_importances)\n",
    "        \n",
    "        output_metrics.append([rmse, r2, mae])\n",
    "        output_importance.append(feature_importances)\n",
    "        epoch_logs = pd.DataFrame(epoch_logs,columns=['Epoch','Train_Loss','Val_loss','Time'])\n",
    "        epoch_logs.to_csv(f\"LSTM_logs_1site_1feature_batch_site{model_sites}_feature{model_input_feature}.csv\",index=False)\n",
    "        \n",
    "    all_output_metrics.append(pd.DataFrame(output_metrics,columns=['RMSE','R2','MAE']))\n",
    "    all_output_importance.append(pd.DataFrame({f\"N{model_sites}\" : output_importance.values}, index = ['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']))\n",
    "    \n",
    "result_output_metrics = pd.concat(all_output_metrics,axis = 1)\n",
    "result_output_importance = pd.concat(all_output_importance,axis = 1)\n",
    "result_output_metrics.index = result_output_importance.index = ['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']\n",
    "\n",
    "result_output_metrics.to_csv(f\"LSTM_1site_1feature_batch_metrics.csv\",index=False)\n",
    "result_output_importance.to_csv(f\"LSTM_1site_1feature_batch_importance.csv\",index=False)\n",
    "#['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91649a08",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 3.1482, Val Loss: 0.0874\n",
      "Epoch 2/200, Train Loss: 0.1274, Val Loss: 0.0882\n",
      "Epoch 3/200, Train Loss: 0.1106, Val Loss: 0.0720\n",
      "Epoch 4/200, Train Loss: 0.1056, Val Loss: 0.0879\n",
      "Epoch 5/200, Train Loss: 0.1043, Val Loss: 0.0580\n",
      "Epoch 6/200, Train Loss: 0.1009, Val Loss: 0.0822\n",
      "Epoch 7/200, Train Loss: 0.0991, Val Loss: 0.0624\n",
      "Epoch 8/200, Train Loss: 0.0972, Val Loss: 0.0646\n",
      "Epoch 9/200, Train Loss: 0.0975, Val Loss: 0.0559\n",
      "Epoch 10/200, Train Loss: 0.0960, Val Loss: 0.0641\n",
      "Epoch 11/200, Train Loss: 0.0963, Val Loss: 0.0633\n",
      "Epoch 12/200, Train Loss: 0.0946, Val Loss: 0.0650\n",
      "Epoch 13/200, Train Loss: 0.0934, Val Loss: 0.0663\n",
      "Epoch 14/200, Train Loss: 0.0939, Val Loss: 0.0631\n",
      "Epoch 15/200, Train Loss: 0.0923, Val Loss: 0.0673\n",
      "Epoch 16/200, Train Loss: 0.0905, Val Loss: 0.0704\n",
      "Epoch 17/200, Train Loss: 0.0901, Val Loss: 0.0647\n",
      "Epoch 18/200, Train Loss: 0.0894, Val Loss: 0.0686\n",
      "Epoch 19/200, Train Loss: 0.0885, Val Loss: 0.0579\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.0742\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.2723\n",
      "Test R2: 0.9692\n",
      "Test MAE: 0.1625\n",
      "0    6.116216\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.6714, Val Loss: 0.0611\n",
      "Epoch 2/200, Train Loss: 0.0969, Val Loss: 0.0527\n",
      "Epoch 3/200, Train Loss: 0.0913, Val Loss: 0.0657\n",
      "Epoch 4/200, Train Loss: 0.0876, Val Loss: 0.0496\n",
      "Epoch 5/200, Train Loss: 0.0842, Val Loss: 0.0470\n",
      "Epoch 6/200, Train Loss: 0.0826, Val Loss: 0.0509\n",
      "Epoch 7/200, Train Loss: 0.0806, Val Loss: 0.0497\n",
      "Epoch 8/200, Train Loss: 0.0797, Val Loss: 0.0469\n",
      "Epoch 9/200, Train Loss: 0.0786, Val Loss: 0.0502\n",
      "Epoch 10/200, Train Loss: 0.0798, Val Loss: 0.0565\n",
      "Epoch 11/200, Train Loss: 0.0778, Val Loss: 0.0425\n",
      "Epoch 12/200, Train Loss: 0.0768, Val Loss: 0.0524\n",
      "Epoch 13/200, Train Loss: 0.0765, Val Loss: 0.0429\n",
      "Epoch 14/200, Train Loss: 0.0806, Val Loss: 0.0441\n",
      "Epoch 15/200, Train Loss: 0.0742, Val Loss: 0.0434\n",
      "Epoch 16/200, Train Loss: 0.0740, Val Loss: 0.0437\n",
      "Epoch 17/200, Train Loss: 0.0735, Val Loss: 0.0512\n",
      "Epoch 18/200, Train Loss: 0.0738, Val Loss: 0.0455\n",
      "Epoch 19/200, Train Loss: 0.0727, Val Loss: 0.0519\n",
      "Epoch 20/200, Train Loss: 0.0719, Val Loss: 0.0579\n",
      "Epoch 21/200, Train Loss: 0.0722, Val Loss: 0.0463\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.1114\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.3338\n",
      "Test R2: 0.9376\n",
      "Test MAE: 0.1875\n",
      "0    5.906754\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.5640, Val Loss: 0.2115\n",
      "Epoch 2/200, Train Loss: 0.2080, Val Loss: 0.1911\n",
      "Epoch 3/200, Train Loss: 0.2010, Val Loss: 0.2088\n",
      "Epoch 4/200, Train Loss: 0.1979, Val Loss: 0.1970\n",
      "Epoch 5/200, Train Loss: 0.1930, Val Loss: 0.2013\n",
      "Epoch 6/200, Train Loss: 0.1915, Val Loss: 0.1971\n",
      "Epoch 7/200, Train Loss: 0.1901, Val Loss: 0.2149\n",
      "Epoch 8/200, Train Loss: 0.1877, Val Loss: 0.2029\n",
      "Epoch 9/200, Train Loss: 0.1887, Val Loss: 0.2105\n",
      "Epoch 10/200, Train Loss: 0.1882, Val Loss: 0.2117\n",
      "Epoch 11/200, Train Loss: 0.1864, Val Loss: 0.1904\n",
      "Epoch 12/200, Train Loss: 0.1854, Val Loss: 0.1892\n",
      "Epoch 13/200, Train Loss: 0.1846, Val Loss: 0.1797\n",
      "Epoch 14/200, Train Loss: 0.1828, Val Loss: 0.1880\n",
      "Epoch 15/200, Train Loss: 0.1807, Val Loss: 0.2006\n",
      "Epoch 16/200, Train Loss: 0.1804, Val Loss: 0.1700\n",
      "Epoch 17/200, Train Loss: 0.1786, Val Loss: 0.1744\n",
      "Epoch 18/200, Train Loss: 0.1793, Val Loss: 0.1778\n",
      "Epoch 19/200, Train Loss: 0.1801, Val Loss: 0.1679\n",
      "Epoch 20/200, Train Loss: 0.1763, Val Loss: 0.1876\n",
      "Epoch 21/200, Train Loss: 0.1748, Val Loss: 0.1714\n",
      "Epoch 22/200, Train Loss: 0.1720, Val Loss: 0.1583\n",
      "Epoch 23/200, Train Loss: 0.1673, Val Loss: 0.1626\n",
      "Epoch 24/200, Train Loss: 0.1651, Val Loss: 0.1551\n",
      "Epoch 25/200, Train Loss: 0.1636, Val Loss: 0.1611\n",
      "Epoch 26/200, Train Loss: 0.1615, Val Loss: 0.1479\n",
      "Epoch 27/200, Train Loss: 0.1620, Val Loss: 0.1565\n",
      "Epoch 28/200, Train Loss: 0.1601, Val Loss: 0.1572\n",
      "Epoch 29/200, Train Loss: 0.1600, Val Loss: 0.1472\n",
      "Epoch 30/200, Train Loss: 0.1580, Val Loss: 0.1573\n",
      "Epoch 31/200, Train Loss: 0.1557, Val Loss: 0.1533\n",
      "Epoch 32/200, Train Loss: 0.1578, Val Loss: 0.1652\n",
      "Epoch 33/200, Train Loss: 0.1557, Val Loss: 0.1468\n",
      "Epoch 34/200, Train Loss: 0.1556, Val Loss: 0.1597\n",
      "Epoch 35/200, Train Loss: 0.1564, Val Loss: 0.1403\n",
      "Epoch 36/200, Train Loss: 0.1546, Val Loss: 0.1560\n",
      "Epoch 37/200, Train Loss: 0.1544, Val Loss: 0.1734\n",
      "Epoch 38/200, Train Loss: 0.1545, Val Loss: 0.1586\n",
      "Epoch 39/200, Train Loss: 0.1531, Val Loss: 0.1532\n",
      "Epoch 40/200, Train Loss: 0.1523, Val Loss: 0.1454\n",
      "Epoch 41/200, Train Loss: 0.1507, Val Loss: 0.1504\n",
      "Epoch 42/200, Train Loss: 0.1506, Val Loss: 0.1497\n",
      "Epoch 43/200, Train Loss: 0.1513, Val Loss: 0.1555\n",
      "Epoch 44/200, Train Loss: 0.1506, Val Loss: 0.1469\n",
      "Epoch 45/200, Train Loss: 0.1490, Val Loss: 0.1567\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.2916\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.5400\n",
      "Test R2: 0.9475\n",
      "Test MAE: 0.3180\n",
      "0    10.135922\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.5683, Val Loss: 0.1639\n",
      "Epoch 2/200, Train Loss: 0.1864, Val Loss: 0.1683\n",
      "Epoch 3/200, Train Loss: 0.1744, Val Loss: 0.1663\n",
      "Epoch 4/200, Train Loss: 0.1726, Val Loss: 0.1542\n",
      "Epoch 5/200, Train Loss: 0.1691, Val Loss: 0.1522\n",
      "Epoch 6/200, Train Loss: 0.1642, Val Loss: 0.1600\n",
      "Epoch 7/200, Train Loss: 0.1641, Val Loss: 0.1419\n",
      "Epoch 8/200, Train Loss: 0.1593, Val Loss: 0.1667\n",
      "Epoch 9/200, Train Loss: 0.1559, Val Loss: 0.1471\n",
      "Epoch 10/200, Train Loss: 0.1558, Val Loss: 0.1387\n",
      "Epoch 11/200, Train Loss: 0.1533, Val Loss: 0.1441\n",
      "Epoch 12/200, Train Loss: 0.1508, Val Loss: 0.1322\n",
      "Epoch 13/200, Train Loss: 0.1482, Val Loss: 0.1463\n",
      "Epoch 14/200, Train Loss: 0.1467, Val Loss: 0.1354\n",
      "Epoch 15/200, Train Loss: 0.1440, Val Loss: 0.1334\n",
      "Epoch 16/200, Train Loss: 0.1437, Val Loss: 0.1254\n",
      "Epoch 17/200, Train Loss: 0.1402, Val Loss: 0.1422\n",
      "Epoch 18/200, Train Loss: 0.1356, Val Loss: 0.1288\n",
      "Epoch 19/200, Train Loss: 0.1363, Val Loss: 0.1221\n",
      "Epoch 20/200, Train Loss: 0.1328, Val Loss: 0.1177\n",
      "Epoch 21/200, Train Loss: 0.1288, Val Loss: 0.1123\n",
      "Epoch 22/200, Train Loss: 0.1268, Val Loss: 0.1369\n",
      "Epoch 23/200, Train Loss: 0.1274, Val Loss: 0.1203\n",
      "Epoch 24/200, Train Loss: 0.1250, Val Loss: 0.1138\n",
      "Epoch 25/200, Train Loss: 0.1273, Val Loss: 0.1163\n",
      "Epoch 26/200, Train Loss: 0.1230, Val Loss: 0.1125\n",
      "Epoch 27/200, Train Loss: 0.1205, Val Loss: 0.1192\n",
      "Epoch 28/200, Train Loss: 0.1230, Val Loss: 0.1156\n",
      "Epoch 29/200, Train Loss: 0.1196, Val Loss: 0.1274\n",
      "Epoch 30/200, Train Loss: 0.1180, Val Loss: 0.1223\n",
      "Epoch 31/200, Train Loss: 0.1164, Val Loss: 0.1156\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.0910\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.3017\n",
      "Test R2: 0.9757\n",
      "Test MAE: 0.1827\n",
      "0    4.662769\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 0.7978, Val Loss: 0.1103\n",
      "Epoch 2/200, Train Loss: 0.1520, Val Loss: 0.0988\n",
      "Epoch 3/200, Train Loss: 0.1291, Val Loss: 0.0994\n",
      "Epoch 4/200, Train Loss: 0.1035, Val Loss: 0.1057\n",
      "Epoch 5/200, Train Loss: 0.0979, Val Loss: 0.1161\n",
      "Epoch 6/200, Train Loss: 0.0958, Val Loss: 0.0897\n",
      "Epoch 7/200, Train Loss: 0.0954, Val Loss: 0.0971\n",
      "Epoch 8/200, Train Loss: 0.0930, Val Loss: 0.0893\n",
      "Epoch 9/200, Train Loss: 0.0921, Val Loss: 0.1178\n",
      "Epoch 10/200, Train Loss: 0.0912, Val Loss: 0.0824\n",
      "Epoch 11/200, Train Loss: 0.0894, Val Loss: 0.0817\n",
      "Epoch 12/200, Train Loss: 0.0883, Val Loss: 0.0895\n",
      "Epoch 13/200, Train Loss: 0.0875, Val Loss: 0.0888\n",
      "Epoch 14/200, Train Loss: 0.0869, Val Loss: 0.0792\n",
      "Epoch 15/200, Train Loss: 0.0866, Val Loss: 0.0841\n",
      "Epoch 16/200, Train Loss: 0.0851, Val Loss: 0.0974\n",
      "Epoch 17/200, Train Loss: 0.0848, Val Loss: 0.0900\n",
      "Epoch 18/200, Train Loss: 0.0843, Val Loss: 0.1007\n",
      "Epoch 19/200, Train Loss: 0.0835, Val Loss: 0.0818\n",
      "Epoch 20/200, Train Loss: 0.0831, Val Loss: 0.0789\n",
      "Epoch 21/200, Train Loss: 0.0820, Val Loss: 0.0894\n",
      "Epoch 22/200, Train Loss: 0.0817, Val Loss: 0.0829\n",
      "Epoch 23/200, Train Loss: 0.0811, Val Loss: 0.0977\n",
      "Epoch 24/200, Train Loss: 0.0808, Val Loss: 0.0819\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.0668\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.2584\n",
      "Test R2: 0.9856\n",
      "Test MAE: 0.1314\n",
      "0    4.597859\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.1743, Val Loss: 0.0594\n",
      "Epoch 2/200, Train Loss: 0.1614, Val Loss: 0.0515\n",
      "Epoch 3/200, Train Loss: 0.1564, Val Loss: 0.0570\n",
      "Epoch 4/200, Train Loss: 0.1521, Val Loss: 0.0480\n",
      "Epoch 5/200, Train Loss: 0.1517, Val Loss: 0.0463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss: 0.1499, Val Loss: 0.0482\n",
      "Epoch 7/200, Train Loss: 0.1474, Val Loss: 0.0667\n",
      "Epoch 8/200, Train Loss: 0.1450, Val Loss: 0.0448\n",
      "Epoch 9/200, Train Loss: 0.1428, Val Loss: 0.0486\n",
      "Epoch 10/200, Train Loss: 0.1411, Val Loss: 0.0492\n",
      "Epoch 11/200, Train Loss: 0.1423, Val Loss: 0.0457\n",
      "Epoch 12/200, Train Loss: 0.1415, Val Loss: 0.0451\n",
      "Epoch 13/200, Train Loss: 0.1391, Val Loss: 0.0439\n",
      "Epoch 14/200, Train Loss: 0.1396, Val Loss: 0.0477\n",
      "Epoch 15/200, Train Loss: 0.1374, Val Loss: 0.0470\n",
      "Epoch 16/200, Train Loss: 0.1367, Val Loss: 0.0477\n",
      "Epoch 17/200, Train Loss: 0.1365, Val Loss: 0.0461\n",
      "Epoch 18/200, Train Loss: 0.1366, Val Loss: 0.0468\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.0502\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.2241\n",
      "Test R2: 0.9844\n",
      "Test MAE: 0.1416\n",
      "0    5.33042\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.2074, Val Loss: 0.1534\n",
      "Epoch 2/200, Train Loss: 0.3074, Val Loss: 0.1453\n",
      "Epoch 3/200, Train Loss: 0.3078, Val Loss: 0.1461\n",
      "Epoch 4/200, Train Loss: 0.3003, Val Loss: 0.2456\n",
      "Epoch 5/200, Train Loss: 0.3005, Val Loss: 0.1591\n",
      "Epoch 6/200, Train Loss: 0.3001, Val Loss: 0.1464\n",
      "Epoch 7/200, Train Loss: 0.2967, Val Loss: 0.1498\n",
      "Epoch 8/200, Train Loss: 0.2971, Val Loss: 0.1644\n",
      "Epoch 9/200, Train Loss: 0.2951, Val Loss: 0.1658\n",
      "Epoch 10/200, Train Loss: 0.2942, Val Loss: 0.1396\n",
      "Epoch 11/200, Train Loss: 0.2927, Val Loss: 0.1598\n",
      "Epoch 12/200, Train Loss: 0.2928, Val Loss: 0.1498\n",
      "Epoch 13/200, Train Loss: 0.2939, Val Loss: 0.1577\n",
      "Epoch 14/200, Train Loss: 0.2918, Val Loss: 0.1457\n",
      "Epoch 15/200, Train Loss: 0.2911, Val Loss: 0.1467\n",
      "Epoch 16/200, Train Loss: 0.2899, Val Loss: 0.1565\n",
      "Epoch 17/200, Train Loss: 0.3019, Val Loss: 0.1475\n",
      "Epoch 18/200, Train Loss: 0.2900, Val Loss: 0.1415\n",
      "Epoch 19/200, Train Loss: 0.2878, Val Loss: 0.1362\n",
      "Epoch 20/200, Train Loss: 0.2875, Val Loss: 0.1471\n",
      "Epoch 21/200, Train Loss: 0.2862, Val Loss: 0.1506\n",
      "Epoch 22/200, Train Loss: 0.2859, Val Loss: 0.1463\n",
      "Epoch 23/200, Train Loss: 0.2863, Val Loss: 0.1413\n",
      "Epoch 24/200, Train Loss: 0.2857, Val Loss: 0.1439\n",
      "Epoch 25/200, Train Loss: 0.2851, Val Loss: 0.1428\n",
      "Epoch 26/200, Train Loss: 0.2829, Val Loss: 0.1563\n",
      "Epoch 27/200, Train Loss: 0.2841, Val Loss: 0.1422\n",
      "Epoch 28/200, Train Loss: 0.2837, Val Loss: 0.1463\n",
      "Epoch 29/200, Train Loss: 0.2821, Val Loss: 0.1370\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.1278\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.3575\n",
      "Test R2: 0.9480\n",
      "Test MAE: 0.2486\n",
      "0    5.4175\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 0.9760, Val Loss: 0.2583\n",
      "Epoch 2/200, Train Loss: 0.3411, Val Loss: 0.2686\n",
      "Epoch 3/200, Train Loss: 0.3381, Val Loss: 0.2571\n",
      "Epoch 4/200, Train Loss: 0.3286, Val Loss: 0.2496\n",
      "Epoch 5/200, Train Loss: 0.3252, Val Loss: 0.2501\n",
      "Epoch 6/200, Train Loss: 0.3187, Val Loss: 0.2648\n",
      "Epoch 7/200, Train Loss: 0.3155, Val Loss: 0.2606\n",
      "Epoch 8/200, Train Loss: 0.3111, Val Loss: 0.2534\n",
      "Epoch 9/200, Train Loss: 0.3069, Val Loss: 0.2956\n",
      "Epoch 10/200, Train Loss: 0.3006, Val Loss: 0.2469\n",
      "Epoch 11/200, Train Loss: 0.2971, Val Loss: 0.2557\n",
      "Epoch 12/200, Train Loss: 0.2916, Val Loss: 0.2489\n",
      "Epoch 13/200, Train Loss: 0.2885, Val Loss: 0.2492\n",
      "Epoch 14/200, Train Loss: 0.2851, Val Loss: 0.2664\n",
      "Epoch 15/200, Train Loss: 0.2831, Val Loss: 0.2540\n",
      "Epoch 16/200, Train Loss: 0.2809, Val Loss: 0.2465\n",
      "Epoch 17/200, Train Loss: 0.2789, Val Loss: 0.2661\n",
      "Epoch 18/200, Train Loss: 0.2757, Val Loss: 0.2440\n",
      "Epoch 19/200, Train Loss: 0.2752, Val Loss: 0.2428\n",
      "Epoch 20/200, Train Loss: 0.2736, Val Loss: 0.2436\n",
      "Epoch 21/200, Train Loss: 0.2732, Val Loss: 0.2607\n",
      "Epoch 22/200, Train Loss: 0.2703, Val Loss: 0.2593\n",
      "Epoch 23/200, Train Loss: 0.2692, Val Loss: 0.2476\n",
      "Epoch 24/200, Train Loss: 0.2695, Val Loss: 0.2395\n",
      "Epoch 25/200, Train Loss: 0.2654, Val Loss: 0.2447\n",
      "Epoch 26/200, Train Loss: 0.2671, Val Loss: 0.2423\n",
      "Epoch 27/200, Train Loss: 0.2642, Val Loss: 0.2464\n",
      "Epoch 28/200, Train Loss: 0.2612, Val Loss: 0.2421\n",
      "Epoch 29/200, Train Loss: 0.2616, Val Loss: 0.2473\n",
      "Epoch 30/200, Train Loss: 0.2614, Val Loss: 0.2587\n",
      "Epoch 31/200, Train Loss: 0.2591, Val Loss: 0.2696\n",
      "Epoch 32/200, Train Loss: 0.2575, Val Loss: 0.2416\n",
      "Epoch 33/200, Train Loss: 0.2553, Val Loss: 0.2489\n",
      "Epoch 34/200, Train Loss: 0.2568, Val Loss: 0.2408\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.1208\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.3475\n",
      "Test R2: 0.9475\n",
      "Test MAE: 0.2115\n",
      "0    3.886304\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 0.7836, Val Loss: 0.1079\n",
      "Epoch 2/200, Train Loss: 0.1083, Val Loss: 0.0922\n",
      "Epoch 3/200, Train Loss: 0.1071, Val Loss: 0.0945\n",
      "Epoch 4/200, Train Loss: 0.1041, Val Loss: 0.0919\n",
      "Epoch 5/200, Train Loss: 0.1029, Val Loss: 0.0861\n",
      "Epoch 6/200, Train Loss: 0.1005, Val Loss: 0.0856\n",
      "Epoch 7/200, Train Loss: 0.0985, Val Loss: 0.0922\n",
      "Epoch 8/200, Train Loss: 0.0977, Val Loss: 0.0848\n",
      "Epoch 9/200, Train Loss: 0.0948, Val Loss: 0.1091\n",
      "Epoch 10/200, Train Loss: 0.0912, Val Loss: 0.0868\n",
      "Epoch 11/200, Train Loss: 0.0874, Val Loss: 0.0737\n",
      "Epoch 12/200, Train Loss: 0.0879, Val Loss: 0.0795\n",
      "Epoch 13/200, Train Loss: 0.0871, Val Loss: 0.0801\n",
      "Epoch 14/200, Train Loss: 0.0850, Val Loss: 0.0847\n",
      "Epoch 15/200, Train Loss: 0.0839, Val Loss: 0.0800\n",
      "Epoch 16/200, Train Loss: 0.0841, Val Loss: 0.0745\n",
      "Epoch 17/200, Train Loss: 0.0823, Val Loss: 0.0743\n",
      "Epoch 18/200, Train Loss: 0.0827, Val Loss: 0.0740\n",
      "Epoch 19/200, Train Loss: 0.0829, Val Loss: 0.0795\n",
      "Epoch 20/200, Train Loss: 0.0823, Val Loss: 0.0744\n",
      "Epoch 21/200, Train Loss: 0.0815, Val Loss: 0.0747\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.0629\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.2508\n",
      "Test R2: 0.9831\n",
      "Test MAE: 0.1734\n",
      "0    5.082086\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "all_output_metrics = []\n",
    "all_output_importance = []\n",
    "\n",
    "for model_sites in range(9):\n",
    "    output_metrics = []\n",
    "    output_importance = []\n",
    "    for model_input_feature in range(1):\n",
    "        #Model hyperparameters\n",
    "        # 模型超参数\n",
    "        LSTM_input_size = 1\n",
    "        LSTM_hidden_size = 64  \n",
    "        LSTM_num_layers = 2\n",
    "\n",
    "        input_seq_len = 72  # 输入序列长度,Input sequence length\n",
    "        output_seq_len = 1  # 输出序列长度,output sequence length\n",
    "        target_site_index = model_sites  # 目标站点（例如 站点0）,Target site (e.g. site 0)\n",
    "        target_col = 2  # 目标特征（例如 特征0）,Target feature (e.g. feature 0)\n",
    "        batch_size = 16\n",
    "\n",
    "        X, y = create_sequences(data, input_seq_len, output_seq_len, target_site_index, target_col)\n",
    "        y = y.squeeze((-1,-2))\n",
    "        #Divide the training set，validation set and test set 7:1:2\n",
    "        # 划分训练集验证集和测试集7：1：2\n",
    "        train_size, val_size, test_size = 0.7, 0.1, 0.2\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size/(train_size+val_size+test_size), shuffle=False)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size/(train_size+val_size), shuffle=False)\n",
    "        X_train, X_val, X_test = to_tensor(X_train), to_tensor(X_val), to_tensor(X_test)\n",
    "        y_train, y_val, y_test = to_tensor(y_train), to_tensor(y_val), to_tensor(y_test)\n",
    "        # create DataLoader\n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        val_dataset = TensorDataset(X_val, y_val)\n",
    "        test_dataset = TensorDataset(X_test, y_test)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        lstm_model = LSTMModel(LSTM_input_size, LSTM_hidden_size, LSTM_num_layers, output_seq_len)\n",
    "        lstm_model.to(device)\n",
    "\n",
    "        epochs=200\n",
    "        learning_rate = 0.001\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
    "        epoch_logs=[]\n",
    "        input_feature = model_input_feature#0:WT,1:pH,2:DO,3:EC,4:TSS,5:CODMN,6:AN,7:TP,8:TN\n",
    "\n",
    "        LSTM_train_and_evaluate(lstm_model, train_loader, val_loader, criterion, optimizer, epochs, target_site_index, input_feature)\n",
    "        predictions, actuals = LSTM_evaluate(lstm_model, test_loader, target_site_index, input_feature)\n",
    "        #Calculate accuracy\n",
    "        # 计算精度\n",
    "        rmse, r2, mae = calculate_metrics(predictions, actuals)\n",
    "        #result\n",
    "        # 输出结果\n",
    "        print(f\"predictions shape: {predictions.shape}\")\n",
    "        print(f\"actuals shape: {actuals.shape}\")\n",
    "        print(f\"Test RMSE: {rmse:.4f}\")\n",
    "        print(f\"Test R2: {r2:.4f}\")\n",
    "        print(f\"Test MAE: {mae:.4f}\")\n",
    "        feature_importances = np.mean(pd.DataFrame(LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='zero')),axis= 0)\n",
    "        print(feature_importances)\n",
    "        \n",
    "        output_metrics.append([rmse, r2, mae])\n",
    "        output_importance.append(feature_importances)\n",
    "        epoch_logs = pd.DataFrame(epoch_logs,columns=['Epoch','Train_Loss','Val_loss','Time'])\n",
    "        epoch_logs.to_csv(f\"LSTM_logs_1site_1feature_batch_site{model_sites}_feature{model_input_feature}.csv\",index=False)\n",
    "        \n",
    "    all_output_metrics.append(pd.DataFrame(output_metrics,columns=['RMSE','R2','MAE']))\n",
    "    all_output_importance.append(pd.DataFrame({f\"N{model_sites}\" : output_importance.values}, index = ['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']))\n",
    "    \n",
    "result_output_metrics = pd.concat(all_output_metrics,axis = 1)\n",
    "result_output_importance = pd.concat(all_output_importance,axis = 1)\n",
    "result_output_metrics.index = result_output_importance.index = ['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']\n",
    "\n",
    "result_output_metrics.to_csv(f\"LSTM_1site_1feature_batch_metrics.csv\",index=False)\n",
    "result_output_importance.to_csv(f\"LSTM_1site_1feature_batch_importance.csv\",index=False)\n",
    "#['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127d3a8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 单站点所有特征Single site all feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1820d8a5",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 2.6202, Val Loss: 1.1323\n",
      "Epoch 2/200, Train Loss: 0.7865, Val Loss: 0.8607\n",
      "Epoch 3/200, Train Loss: 0.6741, Val Loss: 0.9804\n",
      "Epoch 4/200, Train Loss: 0.6029, Val Loss: 0.9747\n",
      "Epoch 5/200, Train Loss: 0.5386, Val Loss: 0.8182\n",
      "Epoch 6/200, Train Loss: 0.4953, Val Loss: 0.6205\n",
      "Epoch 7/200, Train Loss: 0.4408, Val Loss: 0.8804\n",
      "Epoch 8/200, Train Loss: 0.4180, Val Loss: 0.9238\n",
      "Epoch 9/200, Train Loss: 0.3838, Val Loss: 1.0262\n",
      "Epoch 10/200, Train Loss: 0.3611, Val Loss: 0.6079\n",
      "Epoch 11/200, Train Loss: 0.3491, Val Loss: 0.7814\n",
      "Epoch 12/200, Train Loss: 0.3197, Val Loss: 0.9267\n",
      "Epoch 13/200, Train Loss: 0.3162, Val Loss: 0.8959\n",
      "Epoch 14/200, Train Loss: 0.2977, Val Loss: 0.6195\n",
      "Epoch 15/200, Train Loss: 0.2878, Val Loss: 0.9947\n",
      "Epoch 16/200, Train Loss: 0.2690, Val Loss: 1.0277\n",
      "Epoch 17/200, Train Loss: 0.2658, Val Loss: 0.8459\n",
      "Epoch 18/200, Train Loss: 0.2550, Val Loss: 0.5891\n",
      "Epoch 19/200, Train Loss: 0.2444, Val Loss: 0.6369\n",
      "Epoch 20/200, Train Loss: 0.2386, Val Loss: 0.6940\n",
      "Epoch 21/200, Train Loss: 0.2314, Val Loss: 0.7375\n",
      "Epoch 22/200, Train Loss: 0.2211, Val Loss: 0.9127\n",
      "Epoch 23/200, Train Loss: 0.2141, Val Loss: 0.8134\n",
      "Epoch 24/200, Train Loss: 0.2114, Val Loss: 1.0056\n",
      "Epoch 25/200, Train Loss: 0.2079, Val Loss: 0.8006\n",
      "Epoch 26/200, Train Loss: 0.2028, Val Loss: 0.7569\n",
      "Epoch 27/200, Train Loss: 0.2012, Val Loss: 0.8236\n",
      "Epoch 28/200, Train Loss: 0.1927, Val Loss: 0.6470\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.7190\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.8480\n",
      "Test R2: 0.7011\n",
      "Test MAE: 0.6274\n",
      "0    2.138958\n",
      "1    2.290434\n",
      "2    0.659580\n",
      "3    0.638669\n",
      "4    0.373547\n",
      "5    0.132400\n",
      "6    0.018785\n",
      "7    0.373194\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.2617, Val Loss: 1.4966\n",
      "Epoch 2/200, Train Loss: 0.7069, Val Loss: 0.9923\n",
      "Epoch 3/200, Train Loss: 0.5849, Val Loss: 0.8727\n",
      "Epoch 4/200, Train Loss: 0.4983, Val Loss: 0.9049\n",
      "Epoch 5/200, Train Loss: 0.4562, Val Loss: 0.5654\n",
      "Epoch 6/200, Train Loss: 0.4195, Val Loss: 0.9197\n",
      "Epoch 7/200, Train Loss: 0.4105, Val Loss: 0.7393\n",
      "Epoch 8/200, Train Loss: 0.3894, Val Loss: 1.0631\n",
      "Epoch 9/200, Train Loss: 0.3850, Val Loss: 0.7528\n",
      "Epoch 10/200, Train Loss: 0.3500, Val Loss: 0.4910\n",
      "Epoch 11/200, Train Loss: 0.3340, Val Loss: 0.7086\n",
      "Epoch 12/200, Train Loss: 0.3109, Val Loss: 0.6225\n",
      "Epoch 13/200, Train Loss: 0.3150, Val Loss: 0.8301\n",
      "Epoch 14/200, Train Loss: 0.3041, Val Loss: 0.5333\n",
      "Epoch 15/200, Train Loss: 0.2980, Val Loss: 0.7934\n",
      "Epoch 16/200, Train Loss: 0.2692, Val Loss: 0.4635\n",
      "Epoch 17/200, Train Loss: 0.2722, Val Loss: 0.7410\n",
      "Epoch 18/200, Train Loss: 0.2666, Val Loss: 0.7593\n",
      "Epoch 19/200, Train Loss: 0.3831, Val Loss: 1.2225\n",
      "Epoch 20/200, Train Loss: 0.2871, Val Loss: 1.1374\n",
      "Epoch 21/200, Train Loss: 0.2861, Val Loss: 0.8548\n",
      "Epoch 22/200, Train Loss: 0.2513, Val Loss: 0.8731\n",
      "Epoch 23/200, Train Loss: 0.2532, Val Loss: 0.7302\n",
      "Epoch 24/200, Train Loss: 0.2325, Val Loss: 0.8430\n",
      "Epoch 25/200, Train Loss: 0.2987, Val Loss: 0.4771\n",
      "Epoch 26/200, Train Loss: 0.3774, Val Loss: 0.7499\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.9390\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.9690\n",
      "Test R2: 0.4740\n",
      "Test MAE: 0.7745\n",
      "0    4.023123\n",
      "1    3.716240\n",
      "2    1.163334\n",
      "3    1.344079\n",
      "4    1.202499\n",
      "5    0.235756\n",
      "6    0.168673\n",
      "7    1.291031\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.5120, Val Loss: 1.1025\n",
      "Epoch 2/200, Train Loss: 0.9554, Val Loss: 1.1760\n",
      "Epoch 3/200, Train Loss: 0.8465, Val Loss: 1.2168\n",
      "Epoch 4/200, Train Loss: 0.7739, Val Loss: 1.0670\n",
      "Epoch 5/200, Train Loss: 0.7401, Val Loss: 1.3530\n",
      "Epoch 6/200, Train Loss: 0.7283, Val Loss: 1.6160\n",
      "Epoch 7/200, Train Loss: 0.6860, Val Loss: 1.1951\n",
      "Epoch 8/200, Train Loss: 0.6582, Val Loss: 1.2418\n",
      "Epoch 9/200, Train Loss: 0.6377, Val Loss: 1.0666\n",
      "Epoch 10/200, Train Loss: 0.6117, Val Loss: 1.1249\n",
      "Epoch 11/200, Train Loss: 0.6302, Val Loss: 1.1565\n",
      "Epoch 12/200, Train Loss: 0.5601, Val Loss: 1.3263\n",
      "Epoch 13/200, Train Loss: 0.5477, Val Loss: 1.1274\n",
      "Epoch 14/200, Train Loss: 0.5312, Val Loss: 1.4009\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.6279\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.2759\n",
      "Test R2: 0.7067\n",
      "Test MAE: 1.0076\n",
      "0    2.530225\n",
      "1    2.649567\n",
      "2    1.465639\n",
      "3    1.589795\n",
      "4    0.640061\n",
      "5    0.665312\n",
      "6    0.070241\n",
      "7    0.629929\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.3470, Val Loss: 2.5648\n",
      "Epoch 2/200, Train Loss: 0.9671, Val Loss: 2.4804\n",
      "Epoch 3/200, Train Loss: 0.8538, Val Loss: 1.8905\n",
      "Epoch 4/200, Train Loss: 0.7346, Val Loss: 1.5816\n",
      "Epoch 5/200, Train Loss: 0.6682, Val Loss: 1.8979\n",
      "Epoch 6/200, Train Loss: 0.6121, Val Loss: 1.7479\n",
      "Epoch 7/200, Train Loss: 0.5782, Val Loss: 1.5613\n",
      "Epoch 8/200, Train Loss: 0.5577, Val Loss: 1.4100\n",
      "Epoch 9/200, Train Loss: 0.5228, Val Loss: 1.8248\n",
      "Epoch 10/200, Train Loss: 0.5130, Val Loss: 1.6260\n",
      "Epoch 11/200, Train Loss: 0.4888, Val Loss: 1.9047\n",
      "Epoch 12/200, Train Loss: 0.4647, Val Loss: 1.6838\n",
      "Epoch 13/200, Train Loss: 0.4527, Val Loss: 1.8231\n",
      "Epoch 14/200, Train Loss: 0.4379, Val Loss: 1.6991\n",
      "Epoch 15/200, Train Loss: 0.4099, Val Loss: 1.1953\n",
      "Epoch 16/200, Train Loss: 0.3959, Val Loss: 2.2985\n",
      "Epoch 17/200, Train Loss: 0.3749, Val Loss: 2.0944\n",
      "Epoch 18/200, Train Loss: 0.3627, Val Loss: 1.5885\n",
      "Epoch 19/200, Train Loss: 0.3518, Val Loss: 1.6161\n",
      "Epoch 20/200, Train Loss: 0.3496, Val Loss: 1.2104\n",
      "Epoch 21/200, Train Loss: 0.3319, Val Loss: 1.8982\n",
      "Epoch 22/200, Train Loss: 0.3186, Val Loss: 1.6667\n",
      "Epoch 23/200, Train Loss: 0.3178, Val Loss: 2.2137\n",
      "Epoch 24/200, Train Loss: 0.3126, Val Loss: 2.0639\n",
      "Epoch 25/200, Train Loss: 0.2984, Val Loss: 1.6229\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.8919\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.9444\n",
      "Test R2: 0.7623\n",
      "Test MAE: 0.7453\n",
      "0    2.283435\n",
      "1    5.228227\n",
      "2    1.212747\n",
      "3    1.222010\n",
      "4    0.655914\n",
      "5    0.408965\n",
      "6    0.048659\n",
      "7    0.251425\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.4815, Val Loss: 1.1311\n",
      "Epoch 2/200, Train Loss: 0.6497, Val Loss: 1.2706\n",
      "Epoch 3/200, Train Loss: 0.5896, Val Loss: 0.9942\n",
      "Epoch 4/200, Train Loss: 0.5589, Val Loss: 1.1088\n",
      "Epoch 5/200, Train Loss: 0.5186, Val Loss: 1.1506\n",
      "Epoch 6/200, Train Loss: 0.4891, Val Loss: 1.3425\n",
      "Epoch 7/200, Train Loss: 0.4699, Val Loss: 1.1456\n",
      "Epoch 8/200, Train Loss: 0.4651, Val Loss: 1.2409\n",
      "Epoch 9/200, Train Loss: 0.4432, Val Loss: 1.1474\n",
      "Epoch 10/200, Train Loss: 0.4098, Val Loss: 1.2816\n",
      "Epoch 11/200, Train Loss: 0.3992, Val Loss: 1.1904\n",
      "Epoch 12/200, Train Loss: 0.3848, Val Loss: 1.1456\n",
      "Epoch 13/200, Train Loss: 0.3625, Val Loss: 1.5782\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.6406\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.8004\n",
      "Test R2: 0.8617\n",
      "Test MAE: 0.6430\n",
      "0    3.237765\n",
      "1    0.411084\n",
      "2    2.267497\n",
      "3    0.731920\n",
      "4    0.161032\n",
      "5    0.981401\n",
      "6    0.173286\n",
      "7    0.681951\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.3180, Val Loss: 1.3154\n",
      "Epoch 2/200, Train Loss: 0.8892, Val Loss: 1.4654\n",
      "Epoch 3/200, Train Loss: 0.8088, Val Loss: 1.3028\n",
      "Epoch 4/200, Train Loss: 0.7256, Val Loss: 1.4405\n",
      "Epoch 5/200, Train Loss: 0.6753, Val Loss: 1.8608\n",
      "Epoch 6/200, Train Loss: 0.6209, Val Loss: 1.8533\n",
      "Epoch 7/200, Train Loss: 0.5615, Val Loss: 1.4429\n",
      "Epoch 8/200, Train Loss: 0.5065, Val Loss: 1.6373\n",
      "Epoch 9/200, Train Loss: 0.4538, Val Loss: 2.2838\n",
      "Epoch 10/200, Train Loss: 0.4390, Val Loss: 1.7342\n",
      "Epoch 11/200, Train Loss: 0.4128, Val Loss: 2.0745\n",
      "Epoch 12/200, Train Loss: 0.3915, Val Loss: 2.0153\n",
      "Epoch 13/200, Train Loss: 0.3771, Val Loss: 1.5136\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.8522\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.9231\n",
      "Test R2: 0.7357\n",
      "Test MAE: 0.7468\n",
      "0    3.303003\n",
      "1    3.660282\n",
      "2    1.503640\n",
      "3    1.197069\n",
      "4    0.379190\n",
      "5    0.032411\n",
      "6    0.105017\n",
      "7    1.019195\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.7697, Val Loss: 1.1499\n",
      "Epoch 2/200, Train Loss: 1.1875, Val Loss: 1.5241\n",
      "Epoch 3/200, Train Loss: 1.0775, Val Loss: 1.9301\n",
      "Epoch 4/200, Train Loss: 0.9783, Val Loss: 1.3223\n",
      "Epoch 5/200, Train Loss: 0.9140, Val Loss: 1.2131\n",
      "Epoch 6/200, Train Loss: 0.8836, Val Loss: 1.4654\n",
      "Epoch 7/200, Train Loss: 0.8481, Val Loss: 2.0130\n",
      "Epoch 8/200, Train Loss: 0.8427, Val Loss: 1.9627\n",
      "Epoch 9/200, Train Loss: 0.8040, Val Loss: 1.2604\n",
      "Epoch 10/200, Train Loss: 0.7902, Val Loss: 2.0551\n",
      "Epoch 11/200, Train Loss: 0.7776, Val Loss: 1.1049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200, Train Loss: 0.7660, Val Loss: 1.5407\n",
      "Epoch 13/200, Train Loss: 0.7577, Val Loss: 1.5868\n",
      "Epoch 14/200, Train Loss: 0.7373, Val Loss: 1.5623\n",
      "Epoch 15/200, Train Loss: 0.7341, Val Loss: 1.6910\n",
      "Epoch 16/200, Train Loss: 0.7194, Val Loss: 1.9042\n",
      "Epoch 17/200, Train Loss: 0.7218, Val Loss: 2.0527\n",
      "Epoch 18/200, Train Loss: 0.7068, Val Loss: 1.7841\n",
      "Epoch 19/200, Train Loss: 0.6888, Val Loss: 1.5900\n",
      "Epoch 20/200, Train Loss: 0.6876, Val Loss: 1.8324\n",
      "Epoch 21/200, Train Loss: 0.6781, Val Loss: 1.9716\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.5480\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.2442\n",
      "Test R2: 0.3697\n",
      "Test MAE: 1.0676\n",
      "0    0.882222\n",
      "1    0.267818\n",
      "2    1.741739\n",
      "3    0.783647\n",
      "4    0.148683\n",
      "5    0.004911\n",
      "6    0.001696\n",
      "7    0.382953\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.0229, Val Loss: 1.8043\n",
      "Epoch 2/200, Train Loss: 1.5061, Val Loss: 1.8709\n",
      "Epoch 3/200, Train Loss: 1.4681, Val Loss: 1.6530\n",
      "Epoch 4/200, Train Loss: 1.4390, Val Loss: 1.6047\n",
      "Epoch 5/200, Train Loss: 1.4568, Val Loss: 1.8629\n",
      "Epoch 6/200, Train Loss: 1.4218, Val Loss: 1.9739\n",
      "Epoch 7/200, Train Loss: 1.3966, Val Loss: 1.8147\n",
      "Epoch 8/200, Train Loss: 1.3779, Val Loss: 2.1493\n",
      "Epoch 9/200, Train Loss: 1.3834, Val Loss: 1.7747\n",
      "Epoch 10/200, Train Loss: 1.3448, Val Loss: 1.9039\n",
      "Epoch 11/200, Train Loss: 1.3410, Val Loss: 2.1268\n",
      "Epoch 12/200, Train Loss: 1.3122, Val Loss: 1.9768\n",
      "Epoch 13/200, Train Loss: 1.2943, Val Loss: 2.1011\n",
      "Epoch 14/200, Train Loss: 1.2901, Val Loss: 1.9454\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.0414\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.4288\n",
      "Test R2: 0.1130\n",
      "Test MAE: 1.1062\n",
      "0    0.525784\n",
      "1    0.045955\n",
      "2    2.333824\n",
      "3    0.336335\n",
      "4    0.082342\n",
      "5    0.002217\n",
      "6    0.002629\n",
      "7    0.037049\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.1363, Val Loss: 2.2058\n",
      "Epoch 2/200, Train Loss: 1.6227, Val Loss: 2.8398\n",
      "Epoch 3/200, Train Loss: 1.5392, Val Loss: 2.0027\n",
      "Epoch 4/200, Train Loss: 1.4686, Val Loss: 2.9633\n",
      "Epoch 5/200, Train Loss: 1.3666, Val Loss: 1.2422\n",
      "Epoch 6/200, Train Loss: 1.2880, Val Loss: 3.4087\n",
      "Epoch 7/200, Train Loss: 1.2850, Val Loss: 1.2983\n",
      "Epoch 8/200, Train Loss: 1.2257, Val Loss: 1.4740\n",
      "Epoch 9/200, Train Loss: 1.2068, Val Loss: 1.2809\n",
      "Epoch 10/200, Train Loss: 1.1708, Val Loss: 1.5109\n",
      "Epoch 11/200, Train Loss: 1.1948, Val Loss: 1.0984\n",
      "Epoch 12/200, Train Loss: 1.1388, Val Loss: 1.3789\n",
      "Epoch 13/200, Train Loss: 1.0984, Val Loss: 1.7437\n",
      "Epoch 14/200, Train Loss: 1.0077, Val Loss: 1.2601\n",
      "Epoch 15/200, Train Loss: 0.9684, Val Loss: 1.1013\n",
      "Epoch 16/200, Train Loss: 0.9665, Val Loss: 1.0983\n",
      "Epoch 17/200, Train Loss: 0.9430, Val Loss: 1.9630\n",
      "Epoch 18/200, Train Loss: 0.9074, Val Loss: 1.1837\n",
      "Epoch 19/200, Train Loss: 0.9401, Val Loss: 1.2647\n",
      "Epoch 20/200, Train Loss: 0.9276, Val Loss: 1.2280\n",
      "Epoch 21/200, Train Loss: 0.8765, Val Loss: 1.3447\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.4048\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1852\n",
      "Test R2: 0.6230\n",
      "Test MAE: 0.9340\n",
      "0    1.267925\n",
      "1    0.488832\n",
      "2    2.258293\n",
      "3    0.298448\n",
      "4    0.466590\n",
      "5    0.153266\n",
      "6    0.003032\n",
      "7    0.296628\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "#单站点所有特征循环,Single site all feature\n",
    "#change the Define function input:X_origin[:,:,target_site_index,:].squeeze(),LSTM_input_size = 9\n",
    "all_output_metrics = []\n",
    "all_output_importance = []\n",
    "\n",
    "for model_sites in range(9):\n",
    "    #Model hyperparameters\n",
    "    # 模型超参数\n",
    "    LSTM_input_size = 9\n",
    "    LSTM_hidden_size = 64  \n",
    "    LSTM_num_layers = 2\n",
    "\n",
    "    input_seq_len = 72  # 输入序列长度,Input sequence length\n",
    "    output_seq_len = 1  # 输出序列长度,output sequence length\n",
    "    target_site_index = model_sites  # 目标站点（例如 站点0）,Target site (e.g. site 0)\n",
    "    target_col = 2  # 目标特征（例如 特征0）,Target feature (e.g. feature 0)\n",
    "    batch_size = 16\n",
    "\n",
    "    X, y = create_sequences(data, input_seq_len, output_seq_len, target_site_index, target_col)\n",
    "    y = y.squeeze((-1,-2))\n",
    "    #Divide the training set，validation set and test set 7:1:2\n",
    "    # 划分训练集验证集和测试集7：1：2\n",
    "    train_size, val_size, test_size = 0.7, 0.1, 0.2\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size/(train_size+val_size+test_size), shuffle=False)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size/(train_size+val_size), shuffle=False)\n",
    "    X_train, X_val, X_test = to_tensor(X_train), to_tensor(X_val), to_tensor(X_test)\n",
    "    y_train, y_val, y_test = to_tensor(y_train), to_tensor(y_val), to_tensor(y_test)\n",
    "    # create DataLoader\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    lstm_model = LSTMModel(LSTM_input_size, LSTM_hidden_size, LSTM_num_layers, output_seq_len)\n",
    "    lstm_model.to(device)\n",
    "\n",
    "    epochs=200\n",
    "    learning_rate = 0.001\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
    "    epoch_logs=[]\n",
    "    #input_feature will not input into the model\n",
    "    input_feature = 0#0:WT,1:pH,2:DO,3:EC,4:TSS,5:CODMN,6:AN,7:TP,8:TN\n",
    "\n",
    "    LSTM_train_and_evaluate(lstm_model, train_loader, val_loader, criterion, optimizer, epochs, target_site_index, input_feature)\n",
    "    predictions, actuals = LSTM_evaluate(lstm_model, test_loader, target_site_index, input_feature)\n",
    "    #Calculate accuracy\n",
    "    # 计算精度\n",
    "    rmse, r2, mae = calculate_metrics(predictions, actuals)\n",
    "    #result\n",
    "    # 输出结果\n",
    "    print(f\"predictions shape: {predictions.shape}\")\n",
    "    print(f\"actuals shape: {actuals.shape}\")\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test R2: {r2:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    feature_importances = np.mean(pd.DataFrame(LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='zero')),axis= 0)\n",
    "    print(feature_importances)\n",
    "\n",
    "    all_output_metrics.append([rmse, r2, mae])\n",
    "    all_output_importance.append(pd.DataFrame({f\"N{model_sites}\" : feature_importances.values}, index = ['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']))\n",
    "    epoch_logs = pd.DataFrame(epoch_logs,columns=['Epoch','Train_Loss','Val_loss','Time'])\n",
    "    epoch_logs.to_csv(f\"LSTM_logs_1siteallfeature_batch_site{model_sites}.csv\",index=False)\n",
    "\n",
    "result_output_metrics = pd.DataFrame(all_output_metrics,columns=['RMSE','R2','MAE'])\n",
    "result_output_importance = pd.concat(all_output_importance,axis = 1)\n",
    "\n",
    "result_output_metrics.to_csv(f\"LSTM_1siteallfeature_batch_metrics_.csv\",index=False)\n",
    "result_output_importance.to_csv(f\"LSTM_1siteallfeature_logs_one_batch_importance.csv\",index=False)\n",
    "#['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f43749d7",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 2.6603, Val Loss: 1.2154\n",
      "Epoch 2/200, Train Loss: 0.8296, Val Loss: 1.4550\n",
      "Epoch 3/200, Train Loss: 0.6991, Val Loss: 1.2598\n",
      "Epoch 4/200, Train Loss: 0.6079, Val Loss: 0.8132\n",
      "Epoch 5/200, Train Loss: 0.5373, Val Loss: 0.8525\n",
      "Epoch 6/200, Train Loss: 0.4523, Val Loss: 1.0703\n",
      "Epoch 7/200, Train Loss: 0.4107, Val Loss: 0.7283\n",
      "Epoch 8/200, Train Loss: 0.3748, Val Loss: 1.0407\n",
      "Epoch 9/200, Train Loss: 0.3367, Val Loss: 0.8848\n",
      "Epoch 10/200, Train Loss: 0.3039, Val Loss: 0.7364\n",
      "Epoch 11/200, Train Loss: 0.2805, Val Loss: 0.9000\n",
      "Epoch 12/200, Train Loss: 0.2529, Val Loss: 0.6937\n",
      "Epoch 13/200, Train Loss: 0.2374, Val Loss: 0.6792\n",
      "Epoch 14/200, Train Loss: 0.2414, Val Loss: 0.7130\n",
      "Epoch 15/200, Train Loss: 0.2234, Val Loss: 0.6951\n",
      "Epoch 16/200, Train Loss: 0.2094, Val Loss: 0.6312\n",
      "Epoch 17/200, Train Loss: 0.2037, Val Loss: 0.6833\n",
      "Epoch 18/200, Train Loss: 0.2113, Val Loss: 0.5691\n",
      "Epoch 19/200, Train Loss: 0.1858, Val Loss: 0.8292\n",
      "Epoch 20/200, Train Loss: 0.2012, Val Loss: 0.6698\n",
      "Epoch 21/200, Train Loss: 0.1748, Val Loss: 0.8668\n",
      "Epoch 22/200, Train Loss: 0.1792, Val Loss: 0.6592\n",
      "Epoch 23/200, Train Loss: 0.1757, Val Loss: 0.7894\n",
      "Epoch 24/200, Train Loss: 0.1669, Val Loss: 0.6704\n",
      "Epoch 25/200, Train Loss: 0.1852, Val Loss: 0.7292\n",
      "Epoch 26/200, Train Loss: 0.1515, Val Loss: 0.7334\n",
      "Epoch 27/200, Train Loss: 0.1519, Val Loss: 0.7542\n",
      "Epoch 28/200, Train Loss: 0.1505, Val Loss: 0.9111\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.6799\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.8245\n",
      "Test R2: 0.7173\n",
      "Test MAE: 0.5777\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "# 模型超参数\n",
    "LSTM_input_size = 8\n",
    "LSTM_hidden_size = 64  # LSTM 隐藏层大小\n",
    "LSTM_num_layers = 2\n",
    "\n",
    "input_seq_len = 72  # 输入序列长度\n",
    "output_seq_len = 1  # 输出序列长度\n",
    "target_site_index = 0  # 目标站点的索引（例如 站点0）\n",
    "target_col = 2  # 目标特征列的索引（例如 特征0）\n",
    "batch_size = 16\n",
    "\n",
    "X, y = create_sequences(data, input_seq_len, output_seq_len, target_site_index, target_col)\n",
    "y = y.squeeze((-1,-2))\n",
    "# 划分训练集和测试集\n",
    "train_size, val_size, test_size = 0.7, 0.1, 0.2\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size/(train_size+val_size+test_size), shuffle=False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size/(train_size+val_size), shuffle=False)\n",
    "X_train, X_val, X_test = to_tensor(X_train), to_tensor(X_val), to_tensor(X_test)\n",
    "y_train, y_val, y_test = to_tensor(y_train), to_tensor(y_val), to_tensor(y_test)\n",
    "# 创建DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "lstm_model = LSTMModel(LSTM_input_size, LSTM_hidden_size, LSTM_num_layers, output_seq_len)\n",
    "lstm_model.to(device)\n",
    "\n",
    "epochs=200\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
    "epoch_logs=[]\n",
    "input_feature = [0,1,3,4,5,6,7,8]#0水温\t1pH\t2溶解氧\t3电导率\t4浊度\t5高锰酸盐\t6氨氮\t7总磷\t8总氮\n",
    "\n",
    "LSTM_train_and_evaluate(lstm_model, train_loader, val_loader, criterion, optimizer, epochs, target_site_index, input_feature)\n",
    "predictions, actuals = LSTM_evaluate(lstm_model, test_loader, target_site_index, input_feature)\n",
    "# 计算精度\n",
    "rmse, r2, mae = calculate_metrics(predictions, actuals)\n",
    "# 输出结果\n",
    "print(f\"predictions shape: {predictions.shape}\")\n",
    "print(f\"actuals shape: {actuals.shape}\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test R2: {r2:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "\n",
    "#['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "877bb4b5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2.391290\n",
      "1    2.771468\n",
      "2    1.032951\n",
      "3    0.758217\n",
      "4    0.344273\n",
      "5    0.086456\n",
      "6    0.011174\n",
      "7    0.401491\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "feature_importances = np.mean(pd.DataFrame(LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='zero')),axis= 0)\n",
    "print(feature_importances)\n",
    "# max(data[:,4,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc94a45",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 所有站点单特征all site single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d737ccb2",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 3.0030, Val Loss: 0.9157\n",
      "Epoch 2/200, Train Loss: 0.9191, Val Loss: 0.9055\n",
      "Epoch 3/200, Train Loss: 0.8260, Val Loss: 1.0826\n",
      "Epoch 4/200, Train Loss: 0.7328, Val Loss: 1.2477\n",
      "Epoch 5/200, Train Loss: 0.6440, Val Loss: 1.2438\n",
      "Epoch 6/200, Train Loss: 0.5811, Val Loss: 1.4037\n",
      "Epoch 7/200, Train Loss: 0.5245, Val Loss: 1.6788\n",
      "Epoch 8/200, Train Loss: 0.4472, Val Loss: 1.8964\n",
      "Epoch 9/200, Train Loss: 0.4101, Val Loss: 1.8230\n",
      "Epoch 10/200, Train Loss: 0.3665, Val Loss: 1.6289\n",
      "Epoch 11/200, Train Loss: 0.4091, Val Loss: 1.5309\n",
      "Epoch 12/200, Train Loss: 0.3304, Val Loss: 1.5466\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.1234\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.0599\n",
      "Test R2: 0.5329\n",
      "Test MAE: 0.7735\n",
      "0    2.296097\n",
      "1    1.228502\n",
      "2    0.843662\n",
      "3    1.298746\n",
      "4    1.704691\n",
      "5    0.666102\n",
      "6    0.990321\n",
      "7    0.828745\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.3002, Val Loss: 0.9018\n",
      "Epoch 2/200, Train Loss: 0.7171, Val Loss: 0.6982\n",
      "Epoch 3/200, Train Loss: 0.6023, Val Loss: 0.9247\n",
      "Epoch 4/200, Train Loss: 0.5014, Val Loss: 0.8042\n",
      "Epoch 5/200, Train Loss: 0.4453, Val Loss: 1.2516\n",
      "Epoch 6/200, Train Loss: 0.4451, Val Loss: 0.7975\n",
      "Epoch 7/200, Train Loss: 0.3759, Val Loss: 0.8651\n",
      "Epoch 8/200, Train Loss: 0.3281, Val Loss: 1.5680\n",
      "Epoch 9/200, Train Loss: 0.3151, Val Loss: 0.9723\n",
      "Epoch 10/200, Train Loss: 0.2864, Val Loss: 1.4283\n",
      "Epoch 11/200, Train Loss: 0.2664, Val Loss: 1.0264\n",
      "Epoch 12/200, Train Loss: 0.2471, Val Loss: 1.0217\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.8862\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.9414\n",
      "Test R2: 0.5036\n",
      "Test MAE: 0.7230\n",
      "0    3.410249\n",
      "1    1.231959\n",
      "2    1.754149\n",
      "3    0.539828\n",
      "4    0.990353\n",
      "5    0.677665\n",
      "6    0.594511\n",
      "7    0.470022\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.0874, Val Loss: 1.0173\n",
      "Epoch 2/200, Train Loss: 0.9206, Val Loss: 1.1431\n",
      "Epoch 3/200, Train Loss: 0.8574, Val Loss: 1.6413\n",
      "Epoch 4/200, Train Loss: 0.7994, Val Loss: 1.1466\n",
      "Epoch 5/200, Train Loss: 0.7539, Val Loss: 1.0154\n",
      "Epoch 6/200, Train Loss: 0.7128, Val Loss: 1.7176\n",
      "Epoch 7/200, Train Loss: 0.6745, Val Loss: 1.7275\n",
      "Epoch 8/200, Train Loss: 0.6404, Val Loss: 1.4030\n",
      "Epoch 9/200, Train Loss: 0.6119, Val Loss: 1.6457\n",
      "Epoch 10/200, Train Loss: 0.5937, Val Loss: 1.0780\n",
      "Epoch 11/200, Train Loss: 0.5782, Val Loss: 1.1315\n",
      "Epoch 12/200, Train Loss: 0.5427, Val Loss: 1.0423\n",
      "Epoch 13/200, Train Loss: 0.5419, Val Loss: 1.4810\n",
      "Epoch 14/200, Train Loss: 0.5000, Val Loss: 1.0643\n",
      "Epoch 15/200, Train Loss: 0.4833, Val Loss: 1.4487\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.0976\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.4483\n",
      "Test R2: 0.6221\n",
      "Test MAE: 1.1481\n",
      "0    0.918810\n",
      "1    1.188200\n",
      "2    1.942964\n",
      "3    2.393117\n",
      "4    0.557271\n",
      "5    0.999377\n",
      "6    0.822826\n",
      "7    1.597014\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.9241, Val Loss: 2.0859\n",
      "Epoch 2/200, Train Loss: 0.7716, Val Loss: 1.9243\n",
      "Epoch 3/200, Train Loss: 0.7126, Val Loss: 2.0063\n",
      "Epoch 4/200, Train Loss: 0.6805, Val Loss: 2.0239\n",
      "Epoch 5/200, Train Loss: 0.6617, Val Loss: 2.3879\n",
      "Epoch 6/200, Train Loss: 0.6394, Val Loss: 1.9067\n",
      "Epoch 7/200, Train Loss: 0.6172, Val Loss: 1.6730\n",
      "Epoch 8/200, Train Loss: 0.5874, Val Loss: 2.1001\n",
      "Epoch 9/200, Train Loss: 0.5847, Val Loss: 1.8071\n",
      "Epoch 10/200, Train Loss: 0.5566, Val Loss: 2.6896\n",
      "Epoch 11/200, Train Loss: 0.5368, Val Loss: 2.1566\n",
      "Epoch 12/200, Train Loss: 0.5122, Val Loss: 1.8801\n",
      "Epoch 13/200, Train Loss: 0.5087, Val Loss: 2.0423\n",
      "Epoch 14/200, Train Loss: 0.4821, Val Loss: 1.8893\n",
      "Epoch 15/200, Train Loss: 0.4612, Val Loss: 2.0063\n",
      "Epoch 16/200, Train Loss: 0.4451, Val Loss: 2.2594\n",
      "Epoch 17/200, Train Loss: 0.4357, Val Loss: 1.8786\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.7673\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.8760\n",
      "Test R2: 0.7955\n",
      "Test MAE: 0.6671\n",
      "0    0.918317\n",
      "1    2.003175\n",
      "2    0.784276\n",
      "3    0.631823\n",
      "4    2.496540\n",
      "5    0.526544\n",
      "6    1.232039\n",
      "7    0.807768\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.3410, Val Loss: 2.1874\n",
      "Epoch 2/200, Train Loss: 0.7194, Val Loss: 1.9812\n",
      "Epoch 3/200, Train Loss: 0.6985, Val Loss: 2.3316\n",
      "Epoch 4/200, Train Loss: 0.6556, Val Loss: 1.8345\n",
      "Epoch 5/200, Train Loss: 0.6221, Val Loss: 2.0585\n",
      "Epoch 6/200, Train Loss: 0.5937, Val Loss: 2.1705\n",
      "Epoch 7/200, Train Loss: 0.5656, Val Loss: 2.0104\n",
      "Epoch 8/200, Train Loss: 0.5372, Val Loss: 1.9716\n",
      "Epoch 9/200, Train Loss: 0.5030, Val Loss: 1.9907\n",
      "Epoch 10/200, Train Loss: 0.4760, Val Loss: 2.0858\n",
      "Epoch 11/200, Train Loss: 0.4565, Val Loss: 2.0486\n",
      "Epoch 12/200, Train Loss: 0.4375, Val Loss: 1.9578\n",
      "Epoch 13/200, Train Loss: 0.4251, Val Loss: 2.2079\n",
      "Epoch 14/200, Train Loss: 0.4164, Val Loss: 1.9993\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.1080\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.0526\n",
      "Test R2: 0.7609\n",
      "Test MAE: 0.8448\n",
      "0    1.960501\n",
      "1    0.988266\n",
      "2    1.237403\n",
      "3    1.494400\n",
      "4    0.890822\n",
      "5    0.908592\n",
      "6    0.757757\n",
      "7    3.414669\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.7118, Val Loss: 0.5410\n",
      "Epoch 2/200, Train Loss: 0.7517, Val Loss: 0.5714\n",
      "Epoch 3/200, Train Loss: 0.6968, Val Loss: 0.6547\n",
      "Epoch 4/200, Train Loss: 0.6739, Val Loss: 0.7211\n",
      "Epoch 5/200, Train Loss: 0.6335, Val Loss: 0.6000\n",
      "Epoch 6/200, Train Loss: 0.5873, Val Loss: 0.7730\n",
      "Epoch 7/200, Train Loss: 0.5630, Val Loss: 0.6264\n",
      "Epoch 8/200, Train Loss: 0.5402, Val Loss: 0.6499\n",
      "Epoch 9/200, Train Loss: 0.5178, Val Loss: 0.6382\n",
      "Epoch 10/200, Train Loss: 0.4752, Val Loss: 0.6198\n",
      "Epoch 11/200, Train Loss: 0.4807, Val Loss: 0.6699\n",
      "Early stopping triggered.\n",
      "Test MSE: 0.8524\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 0.9233\n",
      "Test R2: 0.7356\n",
      "Test MAE: 0.7045\n",
      "0    0.684469\n",
      "1    1.594190\n",
      "2    0.645992\n",
      "3    3.134269\n",
      "4    1.092802\n",
      "5    0.534871\n",
      "6    1.233656\n",
      "7    0.678131\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.5976, Val Loss: 0.8250\n",
      "Epoch 2/200, Train Loss: 1.0086, Val Loss: 1.2492\n",
      "Epoch 3/200, Train Loss: 0.9378, Val Loss: 1.2267\n",
      "Epoch 4/200, Train Loss: 0.8900, Val Loss: 1.2939\n",
      "Epoch 5/200, Train Loss: 0.8429, Val Loss: 0.9902\n",
      "Epoch 6/200, Train Loss: 0.8008, Val Loss: 1.5565\n",
      "Epoch 7/200, Train Loss: 0.7501, Val Loss: 1.3915\n",
      "Epoch 8/200, Train Loss: 0.7334, Val Loss: 1.7767\n",
      "Epoch 9/200, Train Loss: 0.7083, Val Loss: 1.2577\n",
      "Epoch 10/200, Train Loss: 0.7285, Val Loss: 1.8029\n",
      "Epoch 11/200, Train Loss: 0.7269, Val Loss: 1.8051\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.0998\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.0487\n",
      "Test R2: 0.5522\n",
      "Test MAE: 0.8564\n",
      "0    0.924140\n",
      "1    1.092927\n",
      "2    1.220607\n",
      "3    0.780408\n",
      "4    1.453317\n",
      "5    1.122156\n",
      "6    1.622087\n",
      "7    0.936727\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.7464, Val Loss: 1.1258\n",
      "Epoch 2/200, Train Loss: 1.1286, Val Loss: 1.1768\n",
      "Epoch 3/200, Train Loss: 1.0911, Val Loss: 1.2421\n",
      "Epoch 4/200, Train Loss: 1.0738, Val Loss: 1.2242\n",
      "Epoch 5/200, Train Loss: 1.0156, Val Loss: 1.2195\n",
      "Epoch 6/200, Train Loss: 0.9853, Val Loss: 1.4146\n",
      "Epoch 7/200, Train Loss: 0.9558, Val Loss: 1.3439\n",
      "Epoch 8/200, Train Loss: 0.9363, Val Loss: 1.2583\n",
      "Epoch 9/200, Train Loss: 0.9030, Val Loss: 1.3036\n",
      "Epoch 10/200, Train Loss: 0.8950, Val Loss: 1.3729\n",
      "Epoch 11/200, Train Loss: 0.8692, Val Loss: 1.4199\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.2386\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1129\n",
      "Test R2: 0.4618\n",
      "Test MAE: 0.8665\n",
      "0    0.745355\n",
      "1    0.907725\n",
      "2    0.489357\n",
      "3    1.425637\n",
      "4    0.382878\n",
      "5    1.317009\n",
      "6    2.386976\n",
      "7    1.539759\n",
      "dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.2726, Val Loss: 1.1932\n",
      "Epoch 2/200, Train Loss: 0.6417, Val Loss: 1.0270\n",
      "Epoch 3/200, Train Loss: 0.5845, Val Loss: 1.1045\n",
      "Epoch 4/200, Train Loss: 0.5515, Val Loss: 1.0371\n",
      "Epoch 5/200, Train Loss: 0.5077, Val Loss: 1.2905\n",
      "Epoch 6/200, Train Loss: 0.4738, Val Loss: 1.3216\n",
      "Epoch 7/200, Train Loss: 0.4829, Val Loss: 1.0449\n",
      "Epoch 8/200, Train Loss: 0.4346, Val Loss: 1.0702\n",
      "Epoch 9/200, Train Loss: 0.4129, Val Loss: 1.4880\n",
      "Epoch 10/200, Train Loss: 0.3908, Val Loss: 1.4281\n",
      "Epoch 11/200, Train Loss: 0.3769, Val Loss: 1.2676\n",
      "Epoch 12/200, Train Loss: 0.3568, Val Loss: 1.3300\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.0862\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.0422\n",
      "Test R2: 0.7085\n",
      "Test MAE: 0.7950\n",
      "0    1.267265\n",
      "1    1.451123\n",
      "2    1.530510\n",
      "3    1.130419\n",
      "4    1.998626\n",
      "5    0.454419\n",
      "6    1.513597\n",
      "7    0.960944\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "#所有站点单特征循环all site single feature\n",
    "#change the Define function input:X_origin[:,:,:,input_feature].squeeze(),LSTM_input_size = 9\n",
    "all_output_metrics = []\n",
    "all_output_importance = []\n",
    "\n",
    "for model_sites in range(9):\n",
    "    output_metrics = []\n",
    "    output_importance = []\n",
    "    for model_input_feature in range(9):\n",
    "        #Model hyperparameters\n",
    "        # 模型超参数\n",
    "        LSTM_input_size = 9\n",
    "        LSTM_hidden_size = 64  \n",
    "        LSTM_num_layers = 2\n",
    "\n",
    "        input_seq_len = 72  # 输入序列长度,Input sequence length\n",
    "        output_seq_len = 1  # 输出序列长度,output sequence length\n",
    "        #target_site_index will note input into the model\n",
    "        target_site_index = model_sites  # 目标站点（例如 站点0）,Target site (e.g. site 0)\n",
    "        target_col = 2  # 目标特征（例如 特征0）,Target feature (e.g. feature 0)\n",
    "        batch_size = 16\n",
    "\n",
    "        X, y = create_sequences(data, input_seq_len, output_seq_len, target_site_index, target_col)\n",
    "        y = y.squeeze((-1,-2))\n",
    "        #Divide the training set，validation set and test set 7:1:2\n",
    "        # 划分训练集和测试集7:1:2\n",
    "        train_size, val_size, test_size = 0.7, 0.1, 0.2\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size/(train_size+val_size+test_size), shuffle=False)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size/(train_size+val_size), shuffle=False)\n",
    "        X_train, X_val, X_test = to_tensor(X_train), to_tensor(X_val), to_tensor(X_test)\n",
    "        y_train, y_val, y_test = to_tensor(y_train), to_tensor(y_val), to_tensor(y_test)\n",
    "        # create DataLoader\n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        val_dataset = TensorDataset(X_val, y_val)\n",
    "        test_dataset = TensorDataset(X_test, y_test)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        lstm_model = LSTMModel(LSTM_input_size, LSTM_hidden_size, LSTM_num_layers, output_seq_len)\n",
    "        lstm_model.to(device)\n",
    "\n",
    "        epochs=200\n",
    "        learning_rate = 0.001\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
    "        epoch_logs=[]\n",
    "        input_feature = model_input_feature#0:WT,1:pH,2:DO,3:EC,4:TSS,5:CODMN,6:AN,7:TP,8:TN\n",
    "\n",
    "        LSTM_train_and_evaluate(lstm_model, train_loader, val_loader, criterion, optimizer, epochs, target_site_index, input_feature)\n",
    "        predictions, actuals = LSTM_evaluate(lstm_model, test_loader, target_site_index, input_feature)\n",
    "        #Calculate accuracy\n",
    "        # 计算精度\n",
    "        rmse, r2, mae = calculate_metrics(predictions, actuals)\n",
    "        #result\n",
    "        # 输出结果\n",
    "        print(f\"predictions shape: {predictions.shape}\")\n",
    "        print(f\"actuals shape: {actuals.shape}\")\n",
    "        print(f\"Test RMSE: {rmse:.4f}\")\n",
    "        print(f\"Test R2: {r2:.4f}\")\n",
    "        print(f\"Test MAE: {mae:.4f}\")\n",
    "        feature_importances = np.mean(pd.DataFrame(LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='zero')),axis= 0)\n",
    "        print(feature_importances)\n",
    "        \n",
    "        feature_importanes= pd.DataFrame({f\"F{model_input_feature}\" : feature_importances.values}, index = [f'N{s}' for s in range(9)])\n",
    "        \n",
    "        output_metrics.append([rmse, r2, mae])\n",
    "        output_importance.append(feature_importances)\n",
    "        epoch_logs = pd.DataFrame(epoch_logs,columns=['Epoch','Train_Loss','Val_loss','Time'])\n",
    "        epoch_logs.to_csv(f\"LSTM_logs_allsite_1feature_batch_site{model_sites}_feature{model_input_feature}.csv\",index=False)\n",
    "         \n",
    "    all_output_metrics.append(pd.DataFrame(output_metrics,columns=['RMSE','R2','MAE'], index = ['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']))\n",
    "    all_output_importance = pd.concat(output_importance,axis = 1)\n",
    "    all_output_importance.to_csv(f\"LSTM_al1site_1feature_batch_importance_site{model_sites}.csv\",index=False)\n",
    "\n",
    "result_output_metrics = pd.concat(all_output_metrics,axis = 1)\n",
    "\n",
    "result_output_metrics.to_csv(f\"LSTM_al1site_1feature_batch_metrics.csv\",index=False)\n",
    "\n",
    "# all_output_metrics.to_csv(f\"LSTM_allsite_1feature_batch_metrics备用查看数据.csv\",index=False)\n",
    "#['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6a59efd",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "#所有站点单特征\n",
    "#所有站点单特征输入为X_origin[:,:,:,input_feature].squeeze(),LSTM_input_size = 9\n",
    "\n",
    "\n",
    "model_sites = 2\n",
    "LSTM_input_size = 8\n",
    "LSTM_hidden_size = 64  # LSTM 隐藏层大小\n",
    "LSTM_num_layers = 2\n",
    "\n",
    "input_seq_len = 72  # 输入序列长度\n",
    "output_seq_len = 1  # 输出序列长度\n",
    "target_site_index = model_sites  # 目标站点的索引（例如 站点0）\n",
    "target_col = 2  # 目标特征列的索引（例如 特征0）\n",
    "batch_size = 16\n",
    "\n",
    "X, y = create_sequences(data, input_seq_len, output_seq_len, target_site_index, target_col)\n",
    "y = y.squeeze((-1,-2))\n",
    "# 划分训练集和测试集\n",
    "train_size, val_size, test_size = 0.7, 0.1, 0.2\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size/(train_size+val_size+test_size), shuffle=False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size/(train_size+val_size), shuffle=False)\n",
    "X_train, X_val, X_test = to_tensor(X_train), to_tensor(X_val), to_tensor(X_test)\n",
    "y_train, y_val, y_test = to_tensor(y_train), to_tensor(y_val), to_tensor(y_test)\n",
    "# 创建DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "lstm_model = LSTMModel(LSTM_input_size, LSTM_hidden_size, LSTM_num_layers, output_seq_len)\n",
    "lstm_model.to(device)\n",
    "\n",
    "epochs=200\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
    "epoch_logs=[]\n",
    "input_feature = 2#0水温\t1pH\t2溶解氧\t3电导率\t4浊度\t5高锰酸盐\t6氨氮\t7总磷\t8总氮\n",
    "\n",
    "LSTM_train_and_evaluate(lstm_model, train_loader, val_loader, criterion, optimizer, epochs, target_site_index, input_feature)\n",
    "predictions, actuals = LSTM_evaluate(lstm_model, test_loader, target_site_index, input_feature)\n",
    "# 计算精度\n",
    "rmse, r2, mae = calculate_metrics(predictions, actuals)\n",
    "# 输出结果\n",
    "print(f\"predictions shape: {predictions.shape}\")\n",
    "print(f\"actuals shape: {actuals.shape}\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test R2: {r2:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "feature_importances = np.mean(pd.DataFrame(LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='zero')),axis= 0)\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7f26012",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 2.3339, Val Loss: 1.3148\n",
      "Epoch 2/200, Train Loss: 1.2836, Val Loss: 1.4694\n",
      "Epoch 3/200, Train Loss: 1.2586, Val Loss: 1.4299\n",
      "Epoch 4/200, Train Loss: 1.2340, Val Loss: 1.5982\n",
      "Epoch 5/200, Train Loss: 1.2124, Val Loss: 1.6321\n",
      "Epoch 6/200, Train Loss: 1.1877, Val Loss: 1.5310\n",
      "Epoch 7/200, Train Loss: 1.1591, Val Loss: 2.0657\n",
      "Epoch 8/200, Train Loss: 1.1723, Val Loss: 1.9402\n",
      "Epoch 9/200, Train Loss: 1.0989, Val Loss: 1.8666\n",
      "Epoch 10/200, Train Loss: 1.0318, Val Loss: 2.1865\n",
      "Epoch 11/200, Train Loss: 0.9942, Val Loss: 1.6020\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.9190\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.3853\n",
      "Test R2: 0.6543\n",
      "Test MAE: 1.1102\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 2, got 72",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest R2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mLSTM_feature_importance_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_site_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzero\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m),axis\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(feature_importances)\n",
      "Cell \u001b[1;32mIn[11], line 100\u001b[0m, in \u001b[0;36mLSTM_feature_importance_analysis\u001b[1;34m(lstm_model, test_loader, target_site_index, input_feature, baseline)\u001b[0m\n\u001b[0;32m     98\u001b[0m X_batch, y_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(device), y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     99\u001b[0m lstm_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m--> 100\u001b[0m baseline_output \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# 将数据移回CPU\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]):  \u001b[38;5;66;03m# 遍历特征\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     perturbed_output \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\GNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\GNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 14\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 14\u001b[0m     lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 批量计算\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#print(lstm_out.shape)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(lstm_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])  \u001b[38;5;66;03m# 仅使用最后时间步的隐藏状态#(batch_size,seq_len,hidden_size)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\GNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\GNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\GNN\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:892\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    888\u001b[0m     c_zeros \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m*\u001b[39m num_directions,\n\u001b[0;32m    889\u001b[0m                           max_batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[0;32m    890\u001b[0m                           dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    891\u001b[0m     hx \u001b[38;5;241m=\u001b[39m (h_zeros, c_zeros)\n\u001b[1;32m--> 892\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\GNN\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:821\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    817\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m    818\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[0;32m    819\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[0;32m    820\u001b[0m                        ):\n\u001b[1;32m--> 821\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    823\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    825\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\GNN\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:240\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 2, got 72"
     ]
    }
   ],
   "source": [
    "input_site = [4,8]\n",
    "lstm_model = LSTMModel(LSTM_input_size, LSTM_hidden_size, LSTM_num_layers, output_seq_len)\n",
    "lstm_model.to(device)\n",
    "\n",
    "epochs=200\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
    "epoch_logs=[]\n",
    "input_feature = 2#0水温\t1pH\t2溶解氧\t3电导率\t4浊度\t5高锰酸盐\t6氨氮\t7总磷\t8总氮\n",
    "\n",
    "LSTM_train_and_evaluate(lstm_model, train_loader, val_loader, criterion, optimizer, epochs, input_site, input_feature)\n",
    "predictions, actuals = LSTM_evaluate(lstm_model, test_loader, input_site, input_feature)\n",
    "# 计算精度\n",
    "rmse, r2, mae = calculate_metrics(predictions, actuals)\n",
    "# 输出结果\n",
    "print(f\"predictions shape: {predictions.shape}\")\n",
    "print(f\"actuals shape: {actuals.shape}\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test R2: {r2:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "feature_importances = np.mean(pd.DataFrame(LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='zero')),axis= 0)\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32ce624",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 所有站点所有特征all site all feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9ef6e66",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 3.2107, Val Loss: 2.0822\n",
      "Epoch 2/200, Train Loss: 1.3884, Val Loss: 2.3025\n",
      "Epoch 3/200, Train Loss: 1.1137, Val Loss: 1.7821\n",
      "Epoch 4/200, Train Loss: 0.9477, Val Loss: 1.9034\n",
      "Epoch 5/200, Train Loss: 0.8750, Val Loss: 2.1305\n",
      "Epoch 6/200, Train Loss: 0.8443, Val Loss: 2.1866\n",
      "Epoch 7/200, Train Loss: 0.7661, Val Loss: 1.9526\n",
      "Epoch 8/200, Train Loss: 0.7565, Val Loss: 2.3212\n",
      "Epoch 9/200, Train Loss: 0.7115, Val Loss: 1.7734\n",
      "Epoch 10/200, Train Loss: 0.6662, Val Loss: 1.5127\n",
      "Epoch 11/200, Train Loss: 0.6588, Val Loss: 1.9886\n",
      "Epoch 12/200, Train Loss: 0.6176, Val Loss: 1.8938\n",
      "Epoch 13/200, Train Loss: 0.6002, Val Loss: 1.6692\n",
      "Epoch 14/200, Train Loss: 0.6049, Val Loss: 1.7951\n",
      "Epoch 15/200, Train Loss: 0.5733, Val Loss: 1.6322\n",
      "Epoch 16/200, Train Loss: 0.5538, Val Loss: 1.4850\n",
      "Epoch 17/200, Train Loss: 0.5407, Val Loss: 1.6763\n",
      "Epoch 18/200, Train Loss: 0.5204, Val Loss: 1.6655\n",
      "Epoch 19/200, Train Loss: 0.5245, Val Loss: 1.4998\n",
      "Epoch 20/200, Train Loss: 0.5000, Val Loss: 1.6403\n",
      "Epoch 21/200, Train Loss: 0.4859, Val Loss: 1.4464\n",
      "Epoch 22/200, Train Loss: 0.4665, Val Loss: 1.5643\n",
      "Epoch 23/200, Train Loss: 0.4496, Val Loss: 1.7039\n",
      "Epoch 24/200, Train Loss: 0.4841, Val Loss: 1.7152\n",
      "Epoch 25/200, Train Loss: 0.4469, Val Loss: 1.6782\n",
      "Epoch 26/200, Train Loss: 0.4223, Val Loss: 1.3385\n",
      "Epoch 27/200, Train Loss: 0.4638, Val Loss: 1.6581\n",
      "Epoch 28/200, Train Loss: 0.4158, Val Loss: 1.6842\n",
      "Epoch 29/200, Train Loss: 0.4334, Val Loss: 1.7016\n",
      "Epoch 30/200, Train Loss: 0.4052, Val Loss: 1.4551\n",
      "Epoch 31/200, Train Loss: 0.3884, Val Loss: 1.5885\n",
      "Epoch 32/200, Train Loss: 0.3987, Val Loss: 1.7372\n",
      "Epoch 33/200, Train Loss: 0.3838, Val Loss: 1.5709\n",
      "Epoch 34/200, Train Loss: 0.3959, Val Loss: 1.5466\n",
      "Epoch 35/200, Train Loss: 0.3530, Val Loss: 1.4741\n",
      "Epoch 36/200, Train Loss: 0.3681, Val Loss: 1.4160\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.7521\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.3237\n",
      "Test R2: 0.2716\n",
      "Test MAE: 1.0394\n",
      "0     0.128493\n",
      "1     0.092602\n",
      "2     0.301218\n",
      "3     0.156178\n",
      "4     0.360499\n",
      "        ...   \n",
      "76    0.138857\n",
      "77    0.012135\n",
      "78    0.005800\n",
      "79    0.000539\n",
      "80    0.013560\n",
      "Length: 81, dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.9209, Val Loss: 2.2745\n",
      "Epoch 2/200, Train Loss: 1.2657, Val Loss: 2.8501\n",
      "Epoch 3/200, Train Loss: 1.1132, Val Loss: 3.1231\n",
      "Epoch 4/200, Train Loss: 0.9631, Val Loss: 1.9048\n",
      "Epoch 5/200, Train Loss: 0.7799, Val Loss: 1.7084\n",
      "Epoch 6/200, Train Loss: 0.6920, Val Loss: 1.9814\n",
      "Epoch 7/200, Train Loss: 0.6193, Val Loss: 0.9426\n",
      "Epoch 8/200, Train Loss: 0.5524, Val Loss: 0.9208\n",
      "Epoch 9/200, Train Loss: 0.4692, Val Loss: 1.1805\n",
      "Epoch 10/200, Train Loss: 0.4170, Val Loss: 1.3324\n",
      "Epoch 11/200, Train Loss: 0.4059, Val Loss: 1.1031\n",
      "Epoch 12/200, Train Loss: 0.3813, Val Loss: 1.4482\n",
      "Epoch 13/200, Train Loss: 0.3747, Val Loss: 1.3612\n",
      "Epoch 14/200, Train Loss: 0.3707, Val Loss: 1.0829\n",
      "Epoch 15/200, Train Loss: 0.3501, Val Loss: 1.0904\n",
      "Epoch 16/200, Train Loss: 0.3336, Val Loss: 1.0436\n",
      "Epoch 17/200, Train Loss: 0.3409, Val Loss: 0.8799\n",
      "Epoch 18/200, Train Loss: 0.3320, Val Loss: 0.9616\n",
      "Epoch 19/200, Train Loss: 0.3082, Val Loss: 1.0617\n",
      "Epoch 20/200, Train Loss: 0.3117, Val Loss: 1.3505\n",
      "Epoch 21/200, Train Loss: 0.3002, Val Loss: 1.0954\n",
      "Epoch 22/200, Train Loss: 0.2821, Val Loss: 1.2591\n",
      "Epoch 23/200, Train Loss: 0.2828, Val Loss: 1.3260\n",
      "Epoch 24/200, Train Loss: 0.2672, Val Loss: 1.1452\n",
      "Epoch 25/200, Train Loss: 0.2670, Val Loss: 1.0335\n",
      "Epoch 26/200, Train Loss: 0.2763, Val Loss: 1.1578\n",
      "Epoch 27/200, Train Loss: 0.2600, Val Loss: 0.9770\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.2397\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1134\n",
      "Test R2: 0.3056\n",
      "Test MAE: 0.8613\n",
      "0     0.116202\n",
      "1     0.030865\n",
      "2     0.148966\n",
      "3     0.184781\n",
      "4     0.173291\n",
      "        ...   \n",
      "76    0.126514\n",
      "77    0.011056\n",
      "78    0.002421\n",
      "79    0.000858\n",
      "80    0.018018\n",
      "Length: 81, dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.5193, Val Loss: 2.5587\n",
      "Epoch 2/200, Train Loss: 1.3447, Val Loss: 1.4733\n",
      "Epoch 3/200, Train Loss: 1.1452, Val Loss: 1.6816\n",
      "Epoch 4/200, Train Loss: 1.0380, Val Loss: 2.3846\n",
      "Epoch 5/200, Train Loss: 0.9400, Val Loss: 2.4876\n",
      "Epoch 6/200, Train Loss: 0.8973, Val Loss: 3.2705\n",
      "Epoch 7/200, Train Loss: 0.9087, Val Loss: 1.8276\n",
      "Epoch 8/200, Train Loss: 0.8114, Val Loss: 2.1187\n",
      "Epoch 9/200, Train Loss: 0.7802, Val Loss: 1.9515\n",
      "Epoch 10/200, Train Loss: 0.7951, Val Loss: 1.8157\n",
      "Epoch 11/200, Train Loss: 0.7833, Val Loss: 2.7390\n",
      "Epoch 12/200, Train Loss: 0.7002, Val Loss: 2.1250\n",
      "Early stopping triggered.\n",
      "Test MSE: 2.7825\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.6681\n",
      "Test R2: 0.4988\n",
      "Test MAE: 1.2930\n",
      "0     0.137399\n",
      "1     0.014271\n",
      "2     0.092157\n",
      "3     0.316097\n",
      "4     0.068109\n",
      "        ...   \n",
      "76    0.076016\n",
      "77    0.003697\n",
      "78    0.003436\n",
      "79    0.000299\n",
      "80    0.008609\n",
      "Length: 81, dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.2328, Val Loss: 1.2144\n",
      "Epoch 2/200, Train Loss: 1.2101, Val Loss: 1.3606\n",
      "Epoch 3/200, Train Loss: 1.0042, Val Loss: 1.1641\n",
      "Epoch 4/200, Train Loss: 0.9079, Val Loss: 1.4368\n",
      "Epoch 5/200, Train Loss: 0.8292, Val Loss: 1.7077\n",
      "Epoch 6/200, Train Loss: 0.7527, Val Loss: 1.3620\n",
      "Epoch 7/200, Train Loss: 0.6993, Val Loss: 1.9348\n",
      "Epoch 8/200, Train Loss: 0.6621, Val Loss: 1.7128\n",
      "Epoch 9/200, Train Loss: 0.6343, Val Loss: 1.4767\n",
      "Epoch 10/200, Train Loss: 0.6080, Val Loss: 1.2771\n",
      "Epoch 11/200, Train Loss: 0.5869, Val Loss: 1.5531\n",
      "Epoch 12/200, Train Loss: 0.5715, Val Loss: 1.3016\n",
      "Epoch 13/200, Train Loss: 0.5788, Val Loss: 2.1120\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.3688\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1700\n",
      "Test R2: 0.6352\n",
      "Test MAE: 0.9680\n",
      "0     0.128402\n",
      "1     0.053052\n",
      "2     0.108645\n",
      "3     0.231219\n",
      "4     0.051184\n",
      "        ...   \n",
      "76    0.084201\n",
      "77    0.006645\n",
      "78    0.004665\n",
      "79    0.000289\n",
      "80    0.011057\n",
      "Length: 81, dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.6895, Val Loss: 1.6733\n",
      "Epoch 2/200, Train Loss: 0.9817, Val Loss: 1.4127\n",
      "Epoch 3/200, Train Loss: 0.8231, Val Loss: 1.4669\n",
      "Epoch 4/200, Train Loss: 0.7521, Val Loss: 1.2832\n",
      "Epoch 5/200, Train Loss: 0.7066, Val Loss: 1.0991\n",
      "Epoch 6/200, Train Loss: 0.6589, Val Loss: 1.2550\n",
      "Epoch 7/200, Train Loss: 0.6027, Val Loss: 1.1742\n",
      "Epoch 8/200, Train Loss: 0.5789, Val Loss: 1.4312\n",
      "Epoch 9/200, Train Loss: 0.5780, Val Loss: 1.5495\n",
      "Epoch 10/200, Train Loss: 0.5328, Val Loss: 1.3875\n",
      "Epoch 11/200, Train Loss: 0.5148, Val Loss: 1.4001\n",
      "Epoch 12/200, Train Loss: 0.4865, Val Loss: 1.2561\n",
      "Epoch 13/200, Train Loss: 0.4805, Val Loss: 1.7654\n",
      "Epoch 14/200, Train Loss: 0.4553, Val Loss: 1.3434\n",
      "Epoch 15/200, Train Loss: 0.4715, Val Loss: 1.3512\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.0588\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.0290\n",
      "Test R2: 0.7715\n",
      "Test MAE: 0.8168\n",
      "0     0.143005\n",
      "1     0.009769\n",
      "2     0.100109\n",
      "3     0.106682\n",
      "4     0.045176\n",
      "        ...   \n",
      "76    0.065756\n",
      "77    0.023644\n",
      "78    0.006511\n",
      "79    0.000433\n",
      "80    0.010740\n",
      "Length: 81, dtype: float32\n",
      "Epoch 1/200, Train Loss: 2.4667, Val Loss: 1.0566\n",
      "Epoch 2/200, Train Loss: 1.4779, Val Loss: 1.3383\n",
      "Epoch 3/200, Train Loss: 1.1371, Val Loss: 1.2608\n",
      "Epoch 4/200, Train Loss: 0.8786, Val Loss: 0.9069\n",
      "Epoch 5/200, Train Loss: 0.7904, Val Loss: 0.8986\n",
      "Epoch 6/200, Train Loss: 0.6938, Val Loss: 0.8390\n",
      "Epoch 7/200, Train Loss: 0.6561, Val Loss: 0.8372\n",
      "Epoch 8/200, Train Loss: 0.6157, Val Loss: 0.8119\n",
      "Epoch 9/200, Train Loss: 0.5899, Val Loss: 0.7264\n",
      "Epoch 10/200, Train Loss: 0.5475, Val Loss: 0.7871\n",
      "Epoch 11/200, Train Loss: 0.5280, Val Loss: 0.7986\n",
      "Epoch 12/200, Train Loss: 0.5225, Val Loss: 0.8779\n",
      "Epoch 13/200, Train Loss: 0.5404, Val Loss: 0.9854\n",
      "Epoch 14/200, Train Loss: 0.4918, Val Loss: 0.7217\n",
      "Epoch 15/200, Train Loss: 0.4822, Val Loss: 0.9721\n",
      "Epoch 16/200, Train Loss: 0.4827, Val Loss: 0.9304\n",
      "Epoch 17/200, Train Loss: 0.4657, Val Loss: 0.8995\n",
      "Epoch 18/200, Train Loss: 0.4696, Val Loss: 0.8540\n",
      "Epoch 19/200, Train Loss: 0.4672, Val Loss: 0.7933\n",
      "Epoch 20/200, Train Loss: 0.4501, Val Loss: 1.0029\n",
      "Epoch 21/200, Train Loss: 0.4466, Val Loss: 0.9484\n",
      "Epoch 22/200, Train Loss: 0.4431, Val Loss: 0.9087\n",
      "Epoch 23/200, Train Loss: 0.4274, Val Loss: 0.8152\n",
      "Epoch 24/200, Train Loss: 0.4236, Val Loss: 0.8432\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.5252\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.2350\n",
      "Test R2: 0.5270\n",
      "Test MAE: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.088548\n",
      "1     0.034884\n",
      "2     0.059406\n",
      "3     0.276840\n",
      "4     0.059199\n",
      "        ...   \n",
      "76    0.075109\n",
      "77    0.018241\n",
      "78    0.008419\n",
      "79    0.000306\n",
      "80    0.022159\n",
      "Length: 81, dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.8353, Val Loss: 1.5274\n",
      "Epoch 2/200, Train Loss: 1.2031, Val Loss: 1.3142\n",
      "Epoch 3/200, Train Loss: 1.1226, Val Loss: 1.2441\n",
      "Epoch 4/200, Train Loss: 1.0578, Val Loss: 0.9333\n",
      "Epoch 5/200, Train Loss: 1.0151, Val Loss: 1.5136\n",
      "Epoch 6/200, Train Loss: 0.9584, Val Loss: 1.3747\n",
      "Epoch 7/200, Train Loss: 0.9032, Val Loss: 1.3012\n",
      "Epoch 8/200, Train Loss: 0.8798, Val Loss: 1.2798\n",
      "Epoch 9/200, Train Loss: 0.8540, Val Loss: 1.5454\n",
      "Epoch 10/200, Train Loss: 0.8193, Val Loss: 1.3789\n",
      "Epoch 11/200, Train Loss: 0.7910, Val Loss: 1.0549\n",
      "Epoch 12/200, Train Loss: 0.7684, Val Loss: 1.3401\n",
      "Epoch 13/200, Train Loss: 0.7475, Val Loss: 1.4703\n",
      "Epoch 14/200, Train Loss: 0.7210, Val Loss: 1.1385\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.2508\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.1184\n",
      "Test R2: 0.4907\n",
      "Test MAE: 0.8612\n",
      "0     0.110686\n",
      "1     0.017035\n",
      "2     0.047838\n",
      "3     0.139937\n",
      "4     0.049955\n",
      "        ...   \n",
      "76    0.066674\n",
      "77    0.007014\n",
      "78    0.000910\n",
      "79    0.000217\n",
      "80    0.004964\n",
      "Length: 81, dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.9055, Val Loss: 1.5669\n",
      "Epoch 2/200, Train Loss: 1.3334, Val Loss: 1.3581\n",
      "Epoch 3/200, Train Loss: 1.1850, Val Loss: 1.7290\n",
      "Epoch 4/200, Train Loss: 1.0552, Val Loss: 1.2052\n",
      "Epoch 5/200, Train Loss: 0.9719, Val Loss: 1.2130\n",
      "Epoch 6/200, Train Loss: 0.9063, Val Loss: 1.2968\n",
      "Epoch 7/200, Train Loss: 0.8459, Val Loss: 1.2699\n",
      "Epoch 8/200, Train Loss: 0.8305, Val Loss: 0.9145\n",
      "Epoch 9/200, Train Loss: 0.7778, Val Loss: 1.0792\n",
      "Epoch 10/200, Train Loss: 0.7744, Val Loss: 1.3983\n",
      "Epoch 11/200, Train Loss: 0.7521, Val Loss: 1.1133\n",
      "Epoch 12/200, Train Loss: 0.7402, Val Loss: 1.0096\n",
      "Epoch 13/200, Train Loss: 0.7254, Val Loss: 1.2535\n",
      "Epoch 14/200, Train Loss: 0.7123, Val Loss: 1.4964\n",
      "Epoch 15/200, Train Loss: 0.7097, Val Loss: 1.2231\n",
      "Epoch 16/200, Train Loss: 0.7014, Val Loss: 1.2408\n",
      "Epoch 17/200, Train Loss: 0.6923, Val Loss: 1.1042\n",
      "Epoch 18/200, Train Loss: 0.6851, Val Loss: 1.0001\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.6330\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.2779\n",
      "Test R2: 0.2904\n",
      "Test MAE: 0.9837\n",
      "0     0.071168\n",
      "1     0.018046\n",
      "2     0.034386\n",
      "3     0.198804\n",
      "4     0.051661\n",
      "        ...   \n",
      "76    0.055679\n",
      "77    0.014717\n",
      "78    0.001821\n",
      "79    0.000257\n",
      "80    0.007425\n",
      "Length: 81, dtype: float32\n",
      "Epoch 1/200, Train Loss: 1.6819, Val Loss: 2.1433\n",
      "Epoch 2/200, Train Loss: 0.8844, Val Loss: 1.6610\n",
      "Epoch 3/200, Train Loss: 0.7071, Val Loss: 1.5291\n",
      "Epoch 4/200, Train Loss: 0.6635, Val Loss: 1.5220\n",
      "Epoch 5/200, Train Loss: 0.5527, Val Loss: 1.2249\n",
      "Epoch 6/200, Train Loss: 0.5380, Val Loss: 1.4347\n",
      "Epoch 7/200, Train Loss: 0.4889, Val Loss: 1.4521\n",
      "Epoch 8/200, Train Loss: 0.4872, Val Loss: 1.3533\n",
      "Epoch 9/200, Train Loss: 0.4684, Val Loss: 1.3252\n",
      "Epoch 10/200, Train Loss: 0.4519, Val Loss: 1.2346\n",
      "Epoch 11/200, Train Loss: 0.3974, Val Loss: 1.0310\n",
      "Epoch 12/200, Train Loss: 0.4106, Val Loss: 1.2648\n",
      "Epoch 13/200, Train Loss: 0.3897, Val Loss: 1.2608\n",
      "Epoch 14/200, Train Loss: 0.3785, Val Loss: 1.2647\n",
      "Epoch 15/200, Train Loss: 0.3664, Val Loss: 1.1787\n",
      "Epoch 16/200, Train Loss: 0.3530, Val Loss: 1.1193\n",
      "Epoch 17/200, Train Loss: 0.3361, Val Loss: 1.0941\n",
      "Epoch 18/200, Train Loss: 0.3327, Val Loss: 1.1958\n",
      "Epoch 19/200, Train Loss: 0.3289, Val Loss: 1.1791\n",
      "Epoch 20/200, Train Loss: 0.3111, Val Loss: 1.1650\n",
      "Epoch 21/200, Train Loss: 0.3249, Val Loss: 1.2198\n",
      "Early stopping triggered.\n",
      "Test MSE: 1.8216\n",
      "predictions shape: (6114, 1)\n",
      "actuals shape: (6114, 1)\n",
      "Test RMSE: 1.3497\n",
      "Test R2: 0.5112\n",
      "Test MAE: 1.0862\n",
      "0     0.146019\n",
      "1     0.012007\n",
      "2     0.055180\n",
      "3     0.218199\n",
      "4     0.094044\n",
      "        ...   \n",
      "76    0.110982\n",
      "77    0.023316\n",
      "78    0.005668\n",
      "79    0.000342\n",
      "80    0.021264\n",
      "Length: 81, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "#所有站点所有特征循环all site all feature \n",
    "#change the Define function input:X_origin[:,:,:,:].squeeze(),X_origin = X_origin.reshape(16,72,81),LSTM_input_size = 81\n",
    "all_output_metrics = []\n",
    "all_output_importance = []\n",
    "\n",
    "for model_sites in range(9):\n",
    "    # 模型超参数\n",
    "    LSTM_input_size = 81\n",
    "    LSTM_hidden_size = 64  # LSTM 隐藏层大小\n",
    "    LSTM_num_layers = 2\n",
    "\n",
    "    input_seq_len = 72  # 输入序列长度,Input sequence length\n",
    "    output_seq_len = 1  # 输出序列长度,output sequence length\n",
    "    #target_site_index will note input into the model\n",
    "    target_site_index = model_sites  # 目标站点（例如 站点0）,Target site (e.g. site 0)\n",
    "    target_col = 2  # 目标特征（例如 特征0）,Target feature (e.g. feature 0)\n",
    "    batch_size = 16\n",
    "\n",
    "    X, y = create_sequences(data, input_seq_len, output_seq_len, target_site_index, target_col)\n",
    "    y = y.squeeze((-1,-2))\n",
    "    #Divide the training set，validation set and test set 7:1:2\n",
    "    # 划分训练集和测试集\n",
    "    train_size, val_size, test_size = 0.7, 0.1, 0.2\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size/(train_size+val_size+test_size), shuffle=False)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size/(train_size+val_size), shuffle=False)\n",
    "    X_train, X_val, X_test = to_tensor(X_train), to_tensor(X_val), to_tensor(X_test)\n",
    "    y_train, y_val, y_test = to_tensor(y_train), to_tensor(y_val), to_tensor(y_test)\n",
    "    # create DataLoader\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    lstm_model = LSTMModel(LSTM_input_size, LSTM_hidden_size, LSTM_num_layers, output_seq_len)\n",
    "    lstm_model.to(device)\n",
    "\n",
    "    epochs=200\n",
    "    learning_rate = 0.001\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
    "    epoch_logs=[]\n",
    "    #input_feature will not input into the model\n",
    "    input_feature = 0#0:WT,1:pH,2:DO,3:EC,4:TSS,5:CODMN,6:AN,7:TP,8:TN\n",
    "\n",
    "    LSTM_train_and_evaluate(lstm_model, train_loader, val_loader, criterion, optimizer, epochs, target_site_index, input_feature)\n",
    "    predictions, actuals = LSTM_evaluate(lstm_model, test_loader, target_site_index, input_feature)\n",
    "    #Calculate accuracy\n",
    "    # 计算精度\n",
    "    rmse, r2, mae = calculate_metrics(predictions, actuals)\n",
    "    #result\n",
    "    # 输出结果\n",
    "    print(f\"predictions shape: {predictions.shape}\")\n",
    "    print(f\"actuals shape: {actuals.shape}\")\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test R2: {r2:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    feature_importances = np.mean(pd.DataFrame(LSTM_feature_importance_analysis(lstm_model, test_loader, target_site_index, input_feature, baseline='zero')),axis= 0)\n",
    "    print(feature_importances)\n",
    "\n",
    "    all_output_metrics.append([rmse, r2, mae])\n",
    "    all_output_importance.append(pd.DataFrame({f\"N{model_sites}\" : feature_importances.values}, index=[f'F{s}' for s in range(81)]))\n",
    "    epoch_logs = pd.DataFrame(epoch_logs,columns=['Epoch','Train_Loss','Val_loss','Time'])\n",
    "    epoch_logs.to_csv(f\"LSTM_logs_allsiteallfeature_batch_site{model_sites}.csv\",index=False)\n",
    "\n",
    "result_output_metrics = pd.DataFrame(output_metrics,columns=['RMSE','R2','MAE'])\n",
    "result_output_importance = pd.concat(all_output_importance,axis = 1)\n",
    "\n",
    "result_output_metrics.to_csv(f\"LSTM_allsiteallfeature_batch_metrics_.csv\",index=False)\n",
    "result_output_importance.to_csv(f\"LSTM_1siteallfeature_logs_one_batch_importance.csv\",index=False)\n",
    "# all_output_importance.to_csv(f\"LSTM_allsiteallfeature_logs_one_batch_importance备用查看数据.csv\",index=False)\n",
    "#['WT','pH','DO','EC','TSS','CODMn','AN','TP','TN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f944f1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 其他other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0ef70",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_iter = iter(test_loader)  # 创建一个迭代器\n",
    "X_sample, y_sample = next(data_iter)  # 获取一个批次数据\n",
    "print(X_sample.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GNN]",
   "language": "python",
   "name": "conda-env-GNN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
